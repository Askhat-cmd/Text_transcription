

Ниже — подробный и структурированный PRD, ориентированный на Cursor / IDE-агента, который будет реализовывать бота на основе существующей базы данных `voice_bot_pipeline` (SAG v2.0 + Knowledge Graph). Ничего в пайплайне не меняем, только **читаем и используем** его результаты.

***

# PRD: Супер-Умный Бот-Психолог на базе `voice_bot_pipeline`

## 1. Цель продукта

Создать специализированного AI-бота-психолога, который:

- Работает **исключительно** поверх уже готовых данных `voice_bot_pipeline` (SAG v2.0 JSON + Knowledge Graph + векторная БД).
- Использует **все доступные слои структуры**: блоки, граф-сущности, семантические связи, причинно-следственные цепочки, иерархии концептов, практики, техники, упражнения.
- Отвечает на запросы пользователя не только фактами, но и:
    - Диагностирует состояние (по тексту запроса).
    - Предлагает путь/практики/видео с таймкодами.
    - Объясняет связи между концептами.
- Строится пошагово: от **простого семантического QA** до **сложного "путь-трансформации"**.

***

## 2. Входные ограничения и допущения

1. **Источник данных**:
    - Используем текущий репозиторий `Askhat-cmd/voice_bot_pipeline`.
    - Используем только уже сформированные артефакты:
        - `data/sag_final/YYYY/MM/*.for_vector.json`
        - `data/sag_final/YYYY/MM/*.knowledge_graph.json`
        - Векторную БД (ChromaDB) через `VectorDBManager`/`VectorIndexer` (если уже используется в проекте).
    - Пайплайн обработки видео (YouTube → субтитры → SAG) **не трогаем**.
2. **Ограничение по изменениям**:
    - Никаких модификаций в существующем pipeline_orchestrator, экстракторах и т.п.
    - Допускается **только чтение**:
        - JSON-файлов.
        - Knowledge Graph.
        - ChromaDB коллекций (через существующие или новые обертки).
3. **Исполнение**:
    - Бот разрабатывается как **отдельный модуль/пакет** внутри этого же репозитория (или рядом).
    - Взаимодействие с LLM/моделью — через уже существующий механизм (OpenAI API), указанный в `.env`.

***

## 3. Высокоуровневая функциональность

### 3.1. Базовый уровень (Phase 1) — Семантический QA по лекциям

**Цель:** Реализовать бота, который умеет:

- Понимать вопрос пользователя.
- Находить релевантные блоки лекций.
- Давать ответ с отсылками на конкретные блоки и таймкоды.

**Функции:**

1. **Поиск релевантных блоков:**
    - Использовать:
        - Векторный поиск по коллекции `sag_v2_blocks` (через ChromaDB).
        - При отсутствии векторной БД — fallback: линейный поиск по `blocks[].content` + `keywords`.
    - Возвращать top-k (настраиваемое, по умолчанию 3–5) релевантных блоков.
2. **Формирование ответа:**
    - LLM получает:
        - Вопрос пользователя.
        - Список релевантных блоков (title, summary, content, keywords, youtube_link, start/end).
    - Требование: ответ всегда содержит:
        - Объяснение.
        - 1–3 цитаты/пересказы из блоков.
        - Ссылки на конкретные `youtube_link` (с таймкодом).
    - Ответ должен быть:
        - На русском языке.
        - В тоне "спокойный, поддерживающий гид", без директивности.
3. **Формат результата (API/функция):**
    - Внутренний Python-интерфейс, например:

```python
def answer_question_basic(query: str) -> Dict:
    """
    Возвращает:
      {
        "answer": str,                 # финальный текст для пользователя
        "sources": List[Dict],         # список блоков-источников
        "debug": Optional[Dict]        # отладочная информация
      }
    """
```


***

### 3.2. Средний уровень (Phase 2) — Осознанное использование SAG v2.0

**Цель:** Подключить дополнительные поля SAG v2.0:

- Тип блока, эмоциональный тон, глубина, сложность.
- Граф-сущности блока (`graph_entities`).
- Семантические отношения (`semantic_relationships`).
- Высокоуровневые `document_metadata` и `overview_*`.

**Функции:**

1. **Ответ с учетом уровня пользователя:**
    - Ввести простую **оценку уровня** (beginner/intermediate/advanced) на основе:
        - Явного выбора пользователя (параметр).
        - Или эвристики по тексту (в дальнейшем).
    - Логика:
        - `beginner` → избегать сложных терминов, давать более простое объяснение.
        - `intermediate` → использовать термины, основываясь на `main_topics`.
        - `advanced` → активно ссылаться на структуру учения (нейросталкинг, разотождествление, т.п.).
2. **Вытаскивание ключевых концептов для ответа:**
    - Использовать:
        - `graph_entities` документа и блоков.
        - `semantic_relationships.conceptual_links` для выбора "центральных" концептов.
    - В ответе: явно подсвечивать ключевые концепты и их взаимосвязи.
3. **Глубже работать с `blocks` и `document_metadata`:**
    - Если пользователь спрашивает общий вопрос:
        - Сначала опираться на `document_metadata.overview_summary` + `overview_toc`.
    - Если вопрос узкий:
        - Идти в конкретные блоки, но при этом указывать, как это связано с целой лекцией.
4. **Интерфейс:**

```python
def answer_question_sag_aware(
    query: str,
    user_level: str = "beginner",  # or "intermediate", "advanced"
) -> Dict:
    """
    Возвращает:
      {
        "answer": str,
        "sources": List[Dict],
        "concepts": List[str],          # задействованные концепты
        "relations": List[Dict],        # важные связи между концептами
        "meta": Dict                    # уровень, оценки глубины и т.д.
      }
    """
```


***

### 3.3. Продвинутый уровень (Phase 3) — Использование Knowledge Graph

**Цель:** Бот не только ищет текст, но и **обращается к Knowledge Graph**, чтобы:

- Понимать, какие практики связаны с концептом.
- Понимать причинно-следственные цепочки.
- Предлагать маршруты/последовательности.

**Функции:**

1. **Низкоуровневый API для графа:**
    - Реализовать слой-обертку над `*.knowledge_graph.json`:
        - Загрузка графа (nodes, edges, metadata).
        - Поиск узла по имени / синонимам.
        - Поиск всех связей исходящего/входящего типа.
        - Поиск связей с учетом `confidence` (вес связи).
    - Интерфейс (пример):

```python
class KnowledgeGraphClient:
    def find_node(self, name: str) -> Optional[Dict]:
        ...
    def get_related(self, node_id: str, edge_types: List[str] = None) -> List[Dict]:
        ...
    def get_practices_for_concept(self, concept_name: str) -> List[Dict]:
        ...
    def get_chain(self, from_concept: str, to_concept: str) -> Optional[List[Dict]]:
        ...
```

2. **Рекомендация практик:**
    - На основе графа:
        - Для заданного концепта (или распознанного состояния) поиск `PRACTICE`, `TECHNIQUE`, `EXERCISE`, связанных через `IS_PRACTICE_FOR`, `IS_TECHNIQUE_FOR`, `IS_EXERCISE_FOR`, `ENABLES`, `REQUIRES`.
    - На основе найденных узлов:
        - Найти соответствующие блоки, где эти практики объясняются (через `graph_entities`).
        - Вернуть:
            - Описание практики (вытянутое из блоков).
            - Временные метки и ссылки на видео.

**Интерфейс:**

```python
def suggest_practices_for_concept(concept: str) -> Dict:
    """
    {
      "concept": str,
      "practices": [
        {
          "name": str,
          "type": "PRACTICE" | "TECHNIQUE" | "EXERCISE",
          "description": str,
          "recommended_duration": Optional[str],
          "sources": List[Dict]  # блоки с timecodes
        },
        ...
      ]
    }
    """
```

3. **Объяснение связей ("почему так"):**
    - Если бот дает рекомендацию:
        - Обосновывать ее через граф:
            - `from` → `to` с `edge_type` и `confidence`.
    - В ответах показывать:
        - "Эта практика связана с концептом Х через отношение Y, с силой связи Z".

***

### 3.4. Экспертный уровень (Phase 4) — Диагностика и маршруты

**Цель:** На основе введенного текста пользователя:

- Попытаться **диагностировать состояние/паттерн**.
- Построить **персональный маршрут** (пошаговый план) через знания.

**Важно:** Этот уровень можно реализовывать поэтапно, опираясь на результаты Phases 1–3.

**Функции:**

1. **Распознавание состояния (эвристики + LLM):**
    - Ввести типы состояний (внутренняя модель), например:
        - `CONFUSED_ABOUT_AWARENESS`
        - `BLOCKED_PATTERN_LOOP`
        - `READY_FOR_PRACTICE`
        - `AFTER_SHOCK/INTEGRATION`
    - На первом этапе:
        - Реализовать **простую LLM-функцию-классификатор** поверх текстов, без ML обучения:
            - LLM анализирует текст запроса + (опционально) историю.
            - Возвращает структуру:

```python
{
  "state": str,
  "confidence": float,
  "reasoning": str
}
```

    - Связать каждый `state` с:
        - Набором целевых концептов.
        - Набором рекомендованных типов практик.
2. **Построение маршрута (Path Builder):**
    - На вход: состояние пользователя + целевой вектор (например: "осознавание" или "разотождествление").
    - На выход:
        - Массив шагов:
            - Каждый шаг = {цель шага, концепт/практика, объяснение, ссылки на блоки и видео}.
    - Использовать Knowledge Graph:
        - Найти путь `from_state_concept` → `target_concept` через `LEADS_TO`, `ENABLES`, `REQUIRES` и т.п.
    - Формировать текстовый маршрут:
        - 3–5 шагов (в начале).
        - Каждый шаг с:
            - Простым объяснением.
            - Практикой.
            - Видео с таймкодом.
3. **Интерфейс:**

```python
def build_transformation_path(
    user_text: str,
    target_concept: str = "осознавание"
) -> Dict:
    """
    {
      "detected_state": { ... },
      "target_concept": str,
      "steps": [
        {
          "step_number": int,
          "goal": str,
          "concept": str,
          "practice": Optional[str],
          "explanation": str,
          "sources": List[Dict]
        },
        ...
      ]
    }
    """
```


***

## 4. Архитектурные требования и организация кода

### 4.1. Структура нового модуля

Рекомендованная структура (пример):

```text
voice_bot_pipeline/
├── bot_agent/
│   ├── __init__.py
│   ├── config.py                  # пути к данным, параметры
│   ├── data_loader.py             # загрузка SAG JSON, графа, кэши
│   ├── graph_client.py            # KnowledgeGraphClient
│   ├── rag_engine.py              # работа с ChromaDB/поиском
│   ├── answer_basic.py            # Phase 1
│   ├── answer_sag_aware.py        # Phase 2
│   ├── practices_recommender.py   # Phase 3
│   ├── path_builder.py            # Phase 4
│   ├── state_classifier.py        # эвристики/LLM для состояний
│   └── api.py                     # высокий уровень: единая точка входа
└── ...
```


***

## 5. Не-функциональные требования

1. **Безопасность:**
    - Ответы бота должны:
        - Избегать медицинских/психиатрических диагнозов.
        - Не подменять реальную психотерапию.
        - Содержать дисклеймер при обсуждении тяжелых состояний ("если вы чувствуете сильное отчаяние / суицидальные мысли, обратитесь к специалисту/поддержке").
2. **Тон:**
    - Спокойный, уважительный, поддерживающий.
    - Без категоричных суждений "ты должен/обязан".
    - Фокус на "предлагаю исследовать", "можешь попробовать".
3. **Производительность:**
    - Кэширование:
        - Загрузки .json файлов и графа — один раз на процесс.
    - Поиск:
        - При наличии ChromaDB — использовать его.
        - При отсутствии — простой fallback без падения.
4. **Расширяемость:**
    - Вся логика, завязанная на структуру JSON, должна идти через слой `data_loader`/`graph_client`, чтобы при изменении схемы SAG v2.0 минимум кода ломался.

***

## 6. Приоритеты реализации (рекомендуемый порядок для агента)

### Этап 1 (MVP):

1. `data_loader.py`:
    - Загрузка `*.for_vector.json`.
    - Удобные методы: получить список всех блоков, найти по video_id, и т.п.
2. `rag_engine.py`:
    - Если ChromaDB уже работает — использовать.
    - Если нет — сделать простой поиск по тексту.
3. `answer_basic.py`:
    - Реализация `answer_question_basic`.

### Этап 2:

1. Расширение `data_loader.py`:
    - Поддержка `document_metadata`, `graph_entities`, `semantic_relationships`.
2. `answer_sag_aware.py`:
    - Учёт уровня пользователя.
    - Встраивание концептов и отношений в ответ.

### Этап 3:

1. `graph_client.py`:
    - Загрузка `*.knowledge_graph.json`.
    - Методы поиска узлов и связей.
2. `practices_recommender.py`:
    - `suggest_practices_for_concept`.

### Этап 4:

1. `state_classifier.py`:
    - Простейший LLM-классификатор состояний (без ML-тренировки).
2. `path_builder.py`:
    - `build_transformation_path`.

### Этап 5:

1. `api.py`:
    - Единая точка входа с режимами:
        - "qa_basic"
        - "qa_deep"
        - "practice_suggestion"
        - "path_building"

***

## 7. Критерии готовности (Definition of Done)

### Phase 1:

- Запрос → ответ с:
    - Текстом.
    - Список источников (block_id, title, youtube_link, start/end).
- Все работает на текущей базе без изменения пайплайна.


### Phase 2:

- Ответы адаптируются под `user_level`.
- В ответе явно видны используемые концепты/темы.


### Phase 3:

- Возможность запросить: "какие практики для [концепта]?"
- Ответ возвращает минимум 1–2 практики с описанием и видео.


### Phase 4:

- На длинный текст пользователя бот:
    - Возвращает распознанное состояние.
    - Предлагает 3–5 шагов "пути" с привязкой к концептам и практикам.

***
# PRD

Далее детальный PRD шаги прописаны в соответсвующих документах:
bot_psychologist\implementation of the bot psychologist project\Phase_1.md
bot_psychologist\implementation of the bot psychologist project\Phase_2.md
bot_psychologist\implementation of the bot psychologist project\Phase_3.md
