
# üöÄ –ù–∞—á–∞–ª–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ Phase 1 –≤ Cursor IDE

–ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –±–æ–µ–≤–æ–π —Ä–µ–∂–∏–º. –°–æ–∑–¥–∞—é –ø–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω –¥–ª—è –∞–≥–µ–Ω—Ç–∞ Cursor —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏ –∏ —Ñ–∞–π–ª–∞–º–∏.

***

## –®–∞–≥ 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞

### 1.1 –°–æ–∑–¥–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫

```bash
# –í –∫–æ—Ä–Ω–µ voice_bot_pipeline/
mkdir -p bot_agent
mkdir -p logs/bot_agent
touch bot_agent/__init__.py
```


### 1.2 –û–±–Ω–æ–≤–∏—Ç—å `.env` (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –≤ .env:
# OPENAI_API_KEY=sk-proj-...
# PRIMARY_MODEL=gpt-4o-mini
# DATA_ROOT=data  (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "data")
```


### 1.3 –°–æ–∑–¥–∞—Ç—å `requirements_bot.txt` (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏)

```
openai>=1.3.0
scikit-learn>=1.3.0
numpy>=1.24.0
python-dotenv>=1.0.0
```

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**

```bash
pip install -r requirements_bot.txt
```


***

## –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ (–≤ –ø–æ—Ä—è–¥–∫–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)

### –§–∞–π–ª 1Ô∏è‚É£: `bot_agent/config.py`

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `voice_bot_pipeline/bot_agent/config.py`:

```python
# bot_agent/config.py

import os
from pathlib import Path
from typing import Optional

class Config:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è Phase 1 QA-–±–æ—Ç–∞"""
    
    # === –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º (–∏–∑ voice_bot_pipeline) ===
    PROJECT_ROOT = Path(__file__).parent.parent  # voice_bot_pipeline/
    DATA_ROOT = Path(os.getenv("DATA_ROOT", "data"))
    SAG_FINAL_DIR = DATA_ROOT / "sag_final"  # –≥–¥–µ –ª–µ–∂–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ JSON
    
    # === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ ===
    TOP_K_BLOCKS = 5  # —Å–∫–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –±—Ä–∞—Ç—å
    MIN_RELEVANCE_SCORE = 0.3  # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (0-1)
    
    # === LLM –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ===
    LLM_MODEL = os.getenv("PRIMARY_MODEL", "gpt-4o-mini")
    LLM_TEMPERATURE = 0.7  # 0-1, –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–æ–≤
    LLM_MAX_TOKENS = 1500  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    # === –Ø–∑—ã–∫ ===
    RESPONSE_LANGUAGE = "russian"
    
    # === –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ ===
    ENABLE_CACHING = True
    CACHE_DIR = Path(".cache_bot_agent")
    
    # === –û—Ç–ª–∞–¥–∫–∞ ===
    DEBUG = os.getenv("DEBUG", "False").lower() == "true"
    
    @classmethod
    def validate(cls):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –≤—Å–µ –Ω—É–∂–Ω–æ–µ –µ—Å—Ç—å"""
        if not cls.OPENAI_API_KEY:
            raise ValueError("‚ùå OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env")
        if not cls.SAG_FINAL_DIR.exists():
            raise ValueError(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {cls.SAG_FINAL_DIR}")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç–∞–Ω—Å –∫–æ–Ω—Ñ–∏–≥–∞
config = Config()
```


***

### –§–∞–π–ª 2Ô∏è‚É£: `bot_agent/data_loader.py`

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `voice_bot_pipeline/bot_agent/data_loader.py`:

```python
# bot_agent/data_loader.py

import json
import logging
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime

from config import config

logger = logging.getLogger(__name__)


@dataclass
class Block:
    """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –±–ª–æ–∫–∞ –ª–µ–∫—Ü–∏–∏"""
    block_id: str
    video_id: str
    start: str
    end: str
    title: str
    summary: str
    content: str
    keywords: List[str]
    youtube_link: str
    document_title: str  # –∏–∑ –∫–∞–∫–æ–π –ª–µ–∫—Ü–∏–∏
    
    def get_preview(self, max_len: int = 200) -> str:
        """–í–µ—Ä–Ω—É—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ"""
        text = self.content[:max_len] if len(self.content) > max_len else self.content
        return text + "..." if len(self.content) > max_len else text


@dataclass
class Document:
    """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–π –ª–µ–∫—Ü–∏–∏"""
    video_id: str
    source_url: str
    title: str
    blocks: List[Block]
    metadata: Dict  # –ø–æ–ª–Ω—ã–µ document_metadata –∏–∑ JSON
    
    def get_all_text(self) -> str:
        """–í–µ—Ä–Ω—É—Ç—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        return " ".join([b.content for b in self.blocks])


class DataLoader:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç –≤—Å–µ SAG v2.0 JSON —Ñ–∞–π–ª—ã.
    """
    
    def __init__(self):
        self.documents: List[Document] = []
        self.all_blocks: List[Block] = []
        self._video_id_to_doc: Dict[str, Document] = {}
        self._block_id_to_block: Dict[str, Block] = {}
        
        self.loaded_at: Optional[datetime] = None
        self._is_loaded = False
    
    def load_all_data(self) -> None:
        """
        –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ *.for_vector.json –∏–∑ sag_final/
        """
        if self._is_loaded:
            logger.info("‚úì –î–∞–Ω–Ω—ã–µ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à")
            return
        
        logger.info(f"üìÇ –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É SAG v2.0 –¥–∞–Ω–Ω—ã—Ö –∏–∑ {config.SAG_FINAL_DIR}")
        
        if not config.SAG_FINAL_DIR.exists():
            logger.error(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {config.SAG_FINAL_DIR}")
            return
        
        json_files = list(config.SAG_FINAL_DIR.glob("**/*.for_vector.json"))
        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(json_files)} —Ñ–∞–π–ª–æ–≤")
        
        if not json_files:
            logger.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ *.for_vector.json —Ñ–∞–π–ª–æ–≤ –≤ {config.SAG_FINAL_DIR}")
            return
        
        for json_path in json_files:
            try:
                self._load_single_document(json_path)
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {json_path.name}: {e}")
        
        self._is_loaded = True
        self.loaded_at = datetime.now()
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(self.documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, {len(self.all_blocks)} –±–ª–æ–∫–æ–≤")
    
    def _load_single_document(self, json_path: Path) -> None:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ–¥–∏–Ω JSON —Ñ–∞–π–ª –∏ –ø–∞—Ä—Å–∏—Ç—å –µ–≥–æ"""
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        document_title = data.get("document_title", "Unknown")
        video_id = data["document_metadata"]["video_id"]
        source_url = data["document_metadata"]["source_url"]
        
        blocks = []
        for block_data in data.get("blocks", []):
            block = Block(
                block_id=block_data["block_id"],
                video_id=block_data["video_id"],
                start=block_data["start"],
                end=block_data["end"],
                title=block_data["title"],
                summary=block_data.get("summary", ""),
                content=block_data["content"],
                keywords=block_data.get("keywords", []),
                youtube_link=block_data["youtube_link"],
                document_title=document_title
            )
            blocks.append(block)
            self._block_id_to_block[block.block_id] = block
            self.all_blocks.append(block)
        
        doc = Document(
            video_id=video_id,
            source_url=source_url,
            title=document_title,
            blocks=blocks,
            metadata=data.get("document_metadata", {})
        )
        
        self.documents.append(doc)
        self._video_id_to_doc[video_id] = doc
        
        logger.debug(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {document_title} ({len(blocks)} –±–ª–æ–∫–æ–≤)")
    
    def get_all_blocks(self) -> List[Block]:
        """–í–µ—Ä–Ω—É—Ç—å –≤—Å–µ –±–ª–æ–∫–∏"""
        if not self._is_loaded:
            self.load_all_data()
        return self.all_blocks
    
    def get_document_by_video_id(self, video_id: str) -> Optional[Document]:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ video_id"""
        if not self._is_loaded:
            self.load_all_data()
        return self._video_id_to_doc.get(video_id)
    
    def get_block_by_id(self, block_id: str) -> Optional[Block]:
        """–ü–æ–ª—É—á–∏—Ç—å –±–ª–æ–∫ –ø–æ block_id"""
        if not self._is_loaded:
            self.load_all_data()
        return self._block_id_to_block.get(block_id)
    
    def get_all_documents(self) -> List[Document]:
        """–í–µ—Ä–Ω—É—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"""
        if not self._is_loaded:
            self.load_all_data()
        return self.documents
    
    def get_blocks_by_video_id(self, video_id: str) -> List[Block]:
        """–í–µ—Ä–Ω—É—Ç—å –≤—Å–µ –±–ª–æ–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        doc = self.get_document_by_video_id(video_id)
        return doc.blocks if doc else []


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç–∞–Ω—Å (—Å–∏–Ω–≥–ª—Ç–æ–Ω)
data_loader = DataLoader()
```


***

### –§–∞–π–ª 3Ô∏è‚É£: `bot_agent/retriever.py`

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `voice_bot_pipeline/bot_agent/retriever.py`:

```python
# bot_agent/retriever.py

import logging
from typing import List, Tuple, Optional
import numpy as np

from data_loader import data_loader, Block
from config import config

logger = logging.getLogger(__name__)


class SimpleRetriever:
    """
    –ü—Ä–æ—Å—Ç–æ–π retriever –Ω–∞ –æ—Å–Ω–æ–≤–µ TF-IDF + –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –µ—Å–ª–∏ –Ω–µ—Ç ChromaDB.
    """
    
    def __init__(self):
        self.vectorizer: Optional[object] = None
        self.tfidf_matrix = None
        self.blocks: List[Block] = []
        self._is_built = False
    
    def build_index(self) -> None:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –±–ª–æ–∫–æ–≤"""
        if self._is_built:
            logger.info("‚úì –ò–Ω–¥–µ–∫—Å —É–∂–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω")
            return
        
        try:
            from sklearn.feature_extraction.text import TfidfVectorizer
        except ImportError:
            logger.error("‚ùå scikit-learn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install scikit-learn")
            raise
        
        logger.info("üî® –°—Ç—Ä–æ—é TF-IDF –∏–Ω–¥–µ–∫—Å...")
        self.blocks = data_loader.get_all_blocks()
        
        if not self.blocks:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –±–ª–æ–∫–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è!")
            return
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞: title + keywords + summary
        texts = [
            f"{b.title} {' '.join(b.keywords)} {b.summary}"
            for b in self.blocks
        ]
        
        self.vectorizer = TfidfVectorizer(
            analyzer='char',  # —Å–∏–º–≤–æ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–ª—É—á—à–µ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)
            ngram_range=(2, 3),
            max_features=5000,
            stop_words='russian'
        )
        self.tfidf_matrix = self.vectorizer.fit_transform(texts)
        self._is_built = True
        logger.info(f"‚úÖ –ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω –¥–ª—è {len(self.blocks)} –±–ª–æ–∫–æ–≤")
    
    def retrieve(self, query: str, top_k: int = None) -> List[Tuple[Block, float]]:
        """
        –ù–∞–π—Ç–∏ top_k —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ (Block, score).
        """
        if top_k is None:
            top_k = config.TOP_K_BLOCKS
        
        if not self._is_built:
            self.build_index()
        
        if not self.blocks or self.tfidf_matrix is None:
            logger.warning("‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –ø—É—Å—Ç!")
            return []
        
        from sklearn.metrics.pairwise import cosine_similarity
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
        query_vec = self.vectorizer.transform([query])
        
        # –°—á–∏—Ç–∞–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        similarities = cosine_similarity(query_vec, self.tfidf_matrix).flatten()
        
        # –ë–µ—Ä–µ–º top_k —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É –ø–æ—Ä–æ–≥—É
        top_indices = np.argsort(-similarities)[:top_k]
        
        results = []
        for idx in top_indices:
            score = float(similarities[idx])
            if score >= config.MIN_RELEVANCE_SCORE:
                results.append((self.blocks[idx], score))
        
        logger.debug(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –¥–ª—è: '{query}'")
        return results


def get_retriever(use_chromadb: bool = False) -> SimpleRetriever:
    """–ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä retriever'–∞"""
    # –ù–∞ Phase 1 –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º SimpleRetriever
    logger.debug("üì¶ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é SimpleRetriever")
    return SimpleRetriever()
```


***

### –§–∞–π–ª 4Ô∏è‚É£: `bot_agent/llm_answerer.py`

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `voice_bot_pipeline/bot_agent/llm_answerer.py`:

```python
# bot_agent/llm_answerer.py

import logging
from typing import List, Dict, Optional

from data_loader import Block
from config import config

logger = logging.getLogger(__name__)


class LLMAnswerer:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—è OpenAI API.
    """
    
    def __init__(self):
        self.api_key = config.OPENAI_API_KEY
        if not self.api_key:
            raise ValueError("‚ùå OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç
        try:
            import openai
            self.client = openai.OpenAI(api_key=self.api_key)
            logger.info("‚úì OpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except ImportError:
            logger.error("‚ùå openai –ø–∞–∫–µ—Ç –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")
            raise
    
    def build_system_prompt(self) -> str:
        """
        –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–æ—Ç–∞-–ø—Å–∏—Ö–æ–ª–æ–≥–∞.
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –µ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è.
        """
        return """–¢—ã ‚Äî —Å–ø–æ–∫–æ–π–Ω—ã–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π –≥–∏–¥, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —É—á–µ–Ω–∏–∏ –°–∞–ª–∞–º–∞—Ç–∞ –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞ –æ –Ω–µ–π—Ä–æ—Å—Ç–∞–ª–∫–∏–Ω–≥–µ –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–æ–∑–Ω–∞–Ω–∏—è.

–¢–í–û–ï –ü–û–í–ï–î–ï–ù–ò–ï:
1. –û—Ç–≤–µ—á–∞–π —Å–ø–æ–∫–æ–π–Ω–æ, —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω–æ, –±–µ–∑ —Å—É–∂–¥–µ–Ω–∏–π.
2. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ª–µ–∫—Ü–∏–π.
3. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç —á—Ç–æ-—Ç–æ –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞, —Å–∫–∞–∂–∏: "–í –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö —ç—Ç–æ –Ω–µ –æ—Å–≤–µ—â–∞–µ—Ç—Å—è, –Ω–æ —è –º–æ–≥—É –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å..."
4. –í—Å–µ–≥–¥–∞ —Å—Ç–∞—Ä–∞–π—Å—è –Ω–∞–π—Ç–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –¥–ª—è –∂–∏–∑–Ω–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
5. –ò–∑–±–µ–≥–∞–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö/–ø—Å–∏—Ö–∏–∞—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∏–∞–≥–Ω–æ–∑–æ–≤. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–ø–æ–º–∏–Ω–∞–µ—Ç —Å–µ—Ä—å–µ–∑–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (—Å—É–∏—Ü–∏–¥–∞–ª—å–Ω—ã–µ –º—ã—Å–ª–∏, –ø–∞–Ω–∏—á–µ—Å–∫–∏–µ –∞—Ç–∞–∫–∏), –¥–æ–±–∞–≤—å –¥–∏—Å–∫–ª–µ–π–º–µ—Ä –æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É.

–¢–û–ù–£–°:
- –°–ø–æ–∫–æ–π–Ω—ã–π, –Ω–æ –Ω–µ –±–µ–∑–ª–∏—á–Ω—ã–π.
- "–ü—Ä–µ–¥–ª–∞–≥–∞—é –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å..." –≤–º–µ—Å—Ç–æ "–¢—ã –¥–æ–ª–∂–µ–Ω...".
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π, –Ω–æ —á–µ—Å—Ç–Ω—ã–π.

–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
1. –ü—Ä—è–º–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.
2. –ü—Ä–∏–≤–µ—Å—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.
3. –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ (–µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ).
4. –£–ø–æ–º—è–Ω—É—Ç—å, –æ—Ç–∫—É–¥–∞ –≤–∑—è—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è."""
    
    def build_context_prompt(self, blocks: List[Block], user_question: str) -> str:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM: –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏ + –≤–æ–ø—Ä–æ—Å.
        """
        context = "–ú–ê–¢–ï–†–ò–ê–õ –ò–ó –õ–ï–ö–¶–ò–ô:\n\n"
        
        for i, block in enumerate(blocks, 1):
            context += f"--- –ë–õ–û–ö {i} ---\n"
            context += f"–õ–µ–∫—Ü–∏—è: {block.document_title}\n"
            context += f"–¢–µ–º–∞: {block.title}\n"
            context += f"–¢–∞–π–º–∫–æ–¥: {block.start} ‚Äî {block.end}\n"
            context += f"–°—Å—ã–ª–∫–∞: {block.youtube_link}\n"
            context += f"–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {block.summary}\n"
            context += f"–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{block.content}\n\n"
        
        context += f"–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\n{user_question}\n\n"
        context += "–°—Ñ–æ—Ä–º–∏—Ä—É–π –æ—Ç–≤–µ—Ç, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª –≤—ã—à–µ. –ù–µ –∑–∞–±—É–¥—å —É–ø–æ–º—è–Ω—É—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Ç–∞–π–º–∫–æ–¥—ã."
        
        return context
    
    def generate_answer(
        self,
        user_question: str,
        blocks: List[Block],
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> Dict:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ OpenAI API.
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            {
                "answer": str,                 # –≥–æ—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
                "model_used": str,             # –∫–∞–∫—É—é –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏
                "tokens_used": int,            # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
                "error": Optional[str]         # –µ—Å–ª–∏ –±—ã–ª–∞ –æ—à–∏–±–∫–∞
            }
        """
        if not blocks:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –±–ª–æ–∫–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞!")
            return {
                "answer": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å.",
                "model_used": None,
                "tokens_used": 0,
                "error": "no_blocks"
            }
        
        model = model or config.LLM_MODEL
        temperature = temperature if temperature is not None else config.LLM_TEMPERATURE
        max_tokens = max_tokens or config.LLM_MAX_TOKENS
        
        system_prompt = self.build_system_prompt()
        context = self.build_context_prompt(blocks, user_question)
        
        logger.debug(f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ {model}...")
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": context}
                ],
                temperature=temperature,
                max_tokens=max_tokens,
            )
            
            answer = response.choices[0].message.content
            tokens = response.usage.total_tokens
            
            logger.debug(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω ({tokens} —Ç–æ–∫–µ–Ω–æ–≤)")
            
            return {
                "answer": answer,
                "model_used": model,
                "tokens_used": tokens,
                "error": None
            }
        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenAI API: {e}")
            return {
                "answer": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}",
                "model_used": model,
                "tokens_used": 0,
                "error": str(e)
            }
```


***

### –§–∞–π–ª 5Ô∏è‚É£: `bot_agent/answer_basic.py`

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `voice_bot_pipeline/bot_agent/answer_basic.py`:

```python
# bot_agent/answer_basic.py

import logging
from typing import Dict, List, Optional
from datetime import datetime

from data_loader import data_loader, Block
from retriever import get_retriever
from llm_answerer import LLMAnswerer
from config import config

logger = logging.getLogger(__name__)


def answer_question_basic(
    query: str,
    top_k: Optional[int] = None,
    use_chromadb: bool = False,
    debug: bool = False
) -> Dict:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Phase 1: QA –ø–æ –ª–µ–∫—Ü–∏—è–º.
    
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        query (str): –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º.
        top_k (int, optional): –°–∫–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.
        use_chromadb (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ChromaDB –¥–ª—è –ø–æ–∏—Å–∫–∞.
        debug (bool): –ï—Å–ª–∏ True, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        Dict —Å –∫–ª—é—á–∞–º–∏:
            - "status": "success" –∏–ª–∏ "error"
            - "answer": str ‚Äî –≥–æ—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            - "sources": List[Dict] ‚Äî –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–±–ª–æ–∫–∏ —Å —Å—Å—ã–ª–∫–∞–º–∏)
            - "blocks_used": int ‚Äî —Å–∫–æ–ª—å–∫–æ –±–ª–æ–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ
            - "timestamp": str ‚Äî –∫–æ–≥–¥–∞ –±—ã–ª —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç
            - "processing_time_seconds": float
            - "debug": Optional[Dict] ‚Äî –æ—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–µ—Å–ª–∏ debug=True)
    """
    
    logger.info(f"üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
    
    top_k = top_k or config.TOP_K_BLOCKS
    start_time = datetime.now()
    debug_info = {} if debug else None
    
    try:
        # === –≠–¢–ê–ü 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
        logger.debug("üìÇ –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        data_loader.load_all_data()
        
        if not data_loader.get_all_blocks():
            return {
                "status": "error",
                "answer": "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ª–µ–∫—Ü–∏–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –≤ data/sag_final/",
                "sources": [],
                "blocks_used": 0,
                "error": "no_data",
                "timestamp": datetime.now().isoformat(),
                "processing_time_seconds": 0.0,
                "debug": {"error_detail": "data_loader returned empty blocks"} if debug else None
            }
        
        if debug_info is not None:
            debug_info["data_loaded"] = {
                "total_documents": len(data_loader.get_all_documents()),
                "total_blocks": len(data_loader.get_all_blocks())
            }
        
        # === –≠–¢–ê–ü 2: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤ ===
        logger.debug("üîç –≠—Ç–∞–ø 2: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤...")
        retriever = get_retriever(use_chromadb=use_chromadb)
        retrieved_blocks = retriever.retrieve(query, top_k=top_k)
        
        if not retrieved_blocks:
            logger.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –¥–ª—è: '{query}'")
            return {
                "status": "partial",
                "answer": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à–µ–ª —á–µ—Ç–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —Å–ø—Ä–æ—Å–∏—Ç—å —á—Ç–æ-—Ç–æ –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ.",
                "sources": [],
                "blocks_used": 0,
                "timestamp": datetime.now().isoformat(),
                "processing_time_seconds": (datetime.now() - start_time).total_seconds(),
                "debug": debug_info
            }
        
        blocks = [block for block, score in retrieved_blocks]
        
        if debug_info is not None:
            debug_info["retrieval"] = {
                "query": query,
                "blocks_found": len(blocks),
                "scores": [float(score) for block, score in retrieved_blocks]
            }
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(blocks)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤")
        
        # === –≠–¢–ê–ü 3: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM ===
        logger.debug("ü§ñ –≠—Ç–∞–ø 3: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM...")
        answerer = LLMAnswerer()
        llm_result = answerer.generate_answer(query, blocks)
        
        if llm_result.get("error"):
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM: {llm_result['error']}")
            return {
                "status": "error",
                "answer": llm_result.get("answer", "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞."),
                "sources": [],
                "blocks_used": 0,
                "error": llm_result.get("error"),
                "timestamp": datetime.now().isoformat(),
                "processing_time_seconds": (datetime.now() - start_time).total_seconds(),
                "debug": debug_info
            }
        
        if debug_info is not None:
            debug_info["llm"] = {
                "model": llm_result.get("model_used"),
                "tokens_used": llm_result.get("tokens_used")
            }
        
        # === –≠–¢–ê–ü 4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ===
        logger.debug("üìù –≠—Ç–∞–ø 4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö...")
        sources = [
            {
                "block_id": b.block_id,
                "title": b.title,
                "summary": b.summary,
                "document_title": b.document_title,
                "youtube_link": b.youtube_link,
                "start": b.start,
                "end": b.end,
                "video_id": b.video_id
            }
            for b in blocks
        ]
        
        # === –§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢ ===
        elapsed_time = (datetime.now() - start_time).total_seconds()
        
        result = {
            "status": "success",
            "answer": llm_result["answer"],
            "sources": sources,
            "blocks_used": len(blocks),
            "timestamp": datetime.now().isoformat(),
            "processing_time_seconds": round(elapsed_time, 2)
        }
        
        if debug_info is not None:
            debug_info["total_time"] = elapsed_time
            result["debug"] = debug_info
        
        logger.info(f"‚úÖ –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {elapsed_time:.2f}—Å")
        
        return result
    
    except Exception as e:
        logger.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        return {
            "status": "error",
            "answer": f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}",
            "sources": [],
            "blocks_used": 0,
            "error": str(e),
            "timestamp": datetime.now().isoformat(),
            "processing_time_seconds": (datetime.now() - start_time).total_seconds(),
            "debug": debug_info
        }


# === –ü–†–û–°–¢–û–ô –ò–ù–¢–ï–†–§–ï–ô–° –î–õ–Ø –ë–´–°–¢–†–û–ì–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø ===

def ask(query: str, verbose: bool = False) -> str:
    """
    –ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: –≤–æ–ø—Ä–æ—Å -> –æ—Ç–≤–µ—Ç (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç).
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –µ—Å–ª–∏ –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞:
        >>> print(ask("–ß—Ç–æ —Ç–∞–∫–æ–µ —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ?"))
    """
    result = answer_question_basic(query, debug=verbose)
    
    if verbose and result.get("sources"):
        print(f"\n[DEBUG üìö] –ò—Å—Ç–æ—á–Ω–∏–∫–∏ ({len(result['sources'])} –±–ª–æ–∫–æ–≤):")
        for src in result['sources']:
            print(f"  ‚Ä¢ {src['document_title']} ({src['start']}‚Äî{src['end']})")
            print(f"    ‚Üí {src['youtube_link']}")
    
    return result["answer"]
```


***

### –§–∞–π–ª 6Ô∏è‚É£: `bot_agent/__init__.py`

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `voice_bot_pipeline/bot_agent/__init__.py`:

```python
# bot_agent/__init__.py

import logging
from pathlib import Path
import sys

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent))

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤
LOG_DIR = Path(__file__).parent.parent / "logs" / "bot_agent"
LOG_DIR.mkdir(parents=True, exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ª–æ–≥–µ—Ä–∞
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(name)s | %(levelname)s | %(message)s",
    handlers=[
        logging.FileHandler(LOG_DIR / "bot_agent.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger("bot_agent")

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
from answer_basic import answer_question_basic, ask

__all__ = ["answer_question_basic", "ask"]

logger.info("üöÄ Bot Agent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (Phase 1)")
```


***

## –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `voice_bot_pipeline/test_phase1.py`:

```python
# test_phase1.py
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Phase 1 –±–æ—Ç–∞
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º bot_agent –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent / "bot_agent"))

from answer_basic import answer_question_basic, ask

print("=" * 70)
print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï PHASE 1 - QA –ë–û–¢")
print("=" * 70)

# –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
test_queries = [
    "–ß—Ç–æ —Ç–∞–∫–æ–µ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ?",
    "–ö–∞–∫ —Ä–∞–∑–≤–∏—Ç—å –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏?",
    "–ö–∞–∫–æ–≤–∞ —Å–≤—è–∑—å –º–µ–∂–¥—É –∏—Å—Ü–µ–ª–µ–Ω–∏–µ–º –∏ —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ–º?",
    "–ö–∞–∫–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç—Å—è –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö?",
]

print("\n[INFO] –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ sag_final/...")

for i, query in enumerate(test_queries, 1):
    print(f"\n{'='*70}")
    print(f"–¢–ï–°–¢ {i}/{len(test_queries)}")
    print(f"{'='*70}")
    print(f"\nüìã –í–æ–ø—Ä–æ—Å: {query}\n")
    
    try:
        result = answer_question_basic(query, debug=True)
        
        print(f"Status: {result['status']}")
        print(f"Processing time: {result['processing_time_seconds']}s")
        print(f"Blocks used: {result['blocks_used']}")
        
        print(f"\nüí¨ –û–¢–í–ï–¢:\n{result['answer']}")
        
        if result.get('sources'):
            print(f"\nüìö –ò–°–¢–û–ß–ù–ò–ö–ò ({len(result['sources'])} –±–ª–æ–∫–æ–≤):")
            for src in result['sources']:
                print(f"  ‚Ä¢ {src['title']}")
                print(f"    –õ–µ–∫—Ü–∏—è: {src['document_title']}")
                print(f"    –¢–∞–π–º–∫–æ–¥: {src['start']}‚Äî{src['end']}")
                print(f"    –°—Å—ã–ª–∫–∞: {src['youtube_link']}\n")
        
        if result.get('debug'):
            print(f"\nüîß DEBUG INFO:")
            import json
            print(json.dumps(result['debug'], indent=2, ensure_ascii=False))
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

print("\n" + "=" * 70)
print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
print("=" * 70)
```


***

## –®–∞–≥ 4: –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

```bash
# –ü–µ—Ä–µ–π—Ç–∏ –≤ –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
cd voice_bot_pipeline

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements_bot.txt

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç
python test_phase1.py
```


***

## –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

### –ß—Ç–æ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏–∑–æ–π—Ç–∏:

```
üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï PHASE 1 - QA –ë–û–¢
======================================================================

[INFO] –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ sag_final/...

======================================================================
–¢–ï–°–¢ 1/4
======================================================================

üìã –í–æ–ø—Ä–æ—Å: –ß—Ç–æ —Ç–∞–∫–æ–µ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ?

Status: success
Processing time: 4.87s
Blocks used: 5

üí¨ –û–¢–í–ï–¢:
[–ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç –æ—Ç LLM]

üìö –ò–°–¢–û–ß–ù–ò–ö–ò (5 –±–ª–æ–∫–æ–≤):
  ‚Ä¢ –û—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∫–∞–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    –õ–µ–∫—Ü–∏—è: –õ–µ–∫—Ü–∏—è –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞: Rxoj94WQpsQ
    –¢–∞–π–º–∫–æ–¥: 00:12:30‚Äî00:20:15
    –°—Å—ã–ª–∫–∞: https://youtube.com/watch?v=Rxoj94WQpsQ&t=750s
...
```


***

## üéØ –ß–µ–∫-–ª–∏—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

- [ ] –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ `bot_agent/`
- [ ] –°–æ–∑–¥–∞–Ω—ã –≤—Å–µ 6 —Ñ–∞–π–ª–æ–≤ Python (config, data_loader, retriever, llm_answerer, answer_basic, __init__)
- [ ] –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (`pip install -r requirements_bot.txt`)
- [ ] –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç `test_phase1.py`
- [ ] –ó–∞–ø—É—â–µ–Ω —Ç–µ—Å—Ç –∏ –ø–æ–ª—É—á–µ–Ω—ã –æ—Ç–≤–µ—Ç—ã –æ—Ç LLM
- [ ] –í—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–∏–¥–µ–æ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∞–π–º–∫–æ–¥—ã
- [ ] –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç (—Ñ–∞–π–ª `logs/bot_agent/bot_agent.log`)

***

## ‚ö° –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

### –ü—Ä–æ–±–ª–µ–º–∞ 1: `ModuleNotFoundError: No module named 'openai'`

**–†–µ—à–µ–Ω–∏–µ:**

```bash
pip install openai>=1.3.0
```


### –ü—Ä–æ–±–ª–µ–º–∞ 2: `EnvironmentError: OPENAI_API_KEY not set`

**–†–µ—à–µ–Ω–∏–µ:**

- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–π–ª `.env`:

```env
OPENAI_API_KEY=sk-proj-YOUR_KEY_HERE
```


### –ü—Ä–æ–±–ª–µ–º–∞ 3: `FileNotFoundError: [Errno 2] No such file or directory: 'data/sag_final'`

**–†–µ—à–µ–Ω–∏–µ:**

- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∞–ª —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –≤–∏–¥–µ–æ
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤: `ls -la data/sag_final/`


### –ü—Ä–æ–±–ª–µ–º–∞ 4: `ImportError: No module named 'sklearn'`

**–†–µ—à–µ–Ω–∏–µ:**

```bash
pip install scikit-learn
```


***

## üìû –ì–æ—Ç–æ–≤–æ! üéâ

Phase 1 –≥–æ—Ç–æ–≤–∞ –∫ –∑–∞–ø—É—Å–∫—É. –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:

1. ‚úÖ –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç—ã
2. ‚úÖ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤
3. ‚úÖ –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
4. ‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ Phase 2 (SAG v2.0 aware –æ—Ç–≤–µ—Ç—ã)



