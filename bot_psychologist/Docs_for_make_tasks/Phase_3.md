<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# üöÄ –ù–∞—á–∞–ª–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ Phase 3 –≤ Cursor IDE

## –û–±–∑–æ—Ä Phase 3

**Phase 3** –ø–æ–¥–∫–ª—é—á–∞–µ—Ç Knowledge Graph:

- –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ `*.knowledge_graph.json`
- –ü–æ–∏—Å–∫ —É–∑–ª–æ–≤ –∏ —Å–≤—è–∑–µ–π –≤ –≥—Ä–∞—Ñ–µ
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—Ä–∞–∫—Ç–∏–∫ –¥–ª—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ü–µ–ø–æ—á–µ–∫ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ "–ø–æ—á–µ–º—É —Ç–∞–∫" —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ë–æ—Ç –º–æ–∂–µ—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞—Ö–æ–¥–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –Ω–æ –∏ –æ–±—ä—è—Å–Ω—è—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∑–Ω–∞–Ω–∏–π.

***

## –®–∞–≥ 1: –°–æ–∑–¥–∞–Ω–∏–µ `bot_agent/graph_client.py`

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `voice_bot_pipeline/bot_agent/graph_client.py`:

```python
# bot_agent/graph_client.py

import json
import logging
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from collections import defaultdict, deque

from data_loader import data_loader
from config import config

logger = logging.getLogger(__name__)


class GraphNode:
    """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–∞ –≤ Knowledge Graph"""
    
    def __init__(self, node_id: str, name: str, node_type: str, metadata: Dict = None):
        self.node_id = node_id
        self.name = name
        self.node_type = node_type  # CONCEPT, PRACTICE, TECHNIQUE, EXERCISE, PATTERN, PROCESS_STAGE
        self.metadata = metadata or {}


class GraphEdge:
    """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–≤—è–∑–∏ –≤ Knowledge Graph"""
    
    def __init__(
        self,
        from_id: str,
        to_id: str,
        from_name: str,
        to_name: str,
        edge_type: str,
        explanation: str = "",
        confidence: float = 1.0,
        metadata: Dict = None
    ):
        self.from_id = from_id
        self.to_id = to_id
        self.from_name = from_name
        self.to_name = to_name
        self.edge_type = edge_type
        self.explanation = explanation
        self.confidence = confidence  # –≤–µ—Å —Å–≤—è–∑–∏ 0.0-1.0
        self.metadata = metadata or {}


class KnowledgeGraphClient:
    """
    –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Knowledge Graph –∏–∑ SAG v2.0.
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≥—Ä–∞—Ñ, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥—ã –ø–æ–∏—Å–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞.
    """
    
    def __init__(self):
        self.nodes: Dict[str, GraphNode] = {}
        self.edges: List[GraphEdge] = []
        self.adjacency: Dict[str, List[GraphEdge]] = defaultdict(list)  # from_id -> edges
        self.reverse_adjacency: Dict[str, List[GraphEdge]] = defaultdict(list)  # to_id -> edges
        self.node_by_name: Dict[str, GraphNode] = {}  # –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –∏–º–µ–Ω–∏
        self._is_loaded = False
        self.metadata = {}
    
    def load_graphs_from_all_documents(self) -> None:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å Knowledge Graphs –∏–∑ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
        –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≥—Ä–∞—Ñ—ã –≤ –µ–¥–∏–Ω—ã–π –ø–æ–ª–Ω—ã–π –≥—Ä–∞—Ñ.
        """
        if self._is_loaded:
            logger.info("‚úì –ì—Ä–∞—Ñ—ã —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            return
        
        logger.info("üìä –ó–∞–≥—Ä—É–∂–∞—é Knowledge Graphs –∏–∑ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        documents = data_loader.get_all_documents()
        docs_with_graphs = 0
        
        for doc in documents:
            try:
                # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π *.knowledge_graph.json —Ñ–∞–π–ª
                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –æ–Ω –ª–µ–∂–∏—Ç –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ —á—Ç–æ –∏ *.for_vector.json
                # –∏ –∏–º–µ–µ—Ç —Ç–æ –∂–µ –∏–º—è, –Ω–æ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .knowledge_graph.json
                
                # –ü–æ–∫–∞ —á—Ç–æ –≥—Ä–∞—Ñ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏ for_vector.json –≤ –ø–æ–ª–µ "knowledge_graph"
                graph_path = self._find_graph_file_for_doc(doc.video_id)
                
                if graph_path:
                    self._load_single_graph(graph_path)
                    docs_with_graphs += 1
            
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥—Ä–∞—Ñ –¥–ª—è {doc.video_id}: {e}")
        
        self._is_loaded = True
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≥—Ä–∞—Ñ–æ–≤ –∏–∑ {docs_with_graphs} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        logger.info(f"   –í—Å–µ–≥–æ —É–∑–ª–æ–≤: {len(self.nodes)}, —Å–≤—è–∑–µ–π: {len(self.edges)}")
    
    def _find_graph_file_for_doc(self, video_id: str) -> Optional[Path]:
        """
        –ù–∞–π—Ç–∏ —Ñ–∞–π–ª *.knowledge_graph.json –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞.
        """
        graph_files = list(config.SAG_FINAL_DIR.glob(f"**/*{video_id}.knowledge_graph.json"))
        
        if graph_files:
            return graph_files[0]
        
        # –ï—Å–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ for_vector.json
        for_vector_files = list(config.SAG_FINAL_DIR.glob(f"**/*{video_id}.for_vector.json"))
        
        if for_vector_files:
            return for_vector_files[0]
        
        return None
    
    def _load_single_graph(self, graph_path: Path) -> None:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –≥—Ä–∞—Ñ –∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.
        """
        with open(graph_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # –ì—Ä–∞—Ñ –º–æ–∂–µ—Ç –±—ã—Ç—å:
        # 1. –í –ø–æ–ª–µ "knowledge_graph" –≤–Ω—É—Ç—Ä–∏ for_vector.json
        # 2. –í –∫–æ—Ä–Ω–µ —Ñ–∞–π–ª–∞ knowledge_graph.json
        
        if isinstance(data, dict) and "knowledge_graph" in data:
            graph_data = data["knowledge_graph"]
        else:
            graph_data = data
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∑–ª—ã
        for node_data in graph_data.get("nodes", []):
            node_id = node_data.get("id")
            name = node_data.get("name")
            node_type = node_data.get("type", "CONCEPT")
            
            if node_id and name:
                node = GraphNode(node_id, name, node_type, node_data.get("metadata", {}))
                self.nodes[node_id] = node
                self.node_by_name[name.lower()] = node
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤—è–∑–∏
        for edge_data in graph_data.get("edges", []):
            from_id = edge_data.get("from_id")
            to_id = edge_data.get("to_id")
            from_name = edge_data.get("from_name")
            to_name = edge_data.get("to_name")
            edge_type = edge_data.get("edge_type", "RELATED_TO")
            explanation = edge_data.get("explanation", "")
            confidence = float(edge_data.get("confidence", 1.0))
            
            if from_id and to_id:
                edge = GraphEdge(
                    from_id, to_id, from_name, to_name,
                    edge_type, explanation, confidence,
                    edge_data.get("metadata", {})
                )
                self.edges.append(edge)
                self.adjacency[from_id].append(edge)
                self.reverse_adjacency[to_id].append(edge)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∞
        if "metadata" in graph_data:
            self.metadata.update(graph_data["metadata"])
        
        logger.debug(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ωo: {len(graph_data.get('nodes', []))} —É–∑–ª–æ–≤, "
                    f"{len(graph_data.get('edges', []))} —Å–≤—è–∑–µ–π –∏–∑ {graph_path.name}")
    
    def find_node(self, name: str) -> Optional[GraphNode]:
        """
        –ù–∞–π—Ç–∏ —É–∑–µ–ª –ø–æ –∏–º–µ–Ω–∏ (case-insensitive).
        """
        if not self._is_loaded:
            self.load_graphs_from_all_documents()
        
        name_lower = name.lower()
        
        # –ü—Ä—è–º–æ–π –ø–æ–∏—Å–∫
        if name_lower in self.node_by_name:
            return self.node_by_name[name_lower]
        
        # –ü–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é
        for node_name, node in self.node_by_name.items():
            if name_lower in node_name or node_name in name_lower:
                return node
        
        logger.debug(f"‚ö†Ô∏è –£–∑–µ–ª '{name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return None
    
    def find_node_by_id(self, node_id: str) -> Optional[GraphNode]:
        """–ù–∞–π—Ç–∏ —É–∑–µ–ª –ø–æ ID"""
        if not self._is_loaded:
            self.load_graphs_from_all_documents()
        
        return self.nodes.get(node_id)
    
    def get_related(
        self,
        node_id: str,
        edge_types: List[str] = None,
        direction: str = "both"
    ) -> List[Tuple[GraphNode, GraphEdge]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–≤—è–∑–∏ —É–∑–ª–∞.
        
        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            node_id: ID —É–∑–ª–∞
            edge_types: –¢–∏–ø—ã —Å–≤—è–∑–µ–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞ (–µ—Å–ª–∏ None - –≤—Å–µ)
            direction: "outgoing" | "incoming" | "both"
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            –°–ø–∏—Å–æ–∫ (—É–∑–µ–ª, –≥—Ä–∞–Ω–∏—Ü–∞)
        """
        if not self._is_loaded:
            self.load_graphs_from_all_documents()
        
        results = []
        
        # –ò—Å—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏
        if direction in ["outgoing", "both"]:
            for edge in self.adjacency.get(node_id, []):
                if edge_types is None or edge.edge_type in edge_types:
                    target_node = self.nodes.get(edge.to_id)
                    if target_node:
                        results.append((target_node, edge))
        
        # –í—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏
        if direction in ["incoming", "both"]:
            for edge in self.reverse_adjacency.get(node_id, []):
                if edge_types is None or edge.edge_type in edge_types:
                    source_node = self.nodes.get(edge.from_id)
                    if source_node:
                        results.append((source_node, edge))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (confidence)
        results.sort(key=lambda x: x[1].confidence, reverse=True)
        
        logger.debug(f"üîó –ù–∞–π–¥–µ–Ω–æ {len(results)} —Å–≤—è–∑–µ–π –¥–ª—è —É–∑–ª–∞ {node_id}")
        return results
    
    def get_practices_for_concept(self, concept_name: str) -> List[Dict]:
        """
        –ù–∞–π—Ç–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è –∫–æ–Ω—Ü–µ–ø—Ç–∞.
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            List[Dict] —Å –∫–ª—é—á–∞–º–∏:
                - "practice_name": str
                - "type": "PRACTICE" | "TECHNIQUE" | "EXERCISE"
                - "edge_type": —Ç–∏–ø —Å–≤—è–∑–∏
                - "confidence": —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                - "explanation": –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        """
        if not self._is_loaded:
            self.load_graphs_from_all_documents()
        
        concept_node = self.find_node(concept_name)
        if not concept_node:
            logger.warning(f"‚ö†Ô∏è –ö–æ–Ω—Ü–µ–ø—Ç '{concept_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
        
        # –ò—â–µ–º –ø—Ä–∞–∫—Ç–∏–∫–∏ —á–µ—Ä–µ–∑ IS_PRACTICE_FOR, IS_TECHNIQUE_FOR, IS_EXERCISE_FOR
        practice_edge_types = [
            "IS_PRACTICE_FOR",
            "IS_TECHNIQUE_FOR",
            "IS_EXERCISE_FOR",
            "ENABLES",
            "REQUIRES"
        ]
        
        practices = []
        related = self.get_related(concept_node.node_id, edge_types=practice_edge_types)
        
        for node, edge in related:
            if node.node_type in ["PRACTICE", "TECHNIQUE", "EXERCISE"]:
                practices.append({
                    "practice_name": node.name,
                    "type": node.node_type,
                    "edge_type": edge.edge_type,
                    "confidence": edge.confidence,
                    "explanation": edge.explanation,
                    "node_id": node.node_id
                })
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(practices)} –ø—Ä–∞–∫—Ç–∏–∫ –¥–ª—è '{concept_name}'")
        return practices
    
    def get_chain(
        self,
        from_concept: str,
        to_concept: str,
        max_depth: int = 5
    ) -> Optional[List[Dict]]:
        """
        –ù–∞–π—Ç–∏ —Ü–µ–ø–æ—á–∫—É —Å–≤—è–∑–µ–π –æ—Ç –æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞ –∫ –¥—Ä—É–≥–æ–º—É (BFS).
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            List[Dict] –∏–ª–∏ None –µ—Å–ª–∏ –ø—É—Ç–∏ –Ω–µ—Ç
        """
        if not self._is_loaded:
            self.load_graphs_from_all_documents()
        
        from_node = self.find_node(from_concept)
        to_node = self.find_node(to_concept)
        
        if not from_node or not to_node:
            logger.warning(f"‚ö†Ô∏è –ö–æ–Ω—Ü–µ–ø—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return None
        
        # BFS –ø–æ–∏—Å–∫ –ø—É—Ç–∏
        queue = deque([(from_node.node_id, [from_node.node_id], [])])
        visited = {from_node.node_id}
        
        while queue:
            current_id, path, edges_list = queue.popleft()
            
            if len(path) > max_depth:
                continue
            
            if current_id == to_node.node_id:
                # –ù–∞—à–ª–∏ –ø—É—Ç—å!
                chain = []
                for i, node_id in enumerate(path):
                    node = self.nodes[node_id]
                    step = {
                        "step": i + 1,
                        "concept": node.name,
                        "type": node.node_type,
                        "node_id": node_id
                    }
                    
                    if i > 0 and edges_list:
                        step["relation"] = edges_list[i-1]
                    
                    chain.append(step)
                
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Ü–µ–ø–æ—á–∫–∞ –∏–∑ {len(chain)} —à–∞–≥–æ–≤: {from_concept} ‚Üí {to_concept}")
                return chain
            
            # –†–∞–∑–≤–∏–≤–∞–µ–º –ø–æ–∏—Å–∫
            for neighbor, edge in self.get_related(current_id, direction="outgoing"):
                if neighbor.node_id not in visited:
                    visited.add(neighbor.node_id)
                    queue.append(
                        (neighbor.node_id, path + [neighbor.node_id], edges_list + [edge.edge_type])
                    )
        
        logger.warning(f"‚ö†Ô∏è –¶–µ–ø–æ—á–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {from_concept} ‚Üí {to_concept}")
        return None
    
    def get_prerequisites_for_concept(self, concept_name: str) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ø–æ—Å—ã–ª–∫–∏ (—á—Ç–æ –Ω—É–∂–Ω–æ –∏–∑—É—á–∏—Ç—å –ø–µ—Ä–µ–¥ –∫–æ–Ω—Ü–µ–ø—Ç–æ–º).
        """
        if not self._is_loaded:
            self.load_graphs_from_all_documents()
        
        concept_node = self.find_node(concept_name)
        if not concept_node:
            return []
        
        prerequisites = []
        
        # –ò—â–µ–º –≤—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏ —Ç–∏–ø–∞ REQUIRES, NEEDS, PREREQUISITE
        related = self.get_related(
            concept_node.node_id,
            edge_types=["REQUIRES", "NEEDS", "PREREQUISITE"],
            direction="incoming"
        )
        
        for node, edge in related:
            prerequisites.append({
                "prerequisite": node.name,
                "type": node.node_type,
                "confidence": edge.confidence,
                "explanation": edge.explanation
            })
        
        return prerequisites
    
    def get_concept_hierarchy(self, concept_name: str, depth: int = 3) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—é –∫–æ–Ω—Ü–µ–ø—Ç–∞ (—á—Ç–æ –≤—Ö–æ–¥–∏—Ç –≤ –Ω–µ–≥–æ, —á—Ç–æ –æ–Ω –≤—Ö–æ–¥–∏—Ç).
        """
        if not self._is_loaded:
            self.load_graphs_from_all_documents()
        
        concept_node = self.find_node(concept_name)
        if not concept_node:
            return {"error": f"–ö–æ–Ω—Ü–µ–ø—Ç '{concept_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω"}
        
        return {
            "concept": concept_node.name,
            "type": concept_node.node_type,
            "parent_concepts": [
                {"name": n.name, "type": n.node_type, "confidence": e.confidence}
                for n, e in self.get_related(
                    concept_node.node_id,
                    edge_types=["IS_PART_OF", "IS_COMPONENT_OF"],
                    direction="incoming"
                )
            ],
            "child_concepts": [
                {"name": n.name, "type": n.node_type, "confidence": e.confidence}
                for n, e in self.get_related(
                    concept_node.node_id,
                    edge_types=["HAS_PART", "HAS_COMPONENT"],
                    direction="outgoing"
                )
            ],
            "related_concepts": [
                {"name": n.name, "type": n.node_type, "confidence": e.confidence}
                for n, e in self.get_related(
                    concept_node.node_id,
                    edge_types=["RELATED_TO"],
                    direction="both"
                )
            ]
        }
    
    def get_statistics(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≥—Ä–∞—Ñ–∞"""
        if not self._is_loaded:
            self.load_graphs_from_all_documents()
        
        node_types = defaultdict(int)
        for node in self.nodes.values():
            node_types[node.node_type] += 1
        
        edge_types = defaultdict(int)
        for edge in self.edges:
            edge_types[edge.edge_type] += 1
        
        confidence_stats = {
            "min": min((e.confidence for e in self.edges), default=0),
            "max": max((e.confidence for e in self.edges), default=1),
            "avg": sum(e.confidence for e in self.edges) / len(self.edges) if self.edges else 0
        }
        
        return {
            "total_nodes": len(self.nodes),
            "total_edges": len(self.edges),
            "node_types": dict(node_types),
            "edge_types": dict(edge_types),
            "confidence_statistics": confidence_stats,
            "metadata": self.metadata
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç–∞–Ω—Å
graph_client = KnowledgeGraphClient()
```


***

## –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ `bot_agent/practices_recommender.py`

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `voice_bot_pipeline/bot_agent/practices_recommender.py`:

```python
# bot_agent/practices_recommender.py

import logging
from typing import List, Dict, Optional

from graph_client import graph_client
from data_loader import data_loader, Block

logger = logging.getLogger(__name__)


class PracticesRecommender:
    """
    –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –ø—Ä–∞–∫—Ç–∏–∫–∏, —Ç–µ—Ö–Ω–∏–∫–∏, —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Knowledge Graph.
    """
    
    def __init__(self):
        graph_client.load_graphs_from_all_documents()
    
    def suggest_practices_for_concept(
        self,
        concept: str,
        limit: int = 5
    ) -> Dict:
        """
        –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è –∫–æ–Ω—Ü–µ–ø—Ç–∞.
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            {
                "concept": str,
                "practices": [
                    {
                        "name": str,
                        "type": str,
                        "confidence": float,
                        "explanation": str,
                        "source_blocks": List[Block]
                    }
                ]
            }
        """
        logger.info(f"üéØ –ò—â—É –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è –∫–æ–Ω—Ü–µ–ø—Ç–∞: '{concept}'")
        
        practices_from_graph = graph_client.get_practices_for_concept(concept)
        
        if not practices_from_graph:
            logger.warning(f"‚ö†Ô∏è –ü—Ä–∞–∫—Ç–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –≥—Ä–∞—Ñ–µ –¥–ª—è '{concept}'")
            return {
                "concept": concept,
                "practices": [],
                "error": "no_practices_found"
            }
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        practices_from_graph.sort(key=lambda p: p["confidence"], reverse=True)
        practices_from_graph = practices_from_graph[:limit]
        
        # –ù–∞—Ö–æ–¥–∏–º –±–ª–æ–∫–∏, –≥–¥–µ —ç—Ç–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è
        all_blocks = data_loader.get_all_blocks()
        
        result_practices = []
        
        for practice_info in practices_from_graph:
            practice_name = practice_info["practice_name"]
            
            # –ò—â–µ–º –±–ª–æ–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —ç—Ç—É –ø—Ä–∞–∫—Ç–∏–∫—É
            relevant_blocks = [
                b for b in all_blocks
                if practice_name.lower() in [e.lower() for e in b.graph_entities]
            ]
            
            result_practices.append({
                "name": practice_name,
                "type": practice_info["type"],
                "confidence": practice_info["confidence"],
                "explanation": practice_info["explanation"],
                "source_blocks": [
                    {
                        "block_id": b.block_id,
                        "title": b.title,
                        "youtube_link": b.youtube_link,
                        "start": b.start,
                        "end": b.end
                    }
                    for b in relevant_blocks[:2]  # –º–∞–∫—Å 2 –±–ª–æ–∫–∞ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫—É
                ]
            })
        
        logger.info(f"‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ {len(result_practices)} –ø—Ä–∞–∫—Ç–∏–∫ –¥–ª—è '{concept}'")
        
        return {
            "concept": concept,
            "practices": result_practices
        }
    
    def get_learning_path(
        self,
        target_concept: str,
        start_concept: Optional[str] = None
    ) -> Dict:
        """
        –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—É—Ç—å –æ–±—É—á–µ–Ω–∏—è –æ—Ç —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞ –∫ —Ü–µ–ª–µ–≤–æ–º—É.
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            {
                "path": [
                    {
                        "step": int,
                        "concept": str,
                        "practices": List[str],
                        "duration": Optional[str]
                    }
                ]
            }
        """
        logger.info(f"üõ§Ô∏è –°—Ç—Ä–æ—é –ø—É—Ç—å –æ–±—É—á–µ–Ω–∏—è –∫ '{target_concept}'")
        
        if start_concept:
            chain = graph_client.get_chain(start_concept, target_concept)
        else:
            # –ï—Å–ª–∏ —Å—Ç–∞—Ä—Ç–æ–≤–æ–π –Ω–µ—Ç, –ø—Ä–æ—Å—Ç–æ –ø–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—Å—ã–ª–∫–∏
            chain = None
        
        if not chain:
            logger.warning("‚ö†Ô∏è –¶–µ–ø–æ—á–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å—Ç—Ä–æ—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–ø–æ—Å—ã–ª–æ–∫")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—Å—ã–ª–∫–∏ —Ü–µ–ª–µ–≤–æ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞
            prerequisites = graph_client.get_prerequisites_for_concept(target_concept)
            
            if prerequisites:
                path = []
                for i, prereq in enumerate(prerequisites, 1):
                    practices = graph_client.get_practices_for_concept(prereq["prerequisite"])
                    path.append({
                        "step": i,
                        "concept": prereq["prerequisite"],
                        "practices": [p["practice_name"] for p in practices[:3]],
                        "required": True
                    })
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ü–µ–ª–µ–≤–æ–π –∫–æ–Ω—Ü–µ–ø—Ç
                target_practices = graph_client.get_practices_for_concept(target_concept)
                path.append({
                    "step": len(path) + 1,
                    "concept": target_concept,
                    "practices": [p["practice_name"] for p in target_practices[:3]],
                    "required": False
                })
                
                return {"path": path}
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—É—é —Ü–µ–ø–æ—á–∫—É
            path = []
            for i, step in enumerate(chain, 1):
                practices = graph_client.get_practices_for_concept(step["concept"])
                path.append({
                    "step": i,
                    "concept": step["concept"],
                    "type": step["type"],
                    "practices": [p["practice_name"] for p in practices[:2]]
                })
            
            return {"path": path}
        
        return {"path": [], "error": "no_path_found"}
    
    def get_practice_details(self, practice_name: str) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∞–∫—Ç–∏–∫–µ.
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            {
                "name": str,
                "description": str,
                "steps": List[str],
                "duration": str,
                "source_blocks": List[Dict]
            }
        """
        logger.info(f"üìñ –ü–æ–ª—É—á–∞—é –¥–µ—Ç–∞–ª–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏: '{practice_name}'")
        
        all_blocks = data_loader.get_all_blocks()
        
        # –ò—â–µ–º –±–ª–æ–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –æ–ø–∏—Å–∞–Ω–∏–µ —ç—Ç–æ–π –ø—Ä–∞–∫—Ç–∏–∫–∏
        relevant_blocks = [
            b for b in all_blocks
            if practice_name.lower() in [e.lower() for e in b.graph_entities]
        ]
        
        if not relevant_blocks:
            return {"error": f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–∞–∫—Ç–∏–∫–µ '{practice_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –±–ª–æ–∫ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        main_block = relevant_blocks[0]
        
        return {
            "name": practice_name,
            "description": main_block.summary,
            "full_content": main_block.content,
            "source_blocks": [
                {
                    "title": b.title,
                    "youtube_link": b.youtube_link,
                    "start": b.start,
                    "end": b.end,
                    "block_id": b.block_id
                }
                for b in relevant_blocks
            ]
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç–∞–Ω—Å
practices_recommender = PracticesRecommender()
```


***

## –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ `bot_agent/answer_graph_powered.py`

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `voice_bot_pipeline/bot_agent/answer_graph_powered.py`:

```python
# bot_agent/answer_graph_powered.py

import logging
from typing import Dict, Optional
from datetime import datetime

from data_loader import data_loader
from retriever import get_retriever
from llm_answerer import LLMAnswerer
from user_level_adapter import UserLevelAdapter
from semantic_analyzer import SemanticAnalyzer
from graph_client import graph_client
from practices_recommender import practices_recommender
from config import config

logger = logging.getLogger(__name__)


def answer_question_graph_powered(
    query: str,
    user_level: str = "beginner",
    include_practices: bool = True,
    include_chain: bool = True,
    debug: bool = False
) -> Dict:
    """
    Phase 3: QA —Å –ø–æ–ª–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Knowledge Graph.
    
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        query (str): –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        user_level (str): –£—Ä–æ–≤–µ–Ω—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        include_practices (bool): –í–∫–ª—é—á–∞—Ç—å –ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø—Ä–∞–∫—Ç–∏–∫.
        include_chain (bool): –í–∫–ª—é—á–∞—Ç—å –ª–∏ —Ü–µ–ø–æ—á–∫–∏ —Å–≤—è–∑–µ–π.
        debug (bool): –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        Dict —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏:
            - "status": "success" | "error" | "partial"
            - "answer": str
            - "sources": List[Dict]
            - "concepts": List[str]
            - "relations": List[Dict]
            - "practices": List[Dict] ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏
            - "concept_hierarchy": Dict ‚Äî –∏–µ—Ä–∞—Ä—Ö–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
            - "learning_path": Optional[List] ‚Äî –ø—É—Ç—å –æ–±—É—á–µ–Ω–∏—è
            - "metadata": Dict
            - "debug": Optional[Dict]
    """
    
    logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ (Phase 3): '{query}'")
    
    start_time = datetime.now()
    debug_info = {} if debug else None
    
    try:
        # === –≠–¢–ê–ü 1: –ë–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–∫–∞–∫ –≤ Phase 2) ===
        logger.debug("üîß –≠—Ç–∞–ø 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...")
        
        data_loader.load_all_data()
        level_adapter = UserLevelAdapter(user_level)
        semantic_analyzer = SemanticAnalyzer()
        
        # === –≠–¢–ê–ü 2: –ü–æ–∏—Å–∫ –±–ª–æ–∫–æ–≤ ===
        logger.debug("üîç –≠—Ç–∞–ø 2: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤...")
        retriever = get_retriever(use_chromadb=False)
        retrieved_blocks = retriever.retrieve(query, top_k=config.TOP_K_BLOCKS)
        
        if not retrieved_blocks:
            return {
                "status": "partial",
                "answer": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –º–∞—Ç–µ—Ä–∏–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.",
                "sources": [],
                "concepts": [],
                "relations": [],
                "practices": [],
                "concept_hierarchy": {},
                "learning_path": None,
                "metadata": {"blocks_used": 0},
                "timestamp": datetime.now().isoformat(),
                "processing_time_seconds": (datetime.now() - start_time).total_seconds(),
                "debug": debug_info
            }
        
        blocks = [block for block, score in retrieved_blocks]
        adapted_blocks = level_adapter.filter_blocks_by_level(blocks)
        semantic_data = semantic_analyzer.analyze_relations(adapted_blocks)
        
        # === –≠–¢–ê–ü 3: –ó–∞–≥—Ä—É–∑–∫–∞ Knowledge Graph ===
        logger.debug("üß† –≠—Ç–∞–ø 3: –ó–∞–≥—Ä—É–∑–∫–∞ Knowledge Graph...")
        graph_client.load_graphs_from_all_documents()
        
        if debug_info is not None:
            graph_stats = graph_client.get_statistics()
            debug_info["graph_stats"] = {
                "total_nodes": graph_stats["total_nodes"],
                "total_edges": graph_stats["total_edges"]
            }
        
        # === –≠–¢–ê–ü 4: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ ===
        logger.debug("üîó –≠—Ç–∞–ø 4: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ...")
        
        primary_concepts = semantic_data["primary_concepts"]
        concept_hierarchies = {}
        
        for concept in primary_concepts:
            hierarchy = graph_client.get_concept_hierarchy(concept)
            if "error" not in hierarchy:
                concept_hierarchies[concept] = hierarchy
        
        if debug_info is not None:
            debug_info["graph_analysis"] = {
                "concepts_analyzed": len(concept_hierarchies),
                "hierarchies_found": len([h for h in concept_hierarchies.values() if "parent_concepts" in h])
            }
        
        # === –≠–¢–ê–ü 5: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ ===
        logger.debug("ü§ñ –≠—Ç–∞–ø 5: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞...")
        
        answerer = LLMAnswerer()
        base_prompt = answerer.build_system_prompt()
        adapted_prompt = level_adapter.adapt_system_prompt(base_prompt)
        
        # –û–±–æ–≥–∞—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏–∑ –≥—Ä–∞—Ñ–∞
        context = answerer.build_context_prompt(adapted_blocks, query)
        
        if concept_hierarchies:
            context += "\n\nüß† –°–¢–†–£–ö–¢–£–†–ê –ö–û–ù–¶–ï–ü–¢–û–í (–∏–∑ Knowledge Graph):\n"
            for concept, hierarchy in list(concept_hierarchies.items())[:3]:
                if hierarchy.get("parent_concepts"):
                    context += f"\n{concept} —Ç—Ä–µ–±—É–µ—Ç: {', '.join(p['name'] for p in hierarchy['parent_concepts'][:3])}"
                if hierarchy.get("related_concepts"):
                    context += f"\n{concept} —Å–≤—è–∑–∞–Ω —Å: {', '.join(p['name'] for p in hierarchy['related_concepts'][:3])}"
        
        llm_result = answerer.generate_answer(query, adapted_blocks)
        
        if llm_result.get("error"):
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM: {llm_result['error']}")
            return {
                "status": "error",
                "answer": llm_result.get("answer"),
                "sources": [],
                "concepts": primary_concepts,
                "relations": [],
                "practices": [],
                "concept_hierarchy": {},
                "learning_path": None,
                "metadata": {"error": llm_result.get("error")},
                "timestamp": datetime.now().isoformat(),
                "processing_time_seconds": (datetime.now() - start_time).total_seconds(),
                "debug": debug_info
            }
        
        # === –≠–¢–ê–ü 6: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—Ä–∞–∫—Ç–∏–∫ ===
        logger.debug("üéØ –≠—Ç–∞–ø 6: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—Ä–∞–∫—Ç–∏–∫...")
        
        practices = []
        if include_practices and primary_concepts:
            main_concept = primary_concepts[0]
            practices_rec = practices_recommender.suggest_practices_for_concept(main_concept, limit=3)
            practices = practices_rec.get("practices", [])
        
        # === –≠–¢–ê–ü 7: –¶–µ–ø–æ—á–∫–∏ —Å–≤—è–∑–µ–π ===
        logger.debug("‚õìÔ∏è –≠—Ç–∞–ø 7: –ê–Ω–∞–ª–∏–∑ —Ü–µ–ø–æ—á–µ–∫...")
        
        learning_path = None
        if include_chain and len(primary_concepts) >= 2:
            path_rec = practices_recommender.get_learning_path(
                primary_concepts[0],
                primary_concepts[1] if len(primary_concepts) > 1 else None
            )
            learning_path = path_rec.get("path")
        
        # === –≠–¢–ê–ü 8: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ===
        logger.debug("üìù –≠—Ç–∞–ø 8: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
        
        answer = llm_result["answer"]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∞–∫—Ç–∏–∫–∞—Ö
        if practices:
            answer += "\n\nüí™ **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏:**\n"
            for practice in practices[:3]:
                answer += f"- {practice['name']} ({practice['type']}) ‚Äî {practice['explanation']}\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ü–µ–ø—Ç—ã
        concepts_section = level_adapter.format_concepts_for_output(primary_concepts)
        if concepts_section:
            answer += concepts_section
        
        sources = [
            {
                "block_id": b.block_id,
                "title": b.title,
                "document_title": b.document_title,
                "youtube_link": b.youtube_link,
                "start": b.start,
                "end": b.end,
                "video_id": b.video_id,
                "block_type": b.block_type,
                "complexity_score": b.complexity_score
            }
            for b in adapted_blocks
        ]
        
        elapsed_time = (datetime.now() - start_time).total_seconds()
        
        result = {
            "status": "success",
            "answer": answer,
            "sources": sources,
            "concepts": primary_concepts,
            "relations": semantic_data["conceptual_links"],
            "practices": practices,
            "concept_hierarchy": concept_hierarchies,
            "learning_path": learning_path,
            "metadata": {
                "user_level": user_level,
                "blocks_used": len(adapted_blocks),
                "concepts_found": len(primary_concepts),
                "practices_recommended": len(practices),
                "chain_depth": len(learning_path) if learning_path else 0
            },
            "timestamp": datetime.now().isoformat(),
            "processing_time_seconds": round(elapsed_time, 2)
        }
        
        if debug_info is not None:
            debug_info["total_time"] = elapsed_time
            result["debug"] = debug_info
        
        logger.info(f"‚úÖ –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {elapsed_time:.2f}—Å (Phase 3)")
        
        return result
    
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}", exc_info=True)
        return {
            "status": "error",
            "answer": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}",
            "sources": [],
            "concepts": [],
            "relations": [],
            "practices": [],
            "concept_hierarchy": {},
            "learning_path": None,
            "metadata": {"error": str(e)},
            "timestamp": datetime.now().isoformat(),
            "processing_time_seconds": (datetime.now() - start_time).total_seconds(),
            "debug": debug_info
        }
```


***

## –®–∞–≥ 4: –û–±–Ω–æ–≤–∏—Ç—å `bot_agent/__init__.py`

```python
# bot_agent/__init__.py

import logging
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent))

LOG_DIR = Path(__file__).parent.parent / "logs" / "bot_agent"
LOG_DIR.mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(name)s | %(levelname)s | %(message)s",
    handlers=[
        logging.FileHandler(LOG_DIR / "bot_agent.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger("bot_agent")

# Phase 1
from answer_basic import answer_question_basic, ask

# Phase 2
from answer_sag_aware import answer_question_sag_aware

# Phase 3
from answer_graph_powered import answer_question_graph_powered

__all__ = [
    "answer_question_basic",
    "ask",
    "answer_question_sag_aware",
    "answer_question_graph_powered"
]

logger.info("üöÄ Bot Agent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (Phase 1 + Phase 2 + Phase 3)")
```


***

## –®–∞–≥ 5: –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ `test_phase3.py`

```python
# test_phase3.py
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Phase 3 - Graph Powered QA
"""

import sys
from pathlib import Path
import json

sys.path.insert(0, str(Path(__file__).parent / "bot_agent"))

from answer_graph_powered import answer_question_graph_powered

print("=" * 90)
print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï PHASE 3 - KNOWLEDGE GRAPH POWERED QA –ë–û–¢")
print("=" * 90)

test_queries = [
    ("–ß—Ç–æ —Ç–∞–∫–æ–µ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ?", "beginner", True, True),
    ("–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ?", "intermediate", True, True),
    ("–ö–∞–∫–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –ø–æ–º–æ–≥–∞—é—Ç –≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–æ–∑–Ω–∞–Ω–∏—è?", "advanced", True, True),
]

for i, (query, level, with_practices, with_chain) in enumerate(test_queries, 1):
    print(f"\n{'='*90}")
    print(f"–¢–ï–°–¢ {i}/{len(test_queries)}")
    print(f"{'='*90}")
    print(f"\nüìã –í–æ–ø—Ä–æ—Å: {query}")
    print(f"üìä –£—Ä–æ–≤–µ–Ω—å: {level}\n")
    
    try:
        result = answer_question_graph_powered(
            query,
            user_level=level,
            include_practices=with_practices,
            include_chain=with_chain,
            debug=True
        )
        
        print(f"Status: {result['status']}")
        print(f"Processing time: {result['processing_time_seconds']}s")
        print(f"Metadata: {json.dumps(result['metadata'], indent=2)}")
        
        print(f"\nüí¨ –û–¢–í–ï–¢:\n{result['answer']}")
        
        if result.get('concepts'):
            print(f"\nüîë –ö–û–ù–¶–ï–ü–¢–´ ({len(result['concepts'])}):")
            for concept in result['concepts']:
                print(f"  ‚Ä¢ {concept}")
        
        if result.get('practices'):
            print(f"\nüí™ –ü–†–ê–ö–¢–ò–ö–ò ({len(result['practices'])}):")
            for practice in result['practices'][:3]:
                print(f"  ‚Ä¢ {practice['name']} ({practice['type']})")
                if practice.get('source_blocks'):
                    print(f"    –ò—Å—Ç–æ—á–Ω–∏–∫: {practice['source_blocks'][0]['youtube_link']}")
        
        if result.get('learning_path'):
            print(f"\nüõ§Ô∏è –ü–£–¢–¨ –û–ë–£–ß–ï–ù–ò–Ø ({len(result['learning_path'])} —à–∞–≥–æ–≤):")
            for step in result['learning_path'][:5]:
                print(f"  {step['step']}. {step['concept']}")
                if step.get('practices'):
                    print(f"     –ü—Ä–∞–∫—Ç–∏–∫–∏: {', '.join(step['practices'][:2])}")
        
        if result.get('concept_hierarchy'):
            print(f"\nüìä –ò–ï–†–ê–†–•–ò–Ø –ö–û–ù–¶–ï–ü–¢–û–í:")
            for concept, hierarchy in list(result['concept_hierarchy'].items())[:2]:
                print(f"  {concept}:")
                if hierarchy.get('parent_concepts'):
                    parents = [p['name'] for p in hierarchy['parent_concepts'][:2]]
                    print(f"    ‚Üê {', '.join(parents)}")
                if hierarchy.get('related_concepts'):
                    related = [p['name'] for p in hierarchy['related_concepts'][:2]]
                    print(f"    ‚Üî {', '.join(related)}")
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

print("\n" + "=" * 90)
print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –§–ê–ó–´ 3 –ó–ê–í–ï–†–®–ï–ù–û")
print("=" * 90)
```


***

## –®–∞–≥ 6: –ó–∞–ø—É—Å–∫ Phase 3

```bash
# –£–±–µ–¥–∏—Å—å, —á—Ç–æ —Ñ–∞–∑—ã 1 –∏ 2 —Ä–∞–±–æ—Ç–∞—é—Ç
python test_phase1.py
python test_phase2.py

# –ó–∞–ø—É—Å—Ç–∏ —Ñ–∞–∑—É 3
python test_phase3.py
```


***

## üéØ –ß–µ–∫-–ª–∏—Å—Ç Phase 3

- [ ] –°–æ–∑–¥–∞–Ω `graph_client.py` —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Knowledge Graph
- [ ] –°–æ–∑–¥–∞–Ω `practices_recommender.py` –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø—Ä–∞–∫—Ç–∏–∫
- [ ] –°–æ–∑–¥–∞–Ω `answer_graph_powered.py` –¥–ª—è Phase 3
- [ ] –û–±–Ω–æ–≤–ª–µ–Ω `__init__.py` —Å –Ω–æ–≤—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏
- [ ] –°–æ–∑–¥–∞–Ω `test_phase3.py`
- [ ] –ì—Ä–∞—Ñ—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è
- [ ] –ü—Ä–∞–∫—Ç–∏–∫–∏ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç—Å—è
- [ ] –¶–µ–ø–æ—á–∫–∏ —Å–≤—è–∑–µ–π —Å—Ç—Ä–æ—è—Ç—Å—è
- [ ] –ò–µ—Ä–∞—Ä—Ö–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ

***

## ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç Phase 3

‚úÖ –ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Knowledge Graph
‚úÖ –ü–æ–∏—Å–∫ –ø—Ä–∞–∫—Ç–∏–∫ –¥–ª—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
‚úÖ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ü–µ–ø–æ—á–µ–∫ –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏
‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø—É—Ç–µ–π –æ–±—É—á–µ–Ω–∏—è
‚úÖ –ò–µ—Ä–∞—Ä—Ö–∏—è –∏ —Å–≤—è–∑–∏ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
‚úÖ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ "–ø–æ—á–µ–º—É —Ç–∞–∫" —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ë–æ—Ç –ø—Ä–µ–≤—Ä–∞—Ç–∏–ª—Å—è –≤ **–ø–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏** üöÄ

