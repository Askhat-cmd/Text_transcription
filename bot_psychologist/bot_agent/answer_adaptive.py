# bot_agent/answer_adaptive.py
"""
Adaptive Answer Module - Phase 4
================================

–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Phase 4: answer_question_adaptive.

–†–∞—Å—à–∏—Ä—è–µ—Ç Phase 3 –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–º —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (10 —Å–æ—Å—Ç–æ—è–Ω–∏–π)
- –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
- –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é
- –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
"""

import logging
from typing import Dict, Optional
from datetime import datetime

from .data_loader import data_loader
from .retriever import get_retriever
from .llm_answerer import LLMAnswerer
from .user_level_adapter import UserLevelAdapter, UserLevel
from .semantic_analyzer import SemanticAnalyzer
from .graph_client import graph_client
from .state_classifier import state_classifier, StateAnalysis, UserState
from .conversation_memory import get_conversation_memory
from .path_builder import path_builder
from .config import config

logger = logging.getLogger(__name__)


def answer_question_adaptive(
    query: str,
    user_id: str = "default",
    user_level: str = "beginner",
    include_path_recommendation: bool = True,
    include_feedback_prompt: bool = True,
    top_k: Optional[int] = None,
    debug: bool = False
) -> Dict:
    """
    Phase 4: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π QA —Å —É—á–µ—Ç–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    
    –≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:
        1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        2. –ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        3. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤
        4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
        5. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø—É—Ç–∏
        6. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ø–∞–º—è—Ç—å
    
    Args:
        query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è –ø–∞–º—è—Ç–∏)
        user_level: –£—Ä–æ–≤–µ–Ω—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (beginner/intermediate/advanced)
        include_path_recommendation: –í–∫–ª—é—á–∞—Ç—å –ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø—É—Ç–∏
        include_feedback_prompt: –ó–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å –ª–∏ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
        debug: –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    
    Returns:
        Dict —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏ Phase 4:
            - status: "success" | "error" | "partial"
            - answer: str ‚Äî –æ—Ç–≤–µ—Ç
            - state_analysis: Dict ‚Äî –∞–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            - path_recommendation: Optional[Dict] ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø—É—Ç—å
            - conversation_context: str ‚Äî –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å—Ç–æ—Ä–∏–∏
            - feedback_prompt: str ‚Äî –∑–∞–ø—Ä–æ—Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
            - sources: List[Dict]
            - concepts: List[str]
            - metadata: Dict
            - timestamp: str
            - processing_time_seconds: float
            - debug: Optional[Dict]
    """
    
    logger.info(f"üéØ Phase 4: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è {user_id} | '{query[:50]}...'")
    
    top_k = top_k or config.TOP_K_BLOCKS
    start_time = datetime.now()
    debug_info = {} if debug else None
    
    try:
        # ================================================================
        # –≠–¢–ê–ü 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–∞–º—è—Ç–∏
        # ================================================================
        logger.debug("üìö –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–∞–º—è—Ç–∏...")
        
        data_loader.load_all_data()
        memory = get_conversation_memory(user_id)
        conversation_context = memory.get_context_for_llm(
            n=config.CONVERSATION_HISTORY_DEPTH,
            max_chars=config.MAX_CONTEXT_SIZE
        )
        
        # –ü–∞—Ä—Å–∏–º —É—Ä–æ–≤–µ–Ω—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        try:
            level_enum = UserLevel(user_level.lower())
        except ValueError:
            level_enum = UserLevel.BEGINNER
        
        level_adapter = UserLevelAdapter(user_level)
        
        if debug_info is not None:
            debug_info["user_id"] = user_id
            debug_info["memory_turns"] = len(memory.turns)
        
        # ================================================================
        # –≠–¢–ê–ü 2: –ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        # ================================================================
        logger.debug("üéØ –≠—Ç–∞–ø 2: –ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è...")
        
        # –ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
        conversation_history = [
            {"role": "user", "content": turn.user_input}
            for turn in memory.get_last_turns(config.CONVERSATION_HISTORY_DEPTH)
        ]
        
        state_analysis = state_classifier.analyze_message(
            query,
            conversation_history=conversation_history
        )
        
        logger.info(f"‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ: {state_analysis.primary_state.value} "
                   f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {state_analysis.confidence:.2f})")
        
        if debug_info is not None:
            debug_info["state_analysis"] = {
                "primary": state_analysis.primary_state.value,
                "confidence": state_analysis.confidence,
                "secondary": [s.value for s in state_analysis.secondary_states],
                "emotional_tone": state_analysis.emotional_tone,
                "depth": state_analysis.depth
            }
        
        # ================================================================
        # –≠–¢–ê–ü 3: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤
        # ================================================================
        logger.debug("üîç –≠—Ç–∞–ø 3: –ü–æ–∏—Å–∫ –±–ª–æ–∫–æ–≤...")
        
        retriever = get_retriever()
        retrieved_blocks = retriever.retrieve(query, top_k=top_k)
        
        if not retrieved_blocks:
            response = _build_partial_response(
                "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.",
                state_analysis,
                memory,
                start_time
            )
            memory.add_turn(
                user_input=query,
                bot_response=response.get("answer", ""),
                user_state=state_analysis.primary_state.value if state_analysis else None,
                blocks_used=0,
                concepts=[]
            )
            return response
        
        blocks = [block for block, score in retrieved_blocks]
        adapted_blocks = level_adapter.filter_blocks_by_level(blocks)
        
        if not adapted_blocks:
            adapted_blocks = blocks[:3]  # fallback
        
        if debug_info is not None:
            debug_info["blocks_found"] = len(retrieved_blocks)
            debug_info["blocks_after_filter"] = len(adapted_blocks)
        
        # ================================================================
        # –≠–¢–ê–ü 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
        # ================================================================
        logger.debug("ü§ñ –≠—Ç–∞–ø 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
        
        answerer = LLMAnswerer()
        base_prompt = answerer.build_system_prompt()
        adapted_prompt = level_adapter.adapt_system_prompt(base_prompt)
        
        # –î–æ–±–∞–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è
        state_context = f"""
–ö–û–ù–¢–ï–ö–°–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
- –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {state_analysis.primary_state.value}
- –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω: {state_analysis.emotional_tone}
- –ì–ª—É–±–∏–Ω–∞ –≤–æ–≤–ª–µ—á–µ–Ω–∏—è: {state_analysis.depth}

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø –ü–û –û–¢–í–ï–¢–£:
{state_analysis.recommendations[0] if state_analysis.recommendations else "–û—Ç–≤–µ—á–∞–π –≤ —Å–≤–æ—ë–º –æ–±—ã—á–Ω–æ–º —Å—Ç–∏–ª–µ"}

–ê–¥–∞–ø—Ç–∏—Ä—É–π —Å–≤–æ–π –æ—Ç–≤–µ—Ç –∫ —Å–æ—Å—Ç–æ—è–Ω–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
"""
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ (—Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞)
        final_system_prompt = f"{adapted_prompt}\n\n{state_context.strip()}"
        original_build_prompt = answerer.build_system_prompt
        answerer.build_system_prompt = lambda: final_system_prompt

        llm_result = answerer.generate_answer(
            query,
            adapted_blocks,
            conversation_history=conversation_context
        )
        answerer.build_system_prompt = original_build_prompt
        
        if llm_result.get("error") and llm_result["error"] not in ["no_blocks"]:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM: {llm_result['error']}")
            response = _build_error_response(
                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {llm_result['error']}",
                state_analysis,
                start_time
            )
            try:
                memory.add_turn(
                    user_input=query,
                    bot_response=response.get("answer", ""),
                    user_state=state_analysis.primary_state.value if state_analysis else None,
                    blocks_used=0,
                    concepts=[]
                )
            except Exception:
                pass
            return response
        
        answer = llm_result["answer"]
        
        # ================================================================
        # –≠–¢–ê–ü 5: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
        # ================================================================
        logger.debug("üî¨ –≠—Ç–∞–ø 5: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑...")
        
        semantic_analyzer = SemanticAnalyzer()
        semantic_data = semantic_analyzer.analyze_relations(adapted_blocks)
        concepts = semantic_data.get("primary_concepts", [])
        
        # ================================================================
        # –≠–¢–ê–ü 6: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—É—Ç–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        # ================================================================
        logger.debug("üõ§Ô∏è –≠—Ç–∞–ø 6: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—É—Ç–∏...")
        
        path_recommendation = None
        if include_path_recommendation and state_analysis.primary_state != UserState.INTEGRATED:
            try:
                personal_path = path_builder.build_path(
                    user_id=user_id,
                    state_analysis=state_analysis,
                    user_level=level_enum,
                    memory=memory
                )
                
                path_recommendation = {
                    "current_state": personal_path.current_state.value,
                    "target_state": personal_path.target_state.value,
                    "key_focus": personal_path.key_focus,
                    "steps_count": len(personal_path.path_steps),
                    "total_duration_weeks": personal_path.total_duration_weeks,
                    "adaptation_notes": personal_path.adaptation_notes,
                    "first_step": {
                        "title": personal_path.path_steps[0].title if personal_path.path_steps else "",
                        "duration_weeks": personal_path.path_steps[0].duration_weeks if personal_path.path_steps else 0,
                        "practices": personal_path.path_steps[0].practices[:3] if personal_path.path_steps else []
                    } if personal_path.path_steps else None
                }
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—É—Ç–∏: {e}")
                path_recommendation = None
        
        # ================================================================
        # –≠–¢–ê–ü 7: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        # ================================================================
        logger.debug("üìù –≠—Ç–∞–ø 7: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏...")
        
        feedback_prompt = ""
        if include_feedback_prompt:
            feedback_prompt = _get_feedback_prompt_for_state(state_analysis.primary_state)
        
        # ================================================================
        # –≠–¢–ê–ü 8: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ø–∞–º—è—Ç—å
        # ================================================================
        logger.debug("üíæ –≠—Ç–∞–ø 8: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ø–∞–º—è—Ç—å...")
        
        memory.add_turn(
            user_input=query,
            bot_response=answer,
            user_state=state_analysis.primary_state.value,
            blocks_used=len(adapted_blocks),
            concepts=concepts
        )
        
        # ================================================================
        # –§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢
        # ================================================================
        elapsed_time = (datetime.now() - start_time).total_seconds()
        
        sources = [
            {
                "block_id": b.block_id,
                "title": b.title,
                "document_title": b.document_title,
                "youtube_link": b.youtube_link,
                "start": b.start,
                "end": b.end,
                "block_type": getattr(b, 'block_type', 'unknown'),
                "complexity_score": getattr(b, 'complexity_score', 0)
            }
            for b in adapted_blocks
        ]
        
        result = {
            "status": "success",
            "answer": answer,
            "state_analysis": {
                "primary_state": state_analysis.primary_state.value,
                "confidence": state_analysis.confidence,
                "secondary_states": [s.value for s in state_analysis.secondary_states],
                "emotional_tone": state_analysis.emotional_tone,
                "depth": state_analysis.depth,
                "recommendations": state_analysis.recommendations
            },
            "path_recommendation": path_recommendation,
            "conversation_context": memory.get_context_for_llm(
                n=config.CONVERSATION_HISTORY_DEPTH,
                max_chars=config.MAX_CONTEXT_SIZE
            ),
            "feedback_prompt": feedback_prompt,
            "sources": sources,
            "concepts": concepts,
            "metadata": {
                "user_id": user_id,
                "user_level": user_level,
                "blocks_used": len(adapted_blocks),
                "state": state_analysis.primary_state.value,
                "conversation_turns": len(memory.turns)
            },
            "timestamp": datetime.now().isoformat(),
            "processing_time_seconds": round(elapsed_time, 2)
        }
        
        if debug_info is not None:
            debug_info["memory_summary"] = memory.get_summary()
            debug_info["total_time"] = elapsed_time
            debug_info["llm_tokens"] = llm_result.get("tokens_used", 0)
            result["debug"] = debug_info
        
        logger.info(f"‚úÖ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –≥–æ—Ç–æ–≤ –∑–∞ {elapsed_time:.2f}—Å")
        
        return result
    
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}", exc_info=True)
        response = {
            "status": "error",
            "answer": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}",
            "state_analysis": None,
            "path_recommendation": None,
            "conversation_context": "",
            "feedback_prompt": "",
            "sources": [],
            "concepts": [],
            "metadata": {"user_id": user_id, "user_level": user_level},
            "timestamp": datetime.now().isoformat(),
            "processing_time_seconds": (datetime.now() - start_time).total_seconds()
        }
        try:
            memory = get_conversation_memory(user_id)
            memory.add_turn(user_input=query, bot_response=response["answer"], blocks_used=0)
        except Exception:
            pass
        return response


def _get_feedback_prompt_for_state(state: UserState) -> str:
    """
    –ü–æ–ª—É—á–∏—Ç—å –∑–∞–ø—Ä–æ—Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è.
    """
    prompts = {
        UserState.UNAWARE: "–°—Ç–∞–ª–æ –ª–∏ –ø–æ–Ω—è—Ç–Ω–µ–µ, –æ —á—ë–º —Ä–µ—á—å? –ß—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å –Ω–µ–ø–æ–Ω—è—Ç–Ω—ã–º?",
        UserState.CURIOUS: "–•–æ—Ç–∏—Ç–µ —É–∑–Ω–∞—Ç—å —á—Ç–æ-—Ç–æ –µ—â—ë –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ?",
        UserState.OVERWHELMED: "–ù–µ —Å–ª–∏—à–∫–æ–º –ª–∏ –º–Ω–æ–≥–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏? –ù—É–∂–Ω–æ –ª–∏ —É–ø—Ä–æ—Å—Ç–∏—Ç—å?",
        UserState.RESISTANT: "–ï—Å—Ç—å –ª–∏ —á—Ç–æ-—Ç–æ, —Å —á–µ–º –≤—ã –Ω–µ —Å–æ–≥–ª–∞—Å–Ω—ã? –î–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º.",
        UserState.CONFUSED: "–ü—Ä–æ—è—Å–Ω–∏–ª–æ—Å—å –ª–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ? –ï—Å–ª–∏ –Ω–µ—Ç, –∫–∞–∫–∞—è —á–∞—Å—Ç—å –≤—Å—ë –µ—â—ë –Ω–µ–ø–æ–Ω—è—Ç–Ω–∞?",
        UserState.COMMITTED: "–ì–æ—Ç–æ–≤—ã –ª–∏ –≤—ã –Ω–∞—á–∞—Ç—å –ø—Ä–∞–∫—Ç–∏–∫—É? –ö–∞–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω—É–∂–Ω–∞?",
        UserState.PRACTICING: "–ö–∞–∫ –∏–¥—ë—Ç –ø—Ä–∞–∫—Ç–∏–∫–∞? –ï—Å—Ç—å –ª–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏?",
        UserState.STAGNANT: "–ß—Ç–æ, –ø–æ-–≤–∞—à–µ–º—É, –º–µ—à–∞–µ—Ç –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—é? –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥?",
        UserState.BREAKTHROUGH: "–ü–æ–∑–¥—Ä–∞–≤–ª—è—é —Å –∏–Ω—Å–∞–π—Ç–æ–º! –ö–∞–∫ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —ç—Ç–æ –ø–æ–Ω–∏–º–∞–Ω–∏–µ?",
        UserState.INTEGRATED: "–ö–∞–∫ —ç—Ç–æ –∑–Ω–∞–Ω–∏–µ –ø—Ä–æ—è–≤–ª—è–µ—Ç—Å—è –≤ –≤–∞—à–µ–π –∂–∏–∑–Ω–∏?"
    }
    
    return prompts.get(state, "–ë—ã–ª –ª–∏ —ç—Ç–æ—Ç –æ—Ç–≤–µ—Ç –ø–æ–ª–µ–∑–µ–Ω? –û—Ü–µ–Ω–∏—Ç–µ –æ—Ç 1 –¥–æ 5.")


def _build_partial_response(
    message: str,
    state_analysis: StateAnalysis,
    memory,
    start_time: datetime
) -> Dict:
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç (–Ω–µ—Ç –±–ª–æ–∫–æ–≤)"""
    return {
        "status": "partial",
        "answer": message,
        "state_analysis": {
            "primary_state": state_analysis.primary_state.value,
            "confidence": state_analysis.confidence,
            "emotional_tone": state_analysis.emotional_tone,
            "recommendations": state_analysis.recommendations
        } if state_analysis else None,
        "path_recommendation": None,
        "conversation_context": memory.get_context_for_llm(
            n=config.CONVERSATION_HISTORY_DEPTH,
            max_chars=config.MAX_CONTEXT_SIZE
        ) if memory else "",
        "feedback_prompt": "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.",
        "sources": [],
        "concepts": [],
        "metadata": {"conversation_turns": len(memory.turns) if memory else 0},
        "timestamp": datetime.now().isoformat(),
        "processing_time_seconds": (datetime.now() - start_time).total_seconds()
    }


def _build_error_response(
    message: str,
    state_analysis: StateAnalysis,
    start_time: datetime
) -> Dict:
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –æ—Ç–≤–µ—Ç —Å –æ—à–∏–±–∫–æ–π"""
    return {
        "status": "error",
        "answer": message,
        "state_analysis": {
            "primary_state": state_analysis.primary_state.value if state_analysis else "unknown",
            "confidence": state_analysis.confidence if state_analysis else 0
        } if state_analysis else None,
        "path_recommendation": None,
        "conversation_context": "",
        "feedback_prompt": "",
        "sources": [],
        "concepts": [],
        "metadata": {},
        "timestamp": datetime.now().isoformat(),
        "processing_time_seconds": (datetime.now() - start_time).total_seconds()
    }


