# bot_agent/answer_basic.py
"""
Basic QA Module - Phase 1
=========================

–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã: –ø–æ–∏—Å–∫ –±–ª–æ–∫–æ–≤ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM.
"""

import logging
from typing import Dict, List, Optional
from datetime import datetime

from .data_loader import data_loader, Block
from .retriever import get_retriever
from .config import config
from .conversation_memory import get_conversation_memory
from .decision import DecisionGate, detect_routing_signals, resolve_user_stage
from .retrieval import HybridQueryBuilder, VoyageReranker
from .response import ResponseFormatter, ResponseGenerator

logger = logging.getLogger(__name__)


def answer_question_basic(
    query: str,
    user_id: str = "default",
    top_k: Optional[int] = None,
    debug: bool = False,
    use_semantic_memory: bool = True
) -> Dict:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Phase 1: QA –ø–æ –ª–µ–∫—Ü–∏—è–º.
    
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –Ω–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –±–ª–æ–∫–∏,
    –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ LLM.
    
    Args:
        query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
        top_k: –°–∫–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ config)
        debug: –ï—Å–ª–∏ True, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    
    Returns:
        Dict —Å –∫–ª—é—á–∞–º–∏:
            - status: "success", "partial", –∏–ª–∏ "error"
            - answer: str ‚Äî –≥–æ—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            - sources: List[Dict] ‚Äî —Å–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            - blocks_used: int ‚Äî —Å–∫–æ–ª—å–∫–æ –±–ª–æ–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ
            - timestamp: str ‚Äî –∫–æ–≥–¥–∞ –±—ã–ª —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç
            - processing_time_seconds: float
            - debug: Optional[Dict] ‚Äî –æ—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    
    Example:
        >>> result = answer_question_basic("–ß—Ç–æ —Ç–∞–∫–æ–µ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ?")
        >>> print(result["answer"])
        >>> for src in result["sources"]:
        ...     print(f"  - {src['title']} ({src['youtube_link']})")
    """
    
    logger.info(f"üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: '{query[:50]}...' (user: {user_id})")
    
    top_k = top_k or config.TOP_K_BLOCKS
    start_time = datetime.now()
    debug_info = {} if debug else None
    
    try:
        # === –≠–¢–ê–ü 0: –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞–º—è—Ç–∏ –¥–∏–∞–ª–æ–≥–∞ ===
        memory = get_conversation_memory(user_id)

        if use_semantic_memory and (
            config.ENABLE_SEMANTIC_MEMORY or config.ENABLE_CONVERSATION_SUMMARY
        ):
            memory_context = memory.get_adaptive_context_for_llm(query)
            conversation_context = memory.format_context_for_llm(memory_context)
        else:
            conversation_context = memory.get_context_for_llm(
                n=config.CONVERSATION_HISTORY_DEPTH,
                max_chars=config.MAX_CONTEXT_SIZE
            )
            memory_context = {
                "short_term": conversation_context,
                "semantic": "",
                "summary": ""
            }

        if debug_info is not None:
            debug_info["memory_context_used"] = {
                "short_term_chars": len(memory_context.get("short_term", "")),
                "semantic_chars": len(memory_context.get("semantic", "")),
                "summary_chars": len(memory_context.get("summary", "")),
                "semantic_enabled": bool(use_semantic_memory and config.ENABLE_SEMANTIC_MEMORY),
                "summary_enabled": bool(use_semantic_memory and config.ENABLE_CONVERSATION_SUMMARY)
            }

        user_stage = resolve_user_stage(memory)

        # === –≠–¢–ê–ü 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
        logger.debug("üìÇ –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        data_loader.load_all_data()
        
        if not data_loader.get_all_blocks():
            response = {
                "status": "error",
                "answer": f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ª–µ–∫—Ü–∏–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –≤ {config.SAG_FINAL_DIR}",
                "sources": [],
                "blocks_used": 0,
                "error": "no_data",
                "timestamp": datetime.now().isoformat(),
                "processing_time_seconds": 0.0,
                "debug": {"error_detail": "data_loader returned empty blocks"} if debug else None
            }
            memory.add_turn(user_input=query, bot_response=response["answer"], blocks_used=0)
            return response
        
        if debug_info is not None:
            debug_info["data_loaded"] = {
                "total_documents": len(data_loader.get_all_documents()),
                "total_blocks": len(data_loader.get_all_blocks())
            }
        
        # === –≠–¢–ê–ü 2: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤ ===
        logger.debug("üîç –≠—Ç–∞–ø 2: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤...")
        query_builder = HybridQueryBuilder(max_chars=config.MAX_CONTEXT_SIZE + 1200)
        hybrid_query = query_builder.build_query(
            current_question=query,
            conversation_summary=memory.summary or "",
            working_state=memory.working_state,
            short_term_context=conversation_context,
        )
        retriever = get_retriever()
        retrieved_blocks = retriever.retrieve(hybrid_query, top_k=top_k)
        reranker = VoyageReranker(
            model=config.VOYAGE_MODEL,
            enabled=config.VOYAGE_ENABLED,
        )
        rerank_k = min(len(retrieved_blocks), max(1, min(top_k, config.VOYAGE_TOP_K)))
        if rerank_k > 0:
            reranked = reranker.rerank_pairs(query, retrieved_blocks, top_k=rerank_k)
            if reranked:
                retrieved_blocks = reranked

        decision_gate = DecisionGate()
        routing_signals = detect_routing_signals(query, retrieved_blocks)
        routing_result = decision_gate.route(routing_signals, user_stage=user_stage)

        stage_filtered_blocks = decision_gate.stage_filter.filter_retrieval_pairs(
            user_stage,
            retrieved_blocks,
        )
        block_cap = decision_gate.scorer.suggest_block_cap(
            len(stage_filtered_blocks),
            routing_result.confidence_level,
        )
        retrieved_blocks = stage_filtered_blocks[:block_cap]
        
        if not retrieved_blocks:
            logger.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –¥–ª—è: '{query}'")
            response = {
                "status": "partial",
                "answer": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à—ë–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ —Å–ø—Ä–æ—Å–∏—Ç—å —á—Ç–æ-—Ç–æ –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ.",
                "sources": [],
                "blocks_used": 0,
                "timestamp": datetime.now().isoformat(),
                "processing_time_seconds": (datetime.now() - start_time).total_seconds(),
                "debug": debug_info
            }
            memory.add_turn(user_input=query, bot_response=response["answer"], blocks_used=0)
            return response
        
        blocks = [block for block, score in retrieved_blocks]
        
        if debug_info is not None:
            debug_info["retrieval"] = {
                "query": query,
                "hybrid_query": hybrid_query,
                "blocks_found": len(blocks),
                "scores": [float(score) for block, score in retrieved_blocks],
                "voyage_enabled": bool(config.VOYAGE_ENABLED),
                "voyage_top_k": rerank_k,
                "stage_filter_applied": True,
                "confidence_block_cap": block_cap,
            }
            debug_info["routing"] = {
                "mode": routing_result.mode,
                "rule_id": routing_result.decision.rule_id,
                "reason": routing_result.decision.reason,
                "confidence_score": routing_result.confidence_score,
                "confidence_level": routing_result.confidence_level,
                "adjusted_by_stage": routing_result.adjusted_by_stage,
            }
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(blocks)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤")
        
        # === –≠–¢–ê–ü 3: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM ===
        logger.debug("ü§ñ –≠—Ç–∞–ø 3: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM...")
        response_generator = ResponseGenerator()
        llm_result = response_generator.generate(
            query,
            blocks,
            conversation_context=conversation_context,
            mode=routing_result.mode,
            confidence_level=routing_result.confidence_level,
            forbid=routing_result.decision.forbid,
            model=config.LLM_MODEL,
            temperature=config.LLM_TEMPERATURE,
            max_tokens=config.LLM_MAX_TOKENS,
        )
        
        if llm_result.get("error"):
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM: {llm_result['error']}")
            response = {
                "status": "error",
                "answer": llm_result.get("answer", "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞."),
                "sources": [],
                "blocks_used": 0,
                "error": llm_result.get("error"),
                "timestamp": datetime.now().isoformat(),
                "processing_time_seconds": (datetime.now() - start_time).total_seconds(),
                "debug": debug_info
            }
            memory.add_turn(user_input=query, bot_response=response["answer"], blocks_used=0)
            return response
        
        if debug_info is not None:
            debug_info["llm"] = {
                "model": llm_result.get("model_used"),
                "tokens_used": llm_result.get("tokens_used")
            }
        
        # === –≠–¢–ê–ü 4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ===
        logger.debug("üìù –≠—Ç–∞–ø 4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö...")
        sources = [
            {
                "block_id": b.block_id,
                "title": b.title,
                "summary": b.summary,
                "document_title": b.document_title,
                "youtube_link": b.youtube_link,
                "start": b.start,
                "end": b.end,
                "video_id": b.video_id
            }
            for b in blocks
        ]
        
        # === –§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢ ===
        elapsed_time = (datetime.now() - start_time).total_seconds()
        
        formatter = ResponseFormatter()
        formatted_answer = formatter.format_answer(
            llm_result["answer"],
            mode=routing_result.mode,
            confidence_level=routing_result.confidence_level,
        )

        result = {
            "status": "success",
            "answer": formatted_answer,
            "sources": sources,
            "blocks_used": len(blocks),
            "metadata": {
                "recommended_mode": routing_result.mode,
                "decision_rule_id": routing_result.decision.rule_id,
                "confidence_score": routing_result.confidence_score,
                "confidence_level": routing_result.confidence_level,
                "mode_reason": routing_result.decision.reason,
                "retrieval_block_cap": block_cap,
            },
            "timestamp": datetime.now().isoformat(),
            "processing_time_seconds": round(elapsed_time, 2)
        }

        memory.add_turn(
            user_input=query,
            bot_response=formatted_answer,
            blocks_used=len(blocks),
            concepts=[b.title for b in blocks]
        )
        
        if debug_info is not None:
            debug_info["total_time"] = elapsed_time
            result["debug"] = debug_info
        
        logger.info(f"‚úÖ –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {elapsed_time:.2f}—Å")
        
        return result
    
    except Exception as e:
        logger.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        response = {
            "status": "error",
            "answer": f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}",
            "sources": [],
            "blocks_used": 0,
            "error": str(e),
            "timestamp": datetime.now().isoformat(),
            "processing_time_seconds": (datetime.now() - start_time).total_seconds(),
            "debug": debug_info
        }
        try:
            memory = get_conversation_memory(user_id)
            memory.add_turn(user_input=query, bot_response=response["answer"], blocks_used=0)
        except Exception:
            pass
        return response


# === –ü–†–û–°–¢–û–ô –ò–ù–¢–ï–†–§–ï–ô–° –î–õ–Ø –ë–´–°–¢–†–û–ì–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø ===

def ask(query: str, verbose: bool = False) -> str:
    """
    –ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: –≤–æ–ø—Ä–æ—Å -> –æ—Ç–≤–µ—Ç (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç).
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–≥–¥–∞ –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞:
    
    Example:
        >>> print(ask("–ß—Ç–æ —Ç–∞–∫–æ–µ —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ?"))
        
        >>> # –° –≤—ã–≤–æ–¥–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
        >>> print(ask("–ß—Ç–æ —Ç–∞–∫–æ–µ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ?", verbose=True))
    """
    result = answer_question_basic(query, debug=verbose)
    
    if verbose and result.get("sources"):
        print(f"\n[üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏ ({len(result['sources'])} –±–ª–æ–∫–æ–≤)]")
        for src in result['sources']:
            print(f"  ‚Ä¢ {src['document_title']} ({src['start']}‚Äî{src['end']})")
            print(f"    ‚Üí {src['youtube_link']}")
    
    return result["answer"]



