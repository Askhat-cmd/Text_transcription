# bot_agent/answer_graph_powered.py
"""
Graph-Powered Answer Module - Phase 3
=====================================

–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Phase 3: answer_question_graph_powered.

–†–∞—Å—à–∏—Ä—è–µ—Ç Phase 2 –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Knowledge Graph:
- –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—Ä–∞–∫—Ç–∏–∫ –¥–ª—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—É—Ç–µ–π –æ–±—É—á–µ–Ω–∏—è
- –ò–µ—Ä–∞—Ä—Ö–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–≤—è–∑–µ–π —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
"""

import logging
from typing import Dict, Optional, List
from datetime import datetime

from .data_loader import data_loader, Block
from .retriever import get_retriever
from .llm_answerer import LLMAnswerer
from .user_level_adapter import UserLevelAdapter
from .semantic_analyzer import SemanticAnalyzer
from .graph_client import graph_client
from .practices_recommender import practices_recommender
from .config import config

logger = logging.getLogger(__name__)


def answer_question_graph_powered(
    query: str,
    user_level: str = "beginner",
    include_practices: bool = True,
    include_chain: bool = True,
    top_k: Optional[int] = None,
    debug: bool = False
) -> Dict:
    """
    Phase 3: QA —Å –ø–æ–ª–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Knowledge Graph.
    
    –≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:
        1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        2. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤
        3. –ó–∞–≥—Ä—É–∑–∫–∞ Knowledge Graph
        4. –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
        5. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM
        6. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—Ä–∞–∫—Ç–∏–∫
        7. –ê–Ω–∞–ª–∏–∑ —Ü–µ–ø–æ—á–µ–∫ (learning path)
        8. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    
    Args:
        query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_level: –£—Ä–æ–≤–µ–Ω—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (beginner/intermediate/advanced)
        include_practices: –í–∫–ª—é—á–∞—Ç—å –ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø—Ä–∞–∫—Ç–∏–∫
        include_chain: –í–∫–ª—é—á–∞—Ç—å –ª–∏ —Ü–µ–ø–æ—á–∫–∏ —Å–≤—è–∑–µ–π / learning path
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
        debug: –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    
    Returns:
        Dict —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏ Phase 3:
            - status: "success" | "error" | "partial"
            - answer: str ‚Äî –≥–æ—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
            - sources: List[Dict] ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            - concepts: List[str] ‚Äî –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ç—ã
            - relations: List[Dict] ‚Äî —Å–≤—è–∑–∏ –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏
            - practices: List[Dict] ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏
            - concept_hierarchy: Dict ‚Äî –∏–µ—Ä–∞—Ä—Ö–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
            - learning_path: Optional[List] ‚Äî –ø—É—Ç—å –æ–±—É—á–µ–Ω–∏—è
            - metadata: Dict ‚Äî –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            - timestamp: str ‚Äî –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            - processing_time_seconds: float
            - debug: Optional[Dict] ‚Äî –æ—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    """
    
    logger.info(f"üìä Phase 3: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ '{query[:50]}...' [Level: {user_level}]")
    
    top_k = top_k or config.TOP_K_BLOCKS
    start_time = datetime.now()
    debug_info = {} if debug else None
    
    try:
        # === –≠–¢–ê–ü 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ ===
        logger.debug("üîß –≠—Ç–∞–ø 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
        
        data_loader.load_all_data()
        level_adapter = UserLevelAdapter(user_level)
        semantic_analyzer = SemanticAnalyzer()
        
        if debug_info is not None:
            debug_info["user_level"] = user_level
            debug_info["top_k"] = top_k
            debug_info["include_practices"] = include_practices
            debug_info["include_chain"] = include_chain
        
        # === –≠–¢–ê–ü 2: –ü–æ–∏—Å–∫ –±–ª–æ–∫–æ–≤ ===
        logger.debug("üîç –≠—Ç–∞–ø 2: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤...")
        
        retriever = get_retriever()
        retrieved_blocks = retriever.retrieve(query, top_k=top_k)
        
        if debug_info is not None:
            debug_info["blocks_retrieved"] = len(retrieved_blocks)
        
        if not retrieved_blocks:
            elapsed = (datetime.now() - start_time).total_seconds()
            return _build_empty_response(
                query=query,
                user_level=user_level,
                reason="no_blocks_found",
                elapsed=elapsed,
                debug_info=debug_info
            )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–ª–æ–∫–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        blocks = [block for block, score in retrieved_blocks]
        
        if debug_info is not None:
            debug_info["block_scores"] = [
                {"block_id": b.block_id, "score": round(s, 3)} 
                for b, s in retrieved_blocks
            ]
        
        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ —É—Ä–æ–≤–Ω—é
        adapted_blocks = level_adapter.filter_blocks_by_level(blocks)
        
        # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (Phase 2)
        semantic_data = semantic_analyzer.analyze_relations(adapted_blocks)
        primary_concepts = semantic_data["primary_concepts"]
        
        if debug_info is not None:
            debug_info["blocks_after_level_filter"] = len(adapted_blocks)
            debug_info["primary_concepts"] = primary_concepts
        
        # === –≠–¢–ê–ü 3: –ó–∞–≥—Ä—É–∑–∫–∞ Knowledge Graph ===
        logger.debug("üß† –≠—Ç–∞–ø 3: –ó–∞–≥—Ä—É–∑–∫–∞ Knowledge Graph...")
        
        graph_client.load_graphs_from_all_documents()
        
        if debug_info is not None:
            graph_stats = graph_client.get_statistics()
            debug_info["graph_stats"] = {
                "total_nodes": graph_stats["total_nodes"],
                "total_edges": graph_stats["total_edges"],
                "loaded_files": graph_stats["loaded_files"]
            }
        
        # === –≠–¢–ê–ü 4: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ ===
        logger.debug("üîó –≠—Ç–∞–ø 4: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ —á–µ—Ä–µ–∑ Knowledge Graph...")
        
        concept_hierarchies = {}
        
        for concept in primary_concepts[:3]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–æ–ø-3 –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏
            hierarchy = graph_client.get_concept_hierarchy(concept)
            if "error" not in hierarchy:
                concept_hierarchies[concept] = hierarchy
        
        if debug_info is not None:
            debug_info["graph_analysis"] = {
                "concepts_analyzed": len(concept_hierarchies),
                "hierarchies_found": len([
                    h for h in concept_hierarchies.values() 
                    if h.get("parent_concepts") or h.get("related_concepts")
                ])
            }
        
        # === –≠–¢–ê–ü 5: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM ===
        logger.debug("ü§ñ –≠—Ç–∞–ø 5: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM...")
        
        answerer = LLMAnswerer()
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        base_system_prompt = answerer.build_system_prompt()
        adapted_system_prompt = level_adapter.adapt_system_prompt(base_system_prompt)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = answerer.build_context_prompt(adapted_blocks, query)
        
        # –û–±–æ–≥–∞—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏–∑ –≥—Ä–∞—Ñ–∞
        graph_context = _build_graph_context(concept_hierarchies)
        if graph_context:
            context += graph_context
        
        # –î–æ–±–∞–≤–ª—è–µ–º guidance –ø–æ –¥–ª–∏–Ω–µ
        length_guidance = level_adapter.get_answer_length_guidance()
        context += f"\n\n{length_guidance}"
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        original_build_prompt = answerer.build_system_prompt
        answerer.build_system_prompt = lambda: adapted_system_prompt
        
        llm_result = answerer.generate_answer(
            query,
            adapted_blocks,
            model=config.LLM_MODEL,
            temperature=config.LLM_TEMPERATURE,
            max_tokens=config.LLM_MAX_TOKENS
        )
        
        answerer.build_system_prompt = original_build_prompt
        
        if debug_info is not None:
            debug_info["llm_result"] = {
                "model_used": llm_result.get("model_used"),
                "tokens_used": llm_result.get("tokens_used"),
                "error": llm_result.get("error")
            }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—à–∏–±–∫–∏ LLM
        if llm_result.get("error") and llm_result.get("error") not in ["no_blocks"]:
            elapsed = (datetime.now() - start_time).total_seconds()
            return {
                "status": "error",
                "answer": llm_result.get("answer", "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞"),
                "sources": _format_sources(adapted_blocks),
                "concepts": primary_concepts,
                "relations": [],
                "practices": [],
                "concept_hierarchy": {},
                "learning_path": None,
                "metadata": {"error": llm_result.get("error")},
                "timestamp": datetime.now().isoformat(),
                "processing_time_seconds": round(elapsed, 2),
                "debug": debug_info
            }
        
        # === –≠–¢–ê–ü 6: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—Ä–∞–∫—Ç–∏–∫ ===
        logger.debug("üéØ –≠—Ç–∞–ø 6: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—Ä–∞–∫—Ç–∏–∫...")
        
        practices = []
        if include_practices and primary_concepts:
            main_concept = primary_concepts[0]
            practices_rec = practices_recommender.suggest_practices_for_concept(
                main_concept, 
                limit=3
            )
            practices = practices_rec.get("practices", [])
        
        if debug_info is not None:
            debug_info["practices_found"] = len(practices)
        
        # === –≠–¢–ê–ü 7: –ê–Ω–∞–ª–∏–∑ —Ü–µ–ø–æ—á–µ–∫ (Learning Path) ===
        logger.debug("‚õìÔ∏è –≠—Ç–∞–ø 7: –ê–Ω–∞–ª–∏–∑ —Ü–µ–ø–æ—á–µ–∫...")
        
        learning_path = None
        if include_chain and primary_concepts:
            main_concept = primary_concepts[0]
            path_rec = practices_recommender.get_learning_path(main_concept)
            learning_path = path_rec.get("path")
        
        if debug_info is not None:
            debug_info["learning_path_steps"] = len(learning_path) if learning_path else 0
        
        # === –≠–¢–ê–ü 8: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ===
        logger.debug("üìù –≠—Ç–∞–ø 8: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
        
        answer = llm_result["answer"]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª —Å –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏
        if practices:
            answer += "\n\nüí™ **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏:**\n"
            for practice in practices[:3]:
                explanation = practice.get("explanation", "")
                if explanation:
                    answer += f"- **{practice['name']}** ({practice['type']}) ‚Äî {explanation}\n"
                else:
                    answer += f"- **{practice['name']}** ({practice['type']})\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ü–µ–ø—Ç—ã (—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ —É—Ä–æ–≤–Ω—é)
        concepts_section = level_adapter.format_concepts_for_output(primary_concepts)
        if concepts_section:
            answer += concepts_section
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        sources = _format_sources(adapted_blocks)
        
        elapsed_time = (datetime.now() - start_time).total_seconds()
        
        result = {
            "status": "success",
            "answer": answer,
            "sources": sources,
            "concepts": primary_concepts,
            "relations": semantic_data["conceptual_links"],
            "practices": practices,
            "concept_hierarchy": concept_hierarchies,
            "learning_path": learning_path,
            "metadata": {
                "user_level": user_level,
                "blocks_used": len(adapted_blocks),
                "concepts_found": len(primary_concepts),
                "practices_recommended": len(practices),
                "chain_depth": len(learning_path) if learning_path else 0,
                "model_used": llm_result.get("model_used"),
                "tokens_used": llm_result.get("tokens_used", 0),
                "graph_nodes": graph_client.get_statistics()["total_nodes"],
                "graph_edges": graph_client.get_statistics()["total_edges"]
            },
            "timestamp": datetime.now().isoformat(),
            "processing_time_seconds": round(elapsed_time, 2)
        }
        
        if debug_info is not None:
            debug_info["total_time"] = elapsed_time
            result["debug"] = debug_info
        
        logger.info(
            f"‚úÖ Phase 3: –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {elapsed_time:.2f}—Å "
            f"[Level: {user_level}, Blocks: {len(adapted_blocks)}, "
            f"Concepts: {len(primary_concepts)}, Practices: {len(practices)}]"
        )
        
        return result
    
    except Exception as e:
        logger.error(f"‚ùå Phase 3 Error: {e}", exc_info=True)
        elapsed = (datetime.now() - start_time).total_seconds()
        return {
            "status": "error",
            "answer": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}",
            "sources": [],
            "concepts": [],
            "relations": [],
            "practices": [],
            "concept_hierarchy": {},
            "learning_path": None,
            "metadata": {"error": str(e)},
            "timestamp": datetime.now().isoformat(),
            "processing_time_seconds": round(elapsed, 2),
            "debug": debug_info
        }


def _build_empty_response(
    query: str,
    user_level: str,
    reason: str,
    elapsed: float,
    debug_info: Optional[Dict]
) -> Dict:
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
    return {
        "status": "partial",
        "answer": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à—ë–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. "
                 "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å.",
        "sources": [],
        "concepts": [],
        "relations": [],
        "practices": [],
        "concept_hierarchy": {},
        "learning_path": None,
        "metadata": {"reason": reason, "user_level": user_level},
        "timestamp": datetime.now().isoformat(),
        "processing_time_seconds": round(elapsed, 2),
        "debug": debug_info
    }


def _build_graph_context(concept_hierarchies: Dict) -> str:
    """
    –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏–µ—Ä–∞—Ä—Ö–∏–∏ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –¥–ª—è LLM.
    
    Args:
        concept_hierarchies: Dict –∫–æ–Ω—Ü–µ–ø—Ç -> –∏–µ—Ä–∞—Ä—Ö–∏—è
        
    Returns:
        –°—Ç—Ä–æ–∫–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç
    """
    if not concept_hierarchies:
        return ""
    
    context_lines = ["\n\nüß† –°–¢–†–£–ö–¢–£–†–ê –ö–û–ù–¶–ï–ü–¢–û–í (–∏–∑ Knowledge Graph):"]
    
    for concept, hierarchy in list(concept_hierarchies.items())[:3]:
        context_lines.append(f"\n**{concept}** ({hierarchy.get('type', 'CONCEPT')}):")
        
        # –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –∫–æ–Ω—Ü–µ–ø—Ç—ã
        if hierarchy.get("parent_concepts"):
            parents = [p["name"] for p in hierarchy["parent_concepts"][:3]]
            context_lines.append(f"  ‚Üê –ß–∞—Å—Ç—å: {', '.join(parents)}")
        
        # –î–æ—á–µ—Ä–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ç—ã
        if hierarchy.get("child_concepts"):
            children = [c["name"] for c in hierarchy["child_concepts"][:3]]
            context_lines.append(f"  ‚Üí –°–æ–¥–µ—Ä–∂–∏—Ç: {', '.join(children)}")
        
        # –°–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ç—ã
        if hierarchy.get("related_concepts"):
            related = [r["name"] for r in hierarchy["related_concepts"][:3]]
            context_lines.append(f"  ‚Üî –°–≤—è–∑–∞–Ω —Å: {', '.join(related)}")
    
    return "\n".join(context_lines)


def _format_sources(blocks: List[Block]) -> List[Dict]:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –±–ª–æ–∫–∏ –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å SAG v2.0 –ø–æ–ª—è–º–∏.
    
    Args:
        blocks: –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤
        
    Returns:
        List[Dict] ‚Äî –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    """
    sources = []
    for block in blocks:
        sources.append({
            "block_id": block.block_id,
            "title": block.title,
            "summary": block.summary,
            "document_title": block.document_title,
            "youtube_link": block.youtube_link,
            "start": block.start,
            "end": block.end,
            "video_id": block.video_id,
            # SAG v2.0 –ø–æ–ª—è
            "block_type": block.block_type,
            "emotional_tone": block.emotional_tone,
            "complexity_score": block.complexity_score,
            "conceptual_depth": block.conceptual_depth
        })
    return sources


def ask_graph(
    query: str,
    user_level: str = "beginner",
    include_practices: bool = True
) -> str:
    """
    –ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Phase 3: –≤–µ—Ä–Ω—É—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞.
    
    Args:
        query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_level: –£—Ä–æ–≤–µ–Ω—å (beginner/intermediate/advanced)
        include_practices: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ –≤ –æ—Ç–≤–µ—Ç
        
    Returns:
        –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
    """
    result = answer_question_graph_powered(
        query,
        user_level=user_level,
        include_practices=include_practices
    )
    return result.get("answer", "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞")
