# bot_agent/llm_answerer.py
"""
LLM Answerer Module
===================

–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ OpenAI API —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º –±–æ—Ç–∞-–ø—Å–∏—Ö–æ–ª–æ–≥–∞.
"""

import logging
from typing import List, Dict, Optional

from .data_loader import Block
from .config import config

logger = logging.getLogger(__name__)


class LLMAnswerer:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—è OpenAI API.
    
    Usage:
        >>> answerer = LLMAnswerer()
        >>> result = answerer.generate_answer("–ß—Ç–æ —Ç–∞–∫–æ–µ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ?", blocks)
        >>> print(result["answer"])
    """
    
    def __init__(self):
        self.api_key = config.OPENAI_API_KEY
        self.client = None
        
        if not self.api_key:
            logger.warning("‚ö†Ô∏è OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. LLM –æ—Ç–≤–µ—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
        else:
            self._init_client()
    
    def _init_client(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞"""
        try:
            import openai
            self.client = openai.OpenAI(api_key=self.api_key)
            logger.info("‚úì OpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except ImportError:
            logger.error("‚ùå openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")
            raise
    
    def build_system_prompt(self) -> str:
        """
        –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–æ—Ç–∞-–ø—Å–∏—Ö–æ–ª–æ–≥–∞.
        
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ, —Ç–æ–Ω –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –±–æ—Ç–∞.
        """
        return """–¢—ã ‚Äî —Å–ø–æ–∫–æ–π–Ω—ã–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π –≥–∏–¥, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —É—á–µ–Ω–∏–∏ –°–∞–ª–∞–º–∞—Ç–∞ –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞ –æ –Ω–µ–π—Ä–æ—Å—Ç–∞–ª–∫–∏–Ω–≥–µ –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–æ–∑–Ω–∞–Ω–∏—è.

–¢–í–û–Å –ü–û–í–ï–î–ï–ù–ò–ï:
1. –û—Ç–≤–µ—á–∞–π —Å–ø–æ–∫–æ–π–Ω–æ, —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω–æ, –±–µ–∑ –æ—Å—É–∂–¥–µ–Ω–∏—è.
2. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¢–û–õ–¨–ö–û –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ª–µ–∫—Ü–∏–π.
3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö ‚Äî —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.
4. –í—Å–µ–≥–¥–∞ —Å—Ç–∞—Ä–∞–π—Å—è –Ω–∞–π—Ç–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–ª—è –∂–∏–∑–Ω–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
5. –ò–∑–±–µ–≥–∞–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö/–ø—Å–∏—Ö–∏–∞—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∏–∞–≥–Ω–æ–∑–æ–≤.

–¢–û–ù–£–°:
- –°–ø–æ–∫–æ–π–Ω—ã–π, –Ω–æ –Ω–µ –±–µ–∑–ª–∏—á–Ω—ã–π
- "–ü—Ä–µ–¥–ª–∞–≥–∞—é –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å..." –≤–º–µ—Å—Ç–æ "–¢—ã –¥–æ–ª–∂–µ–Ω..."
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π, –Ω–æ —á–µ—Å—Ç–Ω—ã–π

–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
1. –ü—Ä—è–º–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å
2. –ü—Ä–∏–≤–µ—Å—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
3. –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ (–µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ)
4. –£–ø–æ–º—è–Ω—É—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏

–í–ê–ñ–ù–û: –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–ø–æ–º–∏–Ω–∞–µ—Ç —Å–µ—Ä—å—ë–∑–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è (—Å—É–∏—Ü–∏–¥–∞–ª—å–Ω—ã–µ –º—ã—Å–ª–∏, –ø–∞–Ω–∏—á–µ—Å–∫–∏–µ –∞—Ç–∞–∫–∏), –¥–æ–±–∞–≤—å –¥–∏—Å–∫–ª–µ–π–º–µ—Ä –æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É."""
    
    def build_context_prompt(self, blocks: List[Block], user_question: str) -> str:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM: –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏ + –≤–æ–ø—Ä–æ—Å.
        
        Args:
            blocks: –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤
            user_question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
        """
        context = "–ú–ê–¢–ï–†–ò–ê–õ –ò–ó –õ–ï–ö–¶–ò–ô:\n\n"
        
        for i, block in enumerate(blocks, 1):
            context += f"--- –ë–õ–û–ö {i} ---\n"
            context += f"–õ–µ–∫—Ü–∏—è: {block.document_title}\n"
            context += f"–¢–µ–º–∞: {block.title}\n"
            context += f"–¢–∞–π–º–∫–æ–¥: {block.start} ‚Äî {block.end}\n"
            context += f"–°—Å—ã–ª–∫–∞: {block.youtube_link}\n"
            context += f"–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {block.summary}\n"
            context += f"–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{block.content}\n\n"
        
        context += f"–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\n{user_question}\n\n"
        context += "–°—Ñ–æ—Ä–º–∏—Ä—É–π –æ—Ç–≤–µ—Ç, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª –≤—ã—à–µ. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–ø–æ–º—è–Ω–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏."
        
        return context
    
    def generate_answer(
        self,
        user_question: str,
        blocks: List[Block],
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> Dict:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ OpenAI API.
        
        Args:
            user_question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            blocks: –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤
            model: –ú–æ–¥–µ–ª—å LLM (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ config)
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
            
        Returns:
            Dict —Å –∫–ª—é—á–∞–º–∏:
                - answer: str ‚Äî –≥–æ—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
                - model_used: str ‚Äî –∫–∞–∫—É—é –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏
                - tokens_used: int ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
                - error: Optional[str] ‚Äî –µ—Å–ª–∏ –±—ã–ª–∞ –æ—à–∏–±–∫–∞
        """
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª—É—á–∞—è –±–µ–∑ –±–ª–æ–∫–æ–≤
        if not blocks:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –±–ª–æ–∫–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞!")
            return {
                "answer": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à—ë–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å.",
                "model_used": None,
                "tokens_used": 0,
                "error": "no_blocks"
            }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞
        if not self.client:
            return {
                "answer": "‚ùå OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ OPENAI_API_KEY –≤ .env",
                "model_used": None,
                "tokens_used": 0,
                "error": "no_api_key"
            }
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        model = model or config.LLM_MODEL
        temperature = temperature if temperature is not None else config.LLM_TEMPERATURE
        max_tokens = max_tokens or config.LLM_MAX_TOKENS
        
        # –ü—Ä–æ–º–ø—Ç—ã
        system_prompt = self.build_system_prompt()
        context = self.build_context_prompt(blocks, user_question)
        
        logger.debug(f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ {model}...")
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": context}
                ],
                temperature=temperature,
                max_tokens=max_tokens,
            )
            
            answer = response.choices[0].message.content
            tokens = response.usage.total_tokens if response.usage else 0
            
            logger.debug(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω ({tokens} —Ç–æ–∫–µ–Ω–æ–≤)")
            
            return {
                "answer": answer,
                "model_used": model,
                "tokens_used": tokens,
                "error": None
            }
        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenAI API: {e}")
            return {
                "answer": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}",
                "model_used": model,
                "tokens_used": 0,
                "error": str(e)
            }

