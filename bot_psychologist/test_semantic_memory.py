# bot_psychologist/test_semantic_memory.py
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Semantic Memory
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from bot_agent.conversation_memory import get_conversation_memory
from bot_agent.config import config


def test_semantic_memory():
    print("=" * 60)
    print("–¢–ï–°–¢ SEMANTIC MEMORY")
    print("=" * 60)

    print(f"‚öôÔ∏è Semantic Memory: {'‚úì –í–∫–ª—é—á–µ–Ω–∞' if config.ENABLE_SEMANTIC_MEMORY else '‚úó –í—ã–∫–ª—é—á–µ–Ω–∞'}")
    print(f"‚öôÔ∏è Conversation Summary: {'‚úì –í–∫–ª—é—á–µ–Ω–∞' if config.ENABLE_CONVERSATION_SUMMARY else '‚úó –í—ã–∫–ª—é—á–µ–Ω–∞'}")
    print(f"‚öôÔ∏è Embedding Model: {config.EMBEDDING_MODEL}")
    print()

    memory = get_conversation_memory("test_semantic_user")
    memory.clear()

    turns = [
        ("–ß—Ç–æ —Ç–∞–∫–æ–µ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ?", "–û—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ ‚Äî —ç—Ç–æ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∑–∞–º–µ—á–∞—Ç—å –º—ã—Å–ª–∏ –∏ –æ—â—É—â–µ–Ω–∏—è."),
        ("–ö–∞–∫ –º–µ–¥–∏—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ?", "–ù–∞—á–Ω–∏—Ç–µ —Å 5 –º–∏–Ω—É—Ç –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –∑–∞ –¥—ã—Ö–∞–Ω–∏–µ–º."),
        ("–ö–∞–∫ —Å–ø—Ä–∞–≤–ª—è—Ç—å—Å—è —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º?", "–ü–æ–ª–µ–∑–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è –∫ –¥—ã—Ö–∞–Ω–∏—é –∏ —Ç–µ–ª–µ—Å–Ω—ã–º –æ—â—É—â–µ–Ω–∏—è–º."),
        ("–ü–æ—á–µ–º—É —è —Ç–µ—Ä—è—é —Ñ–æ–∫—É—Å?", "–§–æ–∫—É—Å –º–æ–∂–µ—Ç —Å–Ω–∏–∂–∞—Ç—å—Å—è –∏–∑-–∑–∞ —É—Å—Ç–∞–ª–æ—Å—Ç–∏ –∏ –ø–µ—Ä–µ–≥—Ä—É–∑–∞."),
        ("–ö–∞–∫ —É–∫—Ä–µ–ø–∏—Ç—å –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é?", "–†–µ–≥—É–ª—è—Ä–Ω—ã–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –ø–æ–º–æ–≥–∞—é—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ."),
    ]

    print("üìù –î–æ–±–∞–≤–ª—è—é —Ç–µ—Å—Ç–æ–≤—ã–µ —Ö–æ–¥—ã...")
    for user_input, bot_response in turns:
        memory.add_turn(
            user_input=user_input,
            bot_response=bot_response,
            blocks_used=0,
            concepts=["–æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ", "–¥—ã—Ö–∞–Ω–∏–µ", "–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è"]
        )
        print(f"  ‚úì –î–æ–±–∞–≤–ª–µ–Ω: {user_input[:50]}...")

    print(f"\n‚úÖ –í—Å–µ–≥–æ —Ö–æ–¥–æ–≤ –≤ –ø–∞–º—è—Ç–∏: {len(memory.turns)}")

    if memory.semantic_memory:
        stats = memory.semantic_memory.get_stats()
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Semantic Memory:")
        print(f"  ‚Ä¢ –≠–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {stats.get('total_embeddings')}")
        print(f"  ‚Ä¢ –ú–æ–¥–µ–ª—å: {stats.get('model_name')}")
        print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä –Ω–∞ –¥–∏—Å–∫–µ: {stats.get('embeddings_size_mb', 0):.2f} MB")

        query = "–ö–∞–∫ –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å –æ—Å–æ–∑–Ω–∞–Ω–Ω–æ—Å—Ç—å –ø—Ä–∏ —Å—Ç—Ä–µ—Å—Å–µ?"
        print(f"\nüîç –ó–∞–ø—Ä–æ—Å: {query}")
        similar = memory.semantic_memory.search_similar_turns(
            query=query,
            top_k=2,
            min_similarity=0.5
        )
        if similar:
            print("‚úÖ –ù–∞–π–¥–µ–Ω—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–æ—à–ª—ã–µ –æ–±–º–µ–Ω—ã:")
            for turn_emb, score in similar:
                print(f"  [{score:.3f}] –û–±–º–µ–Ω #{turn_emb.turn_index}: {turn_emb.user_input[:60]}...")
        else:
            print("‚ö†Ô∏è –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ–±–º–µ–Ω–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    else:
        print("\n‚ö†Ô∏è Semantic memory –æ—Ç–∫–ª—é—á–µ–Ω–∞ –∏–ª–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

    print("\n" + "=" * 60)
    print("–ü–û–õ–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢ –î–õ–Ø LLM")
    print("=" * 60)
    test_question = "–ö–∞–∫ –Ω–∞—á–∞—Ç—å –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å –º–µ–¥–∏—Ç–∞—Ü–∏—é, –µ—Å–ª–∏ —É –º–µ–Ω—è —Å—Ç—Ä–µ—Å—Å?"
    full_context = memory.get_adaptive_context_for_llm(test_question)

    print("\nüì¶ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:")
    print(f"  ‚Ä¢ Short-term: {len(full_context.get('short_term', ''))} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"  ‚Ä¢ Semantic: {len(full_context.get('semantic', ''))} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"  ‚Ä¢ Summary: {len(full_context.get('summary', ''))} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"  ‚Ä¢ –ò–¢–û–ì–û: {sum(len(v) for v in full_context.values())} —Å–∏–º–≤–æ–ª–æ–≤")

    if full_context.get("summary"):
        print("\n--- SUMMARY ---")
        print(full_context["summary"][:200] + ("..." if len(full_context["summary"]) > 200 else ""))

    if full_context.get("semantic"):
        print("\n--- SEMANTIC (–ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤) ---")
        print(full_context["semantic"][:300] + "...")

    if full_context.get("short_term"):
        print("\n--- SHORT-TERM (–ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤) ---")
        print(full_context["short_term"][:300] + "...")

    print("\n" + "=" * 60)
    print("üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    memory.clear()
    print("‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")


if __name__ == "__main__":
    try:
        test_semantic_memory()
    except Exception as exc:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {exc}")
