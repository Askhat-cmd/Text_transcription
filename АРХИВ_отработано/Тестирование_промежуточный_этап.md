
# üìã –ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø AI: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –≤—Å–µ—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤

## üéØ –¶–µ–ª—å

–°–æ–∑–¥–∞—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É **–≤—Å–µ—Ö 4 —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤ –≤–º–µ—Å—Ç–µ** –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —Ç–µ–∫—Å—Ç–µ –∏–∑ –ª–µ–∫—Ü–∏–π –°–∞–ª–∞–º–∞—Ç–∞ –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞. –ù–∞–π—Ç–∏ –∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ **–î–û** –Ω–∞–ø–∏—Å–∞–Ω–∏—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞.

***

## üìö –ö–æ–Ω—Ç–µ–∫—Å—Ç

### –£–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (–≠—Ç–∞–ø—ã 1-4):

‚úÖ **–≠—Ç–∞–ø ‚Ññ1:** TerminologyValidator (SMART —Ä–µ–∂–∏–º)
‚úÖ **–≠—Ç–∞–ø ‚Ññ2:** NeurostalkingPatternExtractor
‚úÖ **–≠—Ç–∞–ø ‚Ññ3:** CausalChainExtractor
‚úÖ **–≠—Ç–∞–ø ‚Ññ4:** ConceptHierarchyExtractor

**–ü—Ä–æ–±–ª–µ–º–∞:** –ö–∞–∂–¥—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª—Å—è –û–¢–î–ï–õ–¨–ù–û. –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ –∫–∞–∫ –æ–Ω–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –í–ú–ï–°–¢–ï.

**–†–µ—à–µ–Ω–∏–µ:** –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —Ç–µ–∫—Å—Ç–µ.

***

## üìù –®–ê–ì 1: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã

### –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤:

```bash
mkdir tests/integration
touch tests/integration/__init__.py
touch tests/integration/test_all_extractors.py
```


### –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏:

```bash
mkdir tests/fixtures
touch tests/fixtures/real_sarsekenov_texts.py
```


***

## üìù –®–ê–ì 2: –†–µ–∞–ª—å–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞

### –§–∞–π–ª: `tests/fixtures/real_sarsekenov_texts.py`

```python
"""
–†–µ–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –ª–µ–∫—Ü–∏–π –°–∞–ª–∞–º–∞—Ç–∞ –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞
–¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.

–ò—Å—Ç–æ—á–Ω–∏–∫–∏:
- –õ–µ–∫—Ü–∏–∏ –ø–æ –Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥—É
- –ö–Ω–∏–≥–∞ "–¢–∞–π–Ω–∞ –°–æ–∑–Ω–∞–Ω–∏—è"
- YouTube-–∫–∞–Ω–∞–ª –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞
"""

# –¢–µ–∫—Å—Ç 1: –¢—Ä–∏–∞–¥–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (—Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä)
TRIADA_TRANSFORMATION_TEXT = """
–ö–æ–≥–¥–∞ –ò—â—É—â–∏–π –Ω–∞—á–∏–Ω–∞–µ—Ç –ø—Ä–∞–∫—Ç–∏–∫—É –Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥–∞, –æ–Ω –ø—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ 
—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø–æ–ª–µ–º –≤–Ω–∏–º–∞–Ω–∏—è. –ú–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–±–ª—é–¥–∞—Ç—å –∑–∞ 
–º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º –ø–æ—Ç–æ–∫–æ–º –±–µ–∑ –∑–∞—Ö–≤–∞—Ç–∞ –≤–Ω–∏–º–∞–Ω–∏—è. 

–ß–µ—Ä–µ–∑ –ø—Ä–∞–∫—Ç–∏–∫—É –º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏—è –ò—â—É—â–∏–π –Ω–∞—á–∏–Ω–∞–µ—Ç –∑–∞–º–µ—á–∞—Ç—å –ø–æ—è–≤–ª–µ–Ω–∏–µ 
–Ø-–æ–±—Ä–∞–∑–∞ –≤ –ø–æ–ª–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è. –≠—Ç–æ –ø–µ—Ä–≤—ã–π —ç—Ç–∞–ø - –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ. 

–ó–∞—Ç–µ–º –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–º–æ–≤ –ø—Å–∏—Ö–∏–∫–∏. –ò—â—É—â–∏–π –≤–∏–¥–∏—Ç, 
–∫–∞–∫ –Ø-–æ–±—Ä–∞–∑ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –≤–Ω–∏–º–∞–Ω–∏–µ –∏ —Å–æ–∑–¥–∞—ë—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –¥–∏–∞–ª–æ–≥. 
–≠—Ç–æ –≤—Ç–æ—Ä–æ–π —ç—Ç–∞–ø - –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ.

–î–∞–ª–µ–µ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ —Å –Ø-–æ–±—Ä–∞–∑–æ–º. –ù–∞–±–ª—é–¥–∞—é—â–µ–µ —Å–æ–∑–Ω–∞–Ω–∏–µ 
–æ—Ç–¥–µ–ª—è–µ—Ç—Å—è –æ—Ç –ª–æ–∂–Ω–æ–π —Å–∞–º–æ—Å—Ç–∏. –≠—Ç–æ —Ç—Ä–µ—Ç–∏–π —ç—Ç–∞–ø - —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è —á–µ—Ä–µ–∑ 
—Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ.

–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç —á–∏—Å—Ç–æ–µ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏ —Å–≤–æ–±–æ–¥–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ, 
–Ω–µ –∑–∞—Ö–≤–∞—á–µ–Ω–Ω–æ–µ –Ω–∏–∫–∞–∫–∏–º–∏ –æ–±—Ä–∞–∑–∞–º–∏. –ò—â—É—â–∏–π –ø—Ä–µ–±—ã–≤–∞–µ—Ç –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ 
–ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è –∑–¥–µ—Å—å-–∏-—Å–µ–π—á–∞—Å, –≤ –∂–∏–≤–æ–º –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏–∏ –±—ã—Ç–∏—è.

–ü—Ä–∞–∫—Ç–∏–∫—É–π –º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ –ø–æ 10-15 –º–∏–Ω—É—Ç. –ù–∞—á–Ω–∏ —Å –Ω–∞–±–ª—é–¥–µ–Ω–∏—è 
–∑–∞ –¥—ã—Ö–∞–Ω–∏–µ–º, –∑–∞—Ç–µ–º —Ä–∞—Å—à–∏—Ä—å –ø–æ–ª–µ –≤–Ω–∏–º–∞–Ω–∏—è –Ω–∞ –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫. 
–î–µ–ª–∞–π —ç—Ç–æ —É—Ç—Ä–æ–º –∏ –≤–µ—á–µ—Ä–æ–º –¥–ª—è –ª—É—á—à–µ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –æ–ø—ã—Ç–∞.
"""

# –¢–µ–∫—Å—Ç 2: –†–∞–±–æ—Ç–∞ —Å –ø–æ–ª–µ–º –≤–Ω–∏–º–∞–Ω–∏—è (–∫–æ—Ä–æ—Ç–∫–∏–π)
ATTENTION_FIELD_TEXT = """
–ü–æ–ª–µ –≤–Ω–∏–º–∞–Ω–∏—è ‚Äî —ç—Ç–æ core component –Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥–∞. –ö–æ–≥–¥–∞ –≤–Ω–∏–º–∞–Ω–∏–µ 
–∑–∞—Ö–≤–∞—á–µ–Ω–æ –Ø-–æ–±—Ä–∞–∑–æ–º, –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –º—ã—Å–ª—è–º–∏. 

–¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ. –¢–µ—Ö–Ω–∏–∫–∞ 
—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–ª–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–º —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ. –°–≤–æ–±–æ–¥–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ 
–≤–µ–¥—ë—Ç –∫ —á–∏—Å—Ç–æ–º—É –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏—é.

–ù–∞–±–ª—é–¥–∞–π –∑–∞—Ö–≤–∞—Ç –≤–Ω–∏–º–∞–Ω–∏—è –≤ —Ç–µ—á–µ–Ω–∏–µ –¥–Ω—è. –ó–∞–º–µ—á–∞–π –º–æ–º–µ–Ω—Ç—ã, –∫–æ–≥–¥–∞ –Ø-–æ–±—Ä–∞–∑ 
–∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è.
"""

# –¢–µ–∫—Å—Ç 3: –ò–µ—Ä–∞—Ä—Ö–∏—è –ø—Ä–∞–∫—Ç–∏–∫ (–¥–ª–∏–Ω–Ω—ã–π, —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π)
HIERARCHY_PRACTICES_TEXT = """
–ù–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥ –∫–∞–∫ –ø—Ä–∞–∫—Ç–∏–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–æ–∑–Ω–∞–Ω–∏—è –≤–∫–ª—é—á–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ 
—É—Ä–æ–≤–Ω–µ–π —Ä–∞–±–æ—Ç—ã. –ù–∞ —É—Ä–æ–≤–Ω–µ –ø–æ–Ω–∏–º–∞–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Å–≤–æ–∏—Ç—å –∫–æ–Ω—Ü–µ–ø—Ü–∏—é 
–ø–æ–ª—è –≤–Ω–∏–º–∞–Ω–∏—è –∏ —á–∏—Å—Ç–æ–≥–æ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏—è.

–ë–∞–∑–æ–≤–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–æ–ª–µ–º –≤–Ω–∏–º–∞–Ω–∏—è ‚Äî —ç—Ç–æ –º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ. 
–ú–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏:

1. –ù–∞–±–ª—é–¥–µ–Ω–∏–µ –∑–∞ –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º –ø–æ—Ç–æ–∫–æ–º - –±–∞–∑–æ–≤–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏—è. 
   –ü—Ä–∞–∫—Ç–∏–∫—É–π –µ—ë 5-10 –º–∏–Ω—É—Ç —É—Ç—Ä–æ–º.

2. –¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –¥—ã—Ö–∞–Ω–∏–∏ - —Ç–µ—Ö–Ω–∏–∫–∞ –¥–ª—è —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –≤–Ω–∏–º–∞–Ω–∏—è. 
   –í—ã–ø–æ–ª–Ω—è–π 3 —Ä–∞–∑–∞ –≤ –¥–µ–Ω—å –ø–æ 2-3 –º–∏–Ω—É—Ç—ã.

3. –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–º–æ–≤ –ø—Å–∏—Ö–∏–∫–∏ - —Ç–µ—Ö–Ω–∏–∫–∞ –¥–ª—è –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏—è 
   –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞. –ü—Ä–∞–∫—Ç–∏–∫—É–π –≤ —Ç–µ—á–µ–Ω–∏–µ –¥–Ω—è.

–î—Ä—É–≥–∞—è –∫–ª—é—á–µ–≤–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ ‚Äî —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ —Å –Ø-–æ–±—Ä–∞–∑–æ–º. –û–Ω–∞ —Ç—Ä–µ–±—É–µ—Ç 
–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏—è –∫–∞–∫ foundational practice. –¢–µ—Ö–Ω–∏–∫–∞ —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏—è: 
–Ω–∞–±–ª—é–¥–∞–π –ø–æ—è–≤–ª–µ–Ω–∏–µ –Ø-–æ–±—Ä–∞–∑–∞ –∫–∞–∫ –æ–±—ä–µ–∫—Ç –≤ –ø–æ–ª–µ –≤–Ω–∏–º–∞–Ω–∏—è.

–ú–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –¥–µ–ª–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–º —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ. –†–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ 
–≤–µ–¥—ë—Ç –∫ —á–∏—Å—Ç–æ–º—É –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏—é. –ß–∏—Å—Ç–æ–µ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –≤ 
—É—Å—Ç–æ–π—á–∏–≤–æ–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ.

–î–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö: —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ "5 –º–∏–Ω—É—Ç –º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏—è". –°—è–¥—å –≤ —Ç–∏—Ö–æ–º –º–µ—Å—Ç–µ, 
–∑–∞–∫—Ä–æ–π –≥–ª–∞–∑–∞, –Ω–∞–±–ª—é–¥–∞–π –∑–∞ –¥—ã—Ö–∞–Ω–∏–µ–º 1-2 –º–∏–Ω—É—Ç—ã, –∑–∞—Ç–µ–º —Ä–∞—Å—à–∏—Ä—å –≤–Ω–∏–º–∞–Ω–∏–µ 
–Ω–∞ –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫. –î–µ–ª–∞–π —ç—Ç–æ –∫–∞–∂–¥–æ–µ —É—Ç—Ä–æ –≤ —Ç–µ—á–µ–Ω–∏–µ 21 –¥–Ω—è –¥–ª—è 
—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏–≤—ã—á–∫–∏.
"""

# –¢–µ–∫—Å—Ç 4: –°–º–µ—à–∞–Ω–Ω–∞—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è (–¥–ª—è —Ç–µ—Å—Ç–∞ SMART —Ä–µ–∂–∏–º–∞)
MIXED_TERMINOLOGY_TEXT = """
–ö–æ–≥–¥–∞ —á–µ–ª–æ–≤–µ–∫ –≥–æ–≤–æ—Ä–∏—Ç "–º–æ—ë —ç–≥–æ –º–µ–Ω—è —Ä–∞–∑—Ä—É—à–∞–µ—Ç", —è –æ–±—ä—è—Å–Ω—è—é: —ç—Ç–æ –Ω–µ —ç–≥–æ, 
—ç—Ç–æ –Ø-–æ–±—Ä–∞–∑. –†–∞–±–æ—Ç–∞ —Å –Ø-–æ–±—Ä–∞–∑–æ–º —Ç—Ä–µ–±—É–µ—Ç –Ω–µ –º–µ–¥–∏—Ç–∞—Ü–∏–∏, –∞ –º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏—è.

–†–∞–∑–Ω–∏—Ü–∞ –≤ —Ç–æ–º, —á—Ç–æ –º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ ‚Äî —ç—Ç–æ –∞–∫—Ç–∏–≤–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –∑–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏ 
–≤ –ø–æ–ª–µ –≤–Ω–∏–º–∞–Ω–∏—è, –∞ –Ω–µ –ø–∞—Å—Å–∏–≤–Ω–æ–µ —Ä–∞—Å—Å–ª–∞–±–ª–µ–Ω–∏–µ. –ß–µ—Ä–µ–∑ –º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ 
–ò—â—É—â–∏–π –Ω–∞—á–∏–Ω–∞–µ—Ç –≤–∏–¥–µ—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–º—ã –ø—Å–∏—Ö–∏–∫–∏.

–≠—Ç–æ –≤–µ–¥—ë—Ç –∫ —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏—é —Å –Ø-–æ–±—Ä–∞–∑–æ–º –∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—é —á–∏—Å—Ç–æ–≥–æ 
–æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏—è. –ü—Ä–∞–∫—Ç–∏–∫–∞ –Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥–∞ —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–∏ 
–∑–¥–µ—Å—å-–∏-—Å–µ–π—á–∞—Å.
"""

# –¢–µ–∫—Å—Ç 5: –ë–µ–∑ —Ç–µ—Ä–º–∏–Ω–æ–≤ –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞ (–¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞)
GENERIC_PSYCHOLOGY_TEXT = """
–ü—Å–∏—Ö–æ—Ç–µ—Ä–∞–ø–∏—è –ø–æ–º–æ–≥–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ç—Ä–µ–≤–æ–≥–æ–π –∏ –¥–µ–ø—Ä–µ—Å—Å–∏–µ–π. –í–∞–∂–Ω–æ –ø–æ–≤—ã—Å–∏—Ç—å 
—Å–∞–º–æ–æ—Ü–µ–Ω–∫—É —á–µ—Ä–µ–∑ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ. –†–µ–ª–∞–∫—Å–∞—Ü–∏—è –∏ –º–µ–¥–∏—Ç–∞—Ü–∏—è —Å–Ω–∏–∂–∞—é—Ç 
—Å—Ç—Ä–µ—Å—Å.

–¢–µ—Ö–Ω–∏–∫–∏ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ-–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–π —Ç–µ—Ä–∞–ø–∏–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å 
–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º–∏ –º—ã—Å–ª—è–º–∏. –ö–ª–∏–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –Ω–∞—É—á–∏—Ç—å—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å —Å–≤–æ–∏ —ç–º–æ—Ü–∏–∏.
"""

# –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤
TEXTS_METADATA = {
    "TRIADA_TRANSFORMATION_TEXT": {
        "description": "–ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Ç—Ä–∏–∞–¥—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏",
        "expected_patterns": ["—Ç—Ä–∏–∞–¥–∞_—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏", "—Ä–∞–±–æ—Ç–∞_—Å_–≤–Ω–∏–º–∞–Ω–∏–µ–º", "—Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ"],
        "expected_causal_chains": 1,
        "expected_hierarchy_root": "–Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥",
        "expected_practices": ["–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ", "—Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ"],
        "has_exercises": True,
        "size": "medium"
    },
    "ATTENTION_FIELD_TEXT": {
        "description": "–§–æ–∫—É—Å –Ω–∞ —Ä–∞–±–æ—Ç–µ —Å –ø–æ–ª–µ–º –≤–Ω–∏–º–∞–Ω–∏—è",
        "expected_patterns": ["—Ä–∞–±–æ—Ç–∞_—Å_–≤–Ω–∏–º–∞–Ω–∏–µ–º", "—Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ"],
        "expected_causal_chains": 1,
        "expected_hierarchy_root": "–Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥",
        "expected_practices": ["—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ"],
        "has_exercises": False,
        "size": "short"
    },
    "HIERARCHY_PRACTICES_TEXT": {
        "description": "–ü–æ–ª–Ω–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—è —Å —Ç–µ—Ö–Ω–∏–∫–∞–º–∏ –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è–º–∏",
        "expected_patterns": ["—Ç—Ä–∏–∞–¥–∞_—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏"],
        "expected_causal_chains": 2,
        "expected_hierarchy_root": "–Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥",
        "expected_practices": ["–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ", "—Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ"],
        "has_exercises": True,
        "expected_techniques": 3,
        "size": "long"
    },
    "MIXED_TERMINOLOGY_TEXT": {
        "description": "–°–º–µ—à–∞–Ω–Ω–∞—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è (SMART —Ä–µ–∂–∏–º –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å)",
        "expected_patterns": ["—Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ"],
        "expected_causal_chains": 1,
        "expected_hierarchy_root": "–Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥",
        "has_forbidden_terms": True,
        "should_pass_smart_mode": True,
        "size": "short"
    },
    "GENERIC_PSYCHOLOGY_TEXT": {
        "description": "–û–±—â–∞—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∞)",
        "expected_valid": False,
        "expected_reason": "–Ω–∏–∑–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å",
        "size": "short"
    }
}
```


***

## üìù –®–ê–ì 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç

### –§–∞–π–ª: `tests/integration/test_all_extractors.py`

```python
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –≤—Å–µ—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤.

–ü—Ä–æ–≤–µ—Ä—è—é—Ç —Å–æ–≤–º–µ—Å—Ç–Ω—É—é —Ä–∞–±–æ—Ç—É:
- TerminologyValidator
- NeurostalkingPatternExtractor
- CausalChainExtractor
- ConceptHierarchyExtractor
"""

import pytest
from text_processor.validators import TerminologyValidator
from text_processor.extractors import (
    NeurostalkingPatternExtractor,
    CausalChainExtractor,
    ConceptHierarchyExtractor
)
from tests.fixtures.real_sarsekenov_texts import (
    TRIADA_TRANSFORMATION_TEXT,
    ATTENTION_FIELD_TEXT,
    HIERARCHY_PRACTICES_TEXT,
    MIXED_TERMINOLOGY_TEXT,
    GENERIC_PSYCHOLOGY_TEXT,
    TEXTS_METADATA
)


@pytest.fixture
def validator():
    """–§–∏–∫—Å—Ç—É—Ä–∞ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞"""
    return TerminologyValidator()


@pytest.fixture
def pattern_extractor(validator):
    """–§–∏–∫—Å—Ç—É—Ä–∞ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    return NeurostalkingPatternExtractor(terminology_validator=validator)


@pytest.fixture
def causal_chain_extractor(validator):
    """–§–∏–∫—Å—Ç—É—Ä–∞ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ —Ü–µ–ø–æ—á–µ–∫"""
    return CausalChainExtractor(terminology_validator=validator)


@pytest.fixture
def hierarchy_extractor(validator):
    """–§–∏–∫—Å—Ç—É—Ä–∞ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ –∏–µ—Ä–∞—Ä—Ö–∏–∏"""
    return ConceptHierarchyExtractor(terminology_validator=validator)


class TestFullPipeline:
    """–¢–µ—Å—Ç—ã –ø–æ–ª–Ω–æ–≥–æ pipeline –≤—Å–µ—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤"""
    
    def test_triada_transformation_full_pipeline(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """
        –¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ pipeline –Ω–∞ —Ç–µ–∫—Å—Ç–µ –æ —Ç—Ä–∏–∞–¥–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏.
        
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
        1. –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—Ö–æ–¥–∏—Ç
        2. –í—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –∏–∑–≤–ª–µ–∫–∞—é—Ç –¥–∞–Ω–Ω—ã–µ
        3. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–≤–º–µ—Å—Ç–∏–º—ã –º–µ–∂–¥—É —Å–æ–±–æ–π
        """
        text = TRIADA_TRANSFORMATION_TEXT
        metadata = TEXTS_METADATA["TRIADA_TRANSFORMATION_TEXT"]
        
        # –®–ê–ì 1: –í–ê–õ–ò–î–ê–¶–ò–Ø
        validation = validator.validate_text(text)
        
        assert validation.is_valid, f"Validation failed: {validation.reason}"
        assert validation.metrics['density'] >= 0.15, "Density too low"
        
        print(f"\n‚úÖ VALIDATION PASSED")
        print(f"   Density: {validation.metrics['density']:.1%}")
        print(f"   Entities: {len(validation.sarsekenov_entities)}")
        
        # –®–ê–ì 2: –ü–ê–¢–¢–ï–†–ù–´
        patterns_result = pattern_extractor.extract(text)
        
        assert patterns_result['valid'], f"Patterns failed: {patterns_result.get('reason')}"
        assert len(patterns_result['patterns']) > 0, "No patterns extracted"
        
        print(f"\n‚úÖ PATTERNS EXTRACTED")
        print(f"   Total: {len(patterns_result['patterns'])}")
        for p in patterns_result['patterns']:
            print(f"   - {p['pattern_category']}: {p['pattern_name']}")
        
        # –®–ê–ì 3: –¶–ï–ü–û–ß–ö–ò
        chains_result = causal_chain_extractor.extract(text)
        
        assert chains_result['valid'], f"Chains failed: {chains_result.get('reason')}"
        assert len(chains_result['chains']) > 0, "No chains extracted"
        
        print(f"\n‚úÖ CAUSAL CHAINS EXTRACTED")
        print(f"   Total: {len(chains_result['chains'])}")
        for c in chains_result['chains']:
            print(f"   - {c['process_category']}: {len(c['stages'])} stages")
        
        # –®–ê–ì 4: –ò–ï–†–ê–†–•–ò–Ø
        hierarchy_result = hierarchy_extractor.extract(text)
        
        assert hierarchy_result['valid'], f"Hierarchy failed: {hierarchy_result.get('reason')}"
        
        hierarchy = hierarchy_result['hierarchy']
        assert hierarchy['root']['name'] == metadata['expected_hierarchy_root']
        
        print(f"\n‚úÖ HIERARCHY EXTRACTED")
        print(f"   Root: {hierarchy['root']['name']}")
        print(f"   Domains: {len(hierarchy['domains'])}")
        print(f"   Practices: {len(hierarchy['practices'])}")
        
        # –®–ê–ì 5: –ü–†–û–í–ï–†–ö–ê –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
        self._check_compatibility(
            validation,
            patterns_result,
            chains_result,
            hierarchy_result,
            metadata
        )
        
        print(f"\n‚úÖ COMPATIBILITY CHECK PASSED")
    
    def test_attention_field_full_pipeline(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """–¢–µ—Å—Ç –Ω–∞ —Ç–µ–∫—Å—Ç–µ –æ –ø–æ–ª–µ –≤–Ω–∏–º–∞–Ω–∏—è"""
        text = ATTENTION_FIELD_TEXT
        metadata = TEXTS_METADATA["ATTENTION_FIELD_TEXT"]
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        validation = validator.validate_text(text)
        assert validation.is_valid
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns_result = pattern_extractor.extract(text)
        assert patterns_result['valid']
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∂–∏–¥–∞–µ–º—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        categories_found = patterns_result.get('categories_found', [])
        for expected_cat in metadata['expected_patterns']:
            assert expected_cat in categories_found, \
                f"Expected pattern category '{expected_cat}' not found"
        
        print(f"\n‚úÖ ATTENTION FIELD TEST PASSED")
    
    def test_hierarchy_practices_full_pipeline(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """–¢–µ—Å—Ç –Ω–∞ —Ç–µ–∫—Å—Ç–µ —Å –ø–æ–ª–Ω–æ–π –∏–µ—Ä–∞—Ä—Ö–∏–µ–π"""
        text = HIERARCHY_PRACTICES_TEXT
        metadata = TEXTS_METADATA["HIERARCHY_PRACTICES_TEXT"]
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        validation = validator.validate_text(text)
        assert validation.is_valid
        
        # –ò–µ—Ä–∞—Ä—Ö–∏—è
        hierarchy_result = hierarchy_extractor.extract(text)
        assert hierarchy_result['valid']
        
        hierarchy = hierarchy_result['hierarchy']
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–µ—Ö–Ω–∏–∫
        if metadata.get('expected_techniques'):
            assert len(hierarchy['techniques']) >= metadata['expected_techniques'], \
                f"Expected at least {metadata['expected_techniques']} techniques"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π
        if metadata.get('has_exercises'):
            assert len(hierarchy['exercises']) > 0, "Expected exercises not found"
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π
            for exercise in hierarchy['exercises']:
                print(f"\n   Exercise: {exercise['name']}")
                if exercise.get('duration'):
                    print(f"     Duration: {exercise['duration']}")
                if exercise.get('frequency'):
                    print(f"     Frequency: {exercise['frequency']}")
        
        print(f"\n‚úÖ HIERARCHY PRACTICES TEST PASSED")
    
    def test_mixed_terminology_smart_mode(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """
        –¢–µ—Å—Ç SMART —Ä–µ–∂–∏–º–∞: —Ç–µ–∫—Å—Ç —Å forbidden terms –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–π—Ç–∏.
        
        –ö–†–ò–¢–ò–ß–ù–û: –í SMART —Ä–µ–∂–∏–º–µ forbidden terms –ù–ï –±–ª–æ–∫–∏—Ä—É—é—Ç —Ç–µ–∫—Å—Ç!
        """
        text = MIXED_TERMINOLOGY_TEXT
        metadata = TEXTS_METADATA["MIXED_TERMINOLOGY_TEXT"]
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–π—Ç–∏ –≤ SMART —Ä–µ–∂–∏–º–µ
        validation = validator.validate_text(text)
        
        assert validation.is_valid, \
            f"SMART mode should pass texts with forbidden terms! Reason: {validation.reason}"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ forbidden terms –Ω–∞–π–¥–µ–Ω—ã (–Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞–ª–∏)
        assert len(validation.forbidden_terms_found) > 0, \
            "Expected forbidden terms in text"
        
        print(f"\n‚úÖ SMART MODE TEST PASSED")
        print(f"   Forbidden terms found: {validation.forbidden_terms_found}")
        print(f"   But text was accepted (SMART mode)")
        
        # –í—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –¥–æ–ª–∂–Ω—ã —Ä–∞–±–æ—Ç–∞—Ç—å
        patterns_result = pattern_extractor.extract(text)
        assert patterns_result['valid']
        
        chains_result = causal_chain_extractor.extract(text)
        assert chains_result['valid']
        
        hierarchy_result = hierarchy_extractor.extract(text)
        assert hierarchy_result['valid']
    
    def test_generic_psychology_rejected(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """–¢–µ—Å—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –æ–±—â–µ–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏"""
        text = GENERIC_PSYCHOLOGY_TEXT
        metadata = TEXTS_METADATA["GENERIC_PSYCHOLOGY_TEXT"]
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –û–¢–ö–õ–û–ù–ò–¢–¨
        validation = validator.validate_text(text)
        
        assert not validation.is_valid, \
            "Generic psychology text should be rejected"
        
        assert "–ø–ª–æ—Ç–Ω–æ—Å—Ç—å" in validation.reason.lower(), \
            "Should be rejected due to low density"
        
        print(f"\n‚úÖ GENERIC PSYCHOLOGY REJECTED")
        print(f"   Reason: {validation.reason}")
        
        # –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –∏–∑–≤–ª–µ–∫–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
        patterns_result = pattern_extractor.extract(text)
        assert not patterns_result['valid']
        
        chains_result = causal_chain_extractor.extract(text)
        assert not chains_result['valid']
    
    def _check_compatibility(
        self,
        validation,
        patterns_result,
        chains_result,
        hierarchy_result,
        metadata
    ):
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞–∑–Ω—ã—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤.
        
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
        1. –¢–µ—Ä–º–∏–Ω—ã –∏–∑ patterns –µ—Å—Ç—å –≤ validation.sarsekenov_entities
        2. –ü—Ä–∞–∫—Ç–∏–∫–∏ –∏–∑ hierarchy —Å–æ–≤–º–µ—Å—Ç–∏–º—ã —Å patterns
        3. –≠—Ç–∞–ø—ã –∏–∑ chains –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ç–µ –∂–µ —Ç–µ—Ä–º–∏–Ω—ã
        4. –ù–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π –≤ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏
        """
        
        # 1. –¢–ï–†–ú–ò–ù–´ –ò–ó –ü–ê–¢–¢–ï–†–ù–û–í
        all_pattern_terms = set()
        for pattern in patterns_result['patterns']:
            all_pattern_terms.update(pattern['key_terms'])
        
        validated_entities = set(validation.sarsekenov_entities)
        
        # –í—Å–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ validation
        for term in all_pattern_terms:
            assert term in validated_entities, \
                f"Pattern term '{term}' not found in validation entities"
        
        print(f"\n   ‚úì Pattern terms compatible with validation")
        
        # 2. –ü–†–ê–ö–¢–ò–ö–ò –ò–ó –ò–ï–†–ê–†–•–ò–ò
        hierarchy = hierarchy_result['hierarchy']
        hierarchy_practices = [p['name'] for p in hierarchy['practices']]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –æ–∂–∏–¥–∞–µ–º—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –Ω–∞–π–¥–µ–Ω—ã
        for expected_practice in metadata.get('expected_practices', []):
            assert expected_practice in hierarchy_practices, \
                f"Expected practice '{expected_practice}' not in hierarchy"
        
        print(f"   ‚úì Hierarchy practices match expected")
        
        # 3. –¢–ï–†–ú–ò–ù–´ –ò–ó –¶–ï–ü–û–ß–ï–ö
        all_chain_terms = set()
        for chain in chains_result['chains']:
            for stage in chain['stages']:
                all_chain_terms.update(stage['sarsekenov_terms'])
        
        # –í—Å–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ü–µ–ø–æ—á–µ–∫ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ validation
        for term in all_chain_terms:
            assert term in validated_entities, \
                f"Chain term '{term}' not found in validation entities"
        
        print(f"   ‚úì Chain terms compatible with validation")
        
        # 4. –ö–ê–¢–ï–ì–û–†–ò–ò –ü–ê–¢–¢–ï–†–ù–û–í vs –ö–ê–¢–ï–ì–û–†–ò–ò –¶–ï–ü–û–ß–ï–ö
        pattern_categories = set(patterns_result.get('categories_found', []))
        chain_categories = set(c['process_category'] for c in chains_result['chains'])
        
        # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ (–Ω–æ –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
        overlap = pattern_categories & chain_categories
        assert len(overlap) > 0, \
            "No category overlap between patterns and chains"
        
        print(f"   ‚úì Categories overlap: {overlap}")
        
        # 5. ROOT –í –ò–ï–†–ê–†–•–ò–ò
        root_name = hierarchy['root']['name']
        assert root_name in ["–Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥", "–Ω–µ–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥", "—Å—Ç–∞–ª–∫–∏–Ω–≥ —É–º–∞"], \
            f"Invalid root: {root_name}"
        
        print(f"   ‚úì Valid hierarchy root: {root_name}")


class TestPerformance:
    """–¢–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def test_pipeline_performance(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ pipeline —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±—ã—Å—Ç—Ä–æ"""
        import time
        
        text = TRIADA_TRANSFORMATION_TEXT
        
        start = time.time()
        
        validation = validator.validate_text(text)
        patterns_result = pattern_extractor.extract(text)
        chains_result = causal_chain_extractor.extract(text)
        hierarchy_result = hierarchy_extractor.extract(text)
        
        elapsed = time.time() - start
        
        # –ù–µ –¥–æ–ª–∂–Ω–æ –∑–∞–Ω–∏–º–∞—Ç—å –±–æ–ª—å—à–µ 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        assert elapsed < 5.0, f"Pipeline too slow: {elapsed:.2f}s"
        
        print(f"\n‚úÖ PERFORMANCE TEST PASSED")
        print(f"   Total time: {elapsed:.2f}s")
        print(f"   Validation: ~{elapsed*0.1:.2f}s")
        print(f"   Patterns: ~{elapsed*0.3:.2f}s")
        print(f"   Chains: ~{elapsed*0.3:.2f}s")
        print(f"   Hierarchy: ~{elapsed*0.3:.2f}s")


class TestTerminologyConsistency:
    """–¢–µ—Å—Ç—ã —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏"""
    
    def test_same_terms_across_extractors(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """
        –í—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –¥–æ–ª–∂–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        –∏–∑ sarsekenov_terms.json
        """
        text = TRIADA_TRANSFORMATION_TEXT
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        validation = validator.validate_text(text)
        patterns_result = pattern_extractor.extract(text)
        chains_result = causal_chain_extractor.extract(text)
        hierarchy_result = hierarchy_extractor.extract(text)
        
        # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ —Ç–µ—Ä–º–∏–Ω—ã
        validated_terms = set(validation.sarsekenov_entities)
        
        pattern_terms = set()
        for p in patterns_result['patterns']:
            pattern_terms.update(p['key_terms'])
        
        chain_terms = set()
        for c in chains_result['chains']:
            for stage in c['stages']:
                chain_terms.update(stage['sarsekenov_terms'])
        
        hierarchy_terms = set()
        hierarchy = hierarchy_result['hierarchy']
        for node_list in [hierarchy['domains'], hierarchy['practices'], 
                          hierarchy['techniques']]:
            for node in node_list:
                hierarchy_terms.update(node['sarsekenov_terms'])
        
        # –í—Å–µ —Ç–µ—Ä–º–∏–Ω—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ–º validated_terms
        assert pattern_terms.issubset(validated_terms), \
            f"Pattern terms not in validation: {pattern_terms - validated_terms}"
        
        assert chain_terms.issubset(validated_terms), \
            f"Chain terms not in validation: {chain_terms - validated_terms}"
        
        assert hierarchy_terms.issubset(validated_terms), \
            f"Hierarchy terms not in validation: {hierarchy_terms - validated_terms}"
        
        print(f"\n‚úÖ TERMINOLOGY CONSISTENCY PASSED")
        print(f"   Validated terms: {len(validated_terms)}")
        print(f"   Pattern terms: {len(pattern_terms)}")
        print(f"   Chain terms: {len(chain_terms)}")
        print(f"   Hierarchy terms: {len(hierarchy_terms)}")


# ============================================================================
# HELPER: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
# ============================================================================

def print_full_pipeline_results(
    text: str,
    validation,
    patterns_result,
    chains_result,
    hierarchy_result
):
    """
    –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–π –ø–µ—á–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏.
    """
    print("\n" + "="*80)
    print("FULL PIPELINE RESULTS")
    print("="*80)
    
    print(f"\nüìÑ TEXT LENGTH: {len(text)} chars")
    
    print(f"\n‚úÖ VALIDATION:")
    print(f"   Valid: {validation.is_valid}")
    print(f"   Density: {validation.metrics['density']:.1%}")
    print(f"   Entities: {len(validation.sarsekenov_entities)}")
    print(f"   Forbidden terms: {validation.forbidden_terms_found}")
    
    print(f"\nüé® PATTERNS:")
    print(f"   Valid: {patterns_result['valid']}")
    print(f"   Total: {len(patterns_result.get('patterns', []))}")
    for p in patterns_result.get('patterns', []):
        print(f"   - {p['pattern_category']}: {p['pattern_name']} ({p['confidence']:.2f})")
    
    print(f"\nüîó CAUSAL CHAINS:")
    print(f"   Valid: {chains_result['valid']}")
    print(f"   Total: {len(chains_result.get('chains', []))}")
    for c in chains_result.get('chains', []):
        print(f"   - {c['process_category']}: {len(c['stages'])} stages ({c['confidence']:.2f})")
        for stage in c['stages'][:3]:  # –ü–µ—Ä–≤—ã–µ 3 —ç—Ç–∞–ø–∞
            print(f"      {stage['stage']}. {stage['stage_name']}")
    
    print(f"\nüèóÔ∏è HIERARCHY:")
    print(f"   Valid: {hierarchy_result['valid']}")
    if hierarchy_result['valid']:
        h = hierarchy_result['hierarchy']
        print(f"   Root: {h['root']['name']}")
        print(f"   Domains: {len(h['domains'])}")
        print(f"   Practices: {len(h['practices'])}")
        print(f"   Techniques: {len(h['techniques'])}")
        print(f"   Exercises: {len(h['exercises'])}")
        print(f"   Cross-connections: {len(h['cross_connections'])}")
    
    print("\n" + "="*80)
```


***

## üìù –®–ê–ì 4: –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

### –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

```bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
pytest tests/integration/test_all_extractors.py -v

# –ó–∞–ø—É—Å–∫ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –≤—ã–≤–æ–¥–æ–º
pytest tests/integration/test_all_extractors.py -v -s

# –ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
pytest tests/integration/test_all_extractors.py::TestFullPipeline::test_triada_transformation_full_pipeline -v -s

# –ó–∞–ø—É—Å–∫ —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º
pytest tests/integration/test_all_extractors.py --cov=text_processor --cov-report=html
```


***

## üìù –®–ê–ì 5: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –û–∂–∏–¥–∞–µ–º—ã–π —É—Å–ø–µ—à–Ω—ã–π –≤—ã–≤–æ–¥:

```
tests/integration/test_all_extractors.py::TestFullPipeline::test_triada_transformation_full_pipeline PASSED

‚úÖ VALIDATION PASSED
   Density: 48.2%
   Entities: 15

‚úÖ PATTERNS EXTRACTED
   Total: 3
   - —Ç—Ä–∏–∞–¥–∞_—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏: –º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –∏ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
   - —Ä–∞–±–æ—Ç–∞_—Å_–≤–Ω–∏–º–∞–Ω–∏–µ–º: –ø–æ–ª–µ –≤–Ω–∏–º–∞–Ω–∏—è –∏ —Å–≤–æ–±–æ–¥–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ
   - —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ: —Ä–∞–∑–æ—Ç–æ–∂–¥–µ—Å—Ç–≤–ª–µ–Ω–∏–µ –∏ –Ø-–æ–±—Ä–∞–∑

‚úÖ CAUSAL CHAINS EXTRACTED
   Total: 1
   - —Ç—Ä–∏–∞–¥–∞_—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏: 4 stages

‚úÖ HIERARCHY EXTRACTED
   Root: –Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥
   Domains: 2
   Practices: 2

‚úÖ COMPATIBILITY CHECK PASSED
   ‚úì Pattern terms compatible with validation
   ‚úì Hierarchy practices match expected
   ‚úì Chain terms compatible with validation
   ‚úì Categories overlap: {'—Ç—Ä–∏–∞–¥–∞_—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏'}
   ‚úì Valid hierarchy root: –Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥

================== 8 passed in 2.34s ==================
```


### –ï—Å–ª–∏ —Ç–µ—Å—Ç—ã –ø–∞–¥–∞—é—Ç ‚Äî –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:

**–ü—Ä–æ–±–ª–µ–º–∞ 1: Terms not compatible**

```
AssertionError: Pattern term '–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ' not found in validation entities
```

‚Üí **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –≤—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é

**–ü—Ä–æ–±–ª–µ–º–∞ 2: Performance too slow**

```
AssertionError: Pipeline too slow: 8.45s
```

‚Üí **–†–µ—à–µ–Ω–∏–µ:** –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã (–ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ)

**–ü—Ä–æ–±–ª–µ–º–∞ 3: No overlap in categories**

```
AssertionError: No category overlap between patterns and chains
```

‚Üí **–†–µ—à–µ–Ω–∏–µ:** –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –º–µ–∂–¥—É —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞–º–∏

***

## ‚úÖ –ß–µ–∫–ª–∏—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

- [ ] –°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è `tests/integration/`
- [ ] –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª `tests/fixtures/real_sarsekenov_texts.py` —Å 5 —Ç–µ–∫—Å—Ç–∞–º–∏
- [ ] –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª `tests/integration/test_all_extractors.py`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã 3 –∫–ª–∞—Å—Å–∞ —Ç–µ—Å—Ç–æ–≤:
    - [ ] `TestFullPipeline` (5 —Ç–µ—Å—Ç–æ–≤)
    - [ ] `TestPerformance` (1 —Ç–µ—Å—Ç)
    - [ ] `TestTerminologyConsistency` (1 —Ç–µ—Å—Ç)
- [ ] –î–æ–±–∞–≤–ª–µ–Ω–∞ helper-—Ñ—É–Ω–∫—Ü–∏—è `print_full_pipeline_results()`
- [ ] –ó–∞–ø—É—â–µ–Ω—ã –≤—Å–µ —Ç–µ—Å—Ç—ã: `pytest tests/integration/ -v`
- [ ] **–í–°–ï –¢–ï–°–¢–´ –ü–†–û–®–õ–ò** ‚úÖ

***

## üéØ –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞

–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç —Å—á–∏—Ç–∞–µ—Ç—Å—è —É—Å–ø–µ—à–Ω—ã–º –µ—Å–ª–∏:

1. ‚úÖ –í—Å–µ 8 —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ—Ö–æ–¥—è—Ç
2. ‚úÖ –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è < 5 —Å–µ–∫—É–Ω–¥
3. ‚úÖ –ù–µ—Ç –æ—à–∏–±–æ–∫ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏
4. ‚úÖ SMART —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ (–ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç forbidden terms)
5. ‚úÖ –û–±—â–∞—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è

***

## üìä –ß—Ç–æ –¥–∞–ª—å—à–µ?

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞:

1. ‚úÖ **–ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ—à–ª–æ:** –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –≠—Ç–∞–ø—É ‚Ññ5 (–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä)
2. ‚ùå **–ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã:** –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã

***

**–ì–æ—Ç–æ–≤–æ! –ü–æ–ª–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è AI –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞!** üéØ‚ú®

