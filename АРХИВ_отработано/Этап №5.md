

***

# üìã –ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø CURSOR AI: –≠—Ç–∞–ø ‚Ññ5 ‚Äî SarsekenovProcessor (–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä)

## üéØ –¶–µ–ª—å

–°–æ–∑–¥–∞—Ç—å **–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä**, –∫–æ—Ç–æ—Ä—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤—Å–µ 4 —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞, –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ **–µ–¥–∏–Ω—ã–π –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π** (Knowledge Graph) –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ **RAG —Å–∏—Å—Ç–µ–º—É**.

***

## üìö –ö–æ–Ω—Ç–µ–∫—Å—Ç: –£–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (–≠—Ç–∞–ø—ã 1-4)

‚úÖ **–≠—Ç–∞–ø ‚Ññ1:** TerminologyValidator (SMART —Ä–µ–∂–∏–º)
‚úÖ **–≠—Ç–∞–ø ‚Ññ2:** NeurostalkingPatternExtractor
‚úÖ **–≠—Ç–∞–ø ‚Ññ3:** CausalChainExtractor
‚úÖ **–≠—Ç–∞–ø ‚Ññ4:** ConceptHierarchyExtractor
‚úÖ **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç:** –í—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã —Ä–∞–±–æ—Ç–∞—é—Ç –≤–º–µ—Å—Ç–µ (7/7 —Ç–µ—Å—Ç–æ–≤)

***

## üèóÔ∏è –§–∏–ª–æ—Å–æ—Ñ–∏—è –≠—Ç–∞–ø–∞ ‚Ññ5

### –ß—Ç–æ —Ç–∞–∫–æ–µ "–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä"?

**–ê–Ω–∞–ª–æ–≥–∏—è:** –î–∏—Ä–∏–∂—ë—Ä –æ—Ä–∫–µ—Å—Ç—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  –ú—É–∑—ã–∫–∞–Ω—Ç—ã (–≠—Ç–∞–ø—ã 1-4)                  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ –°–∫—Ä–∏–ø–∫–∞ (Validator)                ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ –§–ª–µ–π—Ç–∞ (Patterns)                  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ –¢—Ä—É–±–∞ (Chains)                     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ –í–∏–æ–ª–æ–Ω—á–µ–ª—å (Hierarchy)             ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  üéº –î–∏—Ä–∏–∂—ë—Ä (Orchestrator)              ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –º—É–∑—ã–∫–∞–Ω—Ç–æ–≤         ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ –°–æ–∑–¥–∞—ë—Ç –≥–∞—Ä–º–æ–Ω–∏—é (Graph)        ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Å–∏–º—Ñ–æ–Ω–∏—é (RAG)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–í –Ω–∞—à–µ–º –ø—Ä–æ–µ–∫—Ç–µ:**

- **–ú—É–∑—ã–∫–∞–Ω—Ç—ã** = 4 —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ (—Ä–∞–±–æ—Ç–∞—é—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
- **–î–∏—Ä–∏–∂—ë—Ä** = SarsekenovProcessor (–æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
- **–°–∏–º—Ñ–æ–Ω–∏—è** = Knowledge Graph (–µ–¥–∏–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ –∑–Ω–∞–Ω–∏–π)
- **–ó–∞–ø–∏—Å—å** = –≠–∫—Å–ø–æ—Ä—Ç –≤ RAG (–¥–ª—è AI-–±–æ—Ç–∞)

***

## üìù –®–ê–ì 1: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π

```bash
# –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞
mkdir -p text_processor/orchestrator
touch text_processor/orchestrator/__init__.py
touch text_processor/orchestrator/sarsekenov_processor.py
touch text_processor/orchestrator/knowledge_graph.py

# –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
mkdir -p text_processor/export
touch text_processor/export/__init__.py
touch text_processor/export/rag_formatter.py

# –°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç—ã
mkdir -p tests/orchestrator
touch tests/orchestrator/__init__.py
touch tests/orchestrator/test_sarsekenov_processor.py
touch tests/orchestrator/test_knowledge_graph.py
```

**–ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:**

```
voice_bot_pipeline/
‚îú‚îÄ‚îÄ text_processor/
‚îÇ   ‚îú‚îÄ‚îÄ validators/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terminology_validator.py
‚îÇ   ‚îú‚îÄ‚îÄ extractors/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ neurostalking_pattern_extractor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ causal_chain_extractor.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ concept_hierarchy_extractor.py
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator/                    # üÜï –ù–û–í–û–ï
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sarsekenov_processor.py      # üÜï –ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ knowledge_graph.py           # üÜï –ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π
‚îÇ   ‚îî‚îÄ‚îÄ export/                          # üÜï –ù–û–í–û–ï
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ rag_formatter.py             # üÜï –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è RAG
‚îî‚îÄ‚îÄ tests/
    ‚îî‚îÄ‚îÄ orchestrator/                    # üÜï –ù–û–í–û–ï
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ test_sarsekenov_processor.py
        ‚îî‚îÄ‚îÄ test_knowledge_graph.py
```


***

## üìù –®–ê–ì 2: Knowledge Graph (–ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π)

### –§–∞–π–ª: `text_processor/orchestrator/knowledge_graph.py`

```python
"""
Knowledge Graph –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞.

–ì—Ä–∞—Ñ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑:
- –£–∑–ª–æ–≤ (nodes): –∫–æ–Ω—Ü–µ–ø—Ç—ã, –ø–∞—Ç—Ç–µ—Ä–Ω—ã, —ç—Ç–∞–ø—ã –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
- –†—ë–±–µ—Ä (edges): —Å–≤—è–∑–∏ –º–µ–∂–¥—É —É–∑–ª–∞–º–∏
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: confidence, tier, density
"""

from dataclasses import dataclass, field, asdict
from typing import Dict, List, Optional, Set, Any
from enum import Enum
import json


class NodeType(Enum):
    """–¢–∏–ø—ã —É–∑–ª–æ–≤ –≤ –≥—Ä–∞—Ñ–µ"""
    CONCEPT = "concept"              # –ö–æ–Ω—Ü–µ–ø—Ç –∏–∑ –∏–µ—Ä–∞—Ä—Ö–∏–∏
    PATTERN = "pattern"              # –ü–∞—Ç—Ç–µ—Ä–Ω —É—á–µ–Ω–∏—è
    PROCESS_STAGE = "process_stage"  # –≠—Ç–∞–ø –ø—Ä–æ—Ü–µ—Å—Å–∞
    PRACTICE = "practice"            # –ü—Ä–∞–∫—Ç–∏–∫–∞
    TECHNIQUE = "technique"          # –¢–µ—Ö–Ω–∏–∫–∞
    EXERCISE = "exercise"            # –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ


class EdgeType(Enum):
    """–¢–∏–ø—ã —Å–≤—è–∑–µ–π –≤ –≥—Ä–∞—Ñ–µ"""
    # –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ)
    IS_CORE_COMPONENT_OF = "is_core_component_of"
    IS_PRACTICE_FOR = "is_practice_for"
    IS_TECHNIQUE_FOR = "is_technique_for"
    IS_EXERCISE_FOR = "is_exercise_for"
    
    # –ü—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–µ
    EMERGES_FROM = "emerges_from"
    ENABLES = "enables"
    REQUIRES = "requires"
    LEADS_TO = "leads_to"
    TRANSFORMS_INTO = "transforms_into"
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã
    RELATED_TO = "related_to"
    PART_OF_PATTERN = "part_of_pattern"


@dataclass
class GraphNode:
    """–£–∑–µ–ª –≤ –≥—Ä–∞—Ñ–µ –∑–Ω–∞–Ω–∏–π"""
    id: str                          # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
    name: str                        # –ù–∞–∑–≤–∞–Ω–∏–µ
    node_type: NodeType              # –¢–∏–ø —É–∑–ª–∞
    description: str                 # –û–ø–∏—Å–∞–Ω–∏–µ
    sarsekenov_terms: List[str]      # –¢–µ—Ä–º–∏–Ω—ã –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞
    tier: Optional[int] = None       # Tier (1-6) –µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ
    confidence: float = 1.0          # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (0.0-1.0)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ dict"""
        d = asdict(self)
        d['node_type'] = self.node_type.value
        return d


@dataclass
class GraphEdge:
    """–°–≤—è–∑—å –≤ –≥—Ä–∞—Ñ–µ –∑–Ω–∞–Ω–∏–π"""
    from_id: str                     # ID –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    to_id: str                       # ID —Ü–µ–ª–∏
    edge_type: EdgeType              # –¢–∏–ø —Å–≤—è–∑–∏
    explanation: str                 # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–≤—è–∑–∏
    confidence: float = 1.0          # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–≤—è–∑–∏
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ dict"""
        d = asdict(self)
        d['edge_type'] = self.edge_type.value
        return d


class KnowledgeGraph:
    """
    –ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞.
    
    –•—Ä–∞–Ω–∏—Ç –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –≤ –≤–∏–¥–µ –≥—Ä–∞—Ñ–∞:
    - –£–∑–ª—ã: –∫–æ–Ω—Ü–µ–ø—Ç—ã, –ø–∞—Ç—Ç–µ—Ä–Ω—ã, —ç—Ç–∞–ø—ã
    - –†—ë–±—Ä–∞: —Å–≤—è–∑–∏ –º–µ–∂–¥—É –Ω–∏–º–∏
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤ –∏ —Å–≤—è–∑–µ–π
    - –ü–æ–∏—Å–∫ –ø–æ –≥—Ä–∞—Ñ—É
    - –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—É—Ç–µ–π (reasoning chains)
    - –≠–∫—Å–ø–æ—Ä—Ç –¥–ª—è RAG
    """
    
    def __init__(self):
        self.nodes: Dict[str, GraphNode] = {}  # id -> node
        self.edges: List[GraphEdge] = []
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        self._edges_from: Dict[str, List[GraphEdge]] = {}  # from_id -> edges
        self._edges_to: Dict[str, List[GraphEdge]] = {}    # to_id -> edges
        self._nodes_by_type: Dict[NodeType, Set[str]] = {
            nt: set() for nt in NodeType
        }
        self._nodes_by_name: Dict[str, str] = {}  # name -> id
    
    def add_node(self, node: GraphNode) -> str:
        """
        –î–æ–±–∞–≤–∏—Ç—å —É–∑–µ–ª –≤ –≥—Ä–∞—Ñ.
        
        Args:
            node: –£–∑–µ–ª –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
            
        Returns:
            ID –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —É–∑–ª–∞
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –∏–º–µ–Ω–∏
        if node.name in self._nodes_by_name:
            existing_id = self._nodes_by_name[node.name]
            # –û–±–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —É–∑–µ–ª (merge –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)
            existing_node = self.nodes[existing_id]
            existing_node.metadata.update(node.metadata)
            existing_node.confidence = max(
                existing_node.confidence,
                node.confidence
            )
            return existing_id
        
        # –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π —É–∑–µ–ª
        self.nodes[node.id] = node
        self._nodes_by_type[node.node_type].add(node.id)
        self._nodes_by_name[node.name] = node.id
        
        return node.id
    
    def add_edge(self, edge: GraphEdge) -> None:
        """
        –î–æ–±–∞–≤–∏—Ç—å —Å–≤—è–∑—å –≤ –≥—Ä–∞—Ñ.
        
        Args:
            edge: –°–≤—è–∑—å –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —É–∑–ª–æ–≤
        if edge.from_id not in self.nodes:
            raise ValueError(f"Source node not found: {edge.from_id}")
        if edge.to_id not in self.nodes:
            raise ValueError(f"Target node not found: {edge.to_id}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        for existing_edge in self.edges:
            if (existing_edge.from_id == edge.from_id and
                existing_edge.to_id == edge.to_id and
                existing_edge.edge_type == edge.edge_type):
                # –î—É–±–ª–∏–∫–∞—Ç –Ω–∞–π–¥–µ–Ω, –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º
                return
        
        # –î–æ–±–∞–≤–∏—Ç—å —Å–≤—è–∑—å
        self.edges.append(edge)
        
        # –û–±–Ω–æ–≤–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã
        if edge.from_id not in self._edges_from:
            self._edges_from[edge.from_id] = []
        self._edges_from[edge.from_id].append(edge)
        
        if edge.to_id not in self._edges_to:
            self._edges_to[edge.to_id] = []
        self._edges_to[edge.to_id].append(edge)
    
    def get_node(self, node_id: str) -> Optional[GraphNode]:
        """–ü–æ–ª—É—á–∏—Ç—å —É–∑–µ–ª –ø–æ ID"""
        return self.nodes.get(node_id)
    
    def get_node_by_name(self, name: str) -> Optional[GraphNode]:
        """–ü–æ–ª—É—á–∏—Ç—å —É–∑–µ–ª –ø–æ –∏–º–µ–Ω–∏"""
        node_id = self._nodes_by_name.get(name)
        return self.nodes.get(node_id) if node_id else None
    
    def get_nodes_by_type(self, node_type: NodeType) -> List[GraphNode]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —É–∑–ª—ã –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"""
        node_ids = self._nodes_by_type.get(node_type, set())
        return [self.nodes[nid] for nid in node_ids]
    
    def get_outgoing_edges(self, node_id: str) -> List[GraphEdge]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏ —É–∑–ª–∞"""
        return self._edges_from.get(node_id, [])
    
    def get_incoming_edges(self, node_id: str) -> List[GraphEdge]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏ —É–∑–ª–∞"""
        return self._edges_to.get(node_id, [])
    
    def find_path(
        self,
        from_id: str,
        to_id: str,
        max_depth: int = 5
    ) -> Optional[List[str]]:
        """
        –ù–∞–π—Ç–∏ –ø—É—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è —É–∑–ª–∞–º–∏ (BFS).
        
        Args:
            from_id: ID –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —É–∑–ª–∞
            to_id: ID –∫–æ–Ω–µ—á–Ω–æ–≥–æ —É–∑–ª–∞
            max_depth: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –ø–æ–∏—Å–∫–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ ID —É–∑–ª–æ–≤ –≤–¥–æ–ª—å –ø—É—Ç–∏ –∏–ª–∏ None
        """
        if from_id == to_id:
            return [from_id]
        
        # BFS
        queue = [(from_id, [from_id])]
        visited = {from_id}
        
        while queue:
            current_id, path = queue.pop(0)
            
            if len(path) > max_depth:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ö–æ–¥—è—â–∏—Ö —Å–≤—è–∑–µ–π
            for edge in self.get_outgoing_edges(current_id):
                next_id = edge.to_id
                
                if next_id == to_id:
                    return path + [next_id]
                
                if next_id not in visited:
                    visited.add(next_id)
                    queue.append((next_id, path + [next_id]))
        
        return None
    
    def build_reasoning_chain(
        self,
        from_concept: str,
        to_concept: str
    ) -> Optional[Dict]:
        """
        –ü–æ—Å—Ç—Ä–æ–∏—Ç—å reasoning chain –æ—Ç –æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞ –∫ –¥—Ä—É–≥–æ–º—É.
        
        Args:
            from_concept: –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞
            to_concept: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–Ω–µ—á–Ω–æ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞
            
        Returns:
            Dict —Å —Ü–µ–ø–æ—á–∫–æ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏–ª–∏ None
        """
        # –ù–∞–π—Ç–∏ —É–∑–ª—ã
        from_node = self.get_node_by_name(from_concept)
        to_node = self.get_node_by_name(to_concept)
        
        if not from_node or not to_node:
            return None
        
        # –ù–∞–π—Ç–∏ –ø—É—Ç—å
        path = self.find_path(from_node.id, to_node.id)
        
        if not path:
            return None
        
        # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Ü–µ–ø–æ—á–∫—É
        chain_steps = []
        for i in range(len(path) - 1):
            current_id = path[i]
            next_id = path[i + 1]
            
            # –ù–∞–π—Ç–∏ —Å–≤—è–∑—å
            edge = None
            for e in self.get_outgoing_edges(current_id):
                if e.to_id == next_id:
                    edge = e
                    break
            
            current_node = self.nodes[current_id]
            next_node = self.nodes[next_id]
            
            step = {
                "from": current_node.name,
                "to": next_node.name,
                "relation": edge.edge_type.value if edge else "unknown",
                "explanation": edge.explanation if edge else ""
            }
            chain_steps.append(step)
        
        return {
            "from_concept": from_concept,
            "to_concept": to_concept,
            "steps": chain_steps,
            "length": len(chain_steps)
        }
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≥—Ä–∞—Ñ–∞"""
        return {
            "total_nodes": len(self.nodes),
            "total_edges": len(self.edges),
            "nodes_by_type": {
                nt.value: len(self._nodes_by_type[nt])
                for nt in NodeType
            },
            "avg_connections_per_node": (
                len(self.edges) / len(self.nodes) if self.nodes else 0
            )
        }
    
    def to_dict(self) -> Dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞ –≤ dict"""
        return {
            "nodes": [node.to_dict() for node in self.nodes.values()],
            "edges": [edge.to_dict() for edge in self.edges],
            "statistics": self.get_statistics()
        }
    
    def to_json(self, filepath: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ –≤ JSON —Ñ–∞–π–ª"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, ensure_ascii=False, indent=2)
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'KnowledgeGraph':
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≥—Ä–∞—Ñ –∏–∑ dict"""
        graph = cls()
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å —É–∑–ª—ã
        for node_data in data['nodes']:
            node_data['node_type'] = NodeType(node_data['node_type'])
            node = GraphNode(**node_data)
            graph.add_node(node)
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤—è–∑–∏
        for edge_data in data['edges']:
            edge_data['edge_type'] = EdgeType(edge_data['edge_type'])
            edge = GraphEdge(**edge_data)
            graph.add_edge(edge)
        
        return graph
    
    @classmethod
    def from_json(cls, filepath: str) -> 'KnowledgeGraph':
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≥—Ä–∞—Ñ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return cls.from_dict(data)
```


***

## üìù –®–ê–ì 3: SarsekenovProcessor (–ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä)

### –§–∞–π–ª: `text_processor/orchestrator/sarsekenov_processor.py`

```python
"""
SarsekenovProcessor - –≥–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –≤—Å–µ—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤.

–ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É:
- TerminologyValidator
- NeurostalkingPatternExtractor
- CausalChainExtractor
- ConceptHierarchyExtractor

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Knowledge Graph.
"""

from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
import uuid

from text_processor.validators import TerminologyValidator
from text_processor.extractors import (
    NeurostalkingPatternExtractor,
    CausalChainExtractor,
    ConceptHierarchyExtractor
)
from text_processor.orchestrator.knowledge_graph import (
    KnowledgeGraph,
    GraphNode,
    GraphEdge,
    NodeType,
    EdgeType
)


@dataclass
class ProcessingResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
    text_id: str                     # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Ç–µ–∫—Å—Ç–∞
    is_valid: bool                   # –ü—Ä–æ—à—ë–ª –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é
    validation_reason: str           # –ü—Ä–∏—á–∏–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤
    validation_metrics: Dict
    patterns_extracted: List[Dict]
    chains_extracted: List[Dict]
    hierarchy_extracted: Optional[Dict]
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_concepts: int
    total_patterns: int
    total_chains: int
    sarsekenov_density: float
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata: Dict[str, Any]
    
    def to_dict(self) -> Dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ dict"""
        return asdict(self)


class SarsekenovProcessor:
    """
    –ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤ –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞.
    
    Workflow:
    1. –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (TerminologyValidator)
    2. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ:
       - –ü–∞—Ç—Ç–µ—Ä–Ω—ã (NeurostalkingPatternExtractor)
       - –¶–µ–ø–æ—á–∫–∏ (CausalChainExtractor)
       - –ò–µ—Ä–∞—Ä—Ö–∏—è (ConceptHierarchyExtractor)
    3. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Knowledge Graph
    4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ RAG
    
    –§–ò–õ–û–°–û–§–ò–Ø:
    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
    - –ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤
    - –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –≥—Ä–∞—Ñ
    - –ì–æ—Ç–æ–≤—ã–π API –¥–ª—è AI-–±–æ—Ç–∞
    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
    """
    
    def __init__(
        self,
        validator: Optional[TerminologyValidator] = None,
        pattern_extractor: Optional[NeurostalkingPatternExtractor] = None,
        causal_chain_extractor: Optional[CausalChainExtractor] = None,
        hierarchy_extractor: Optional[ConceptHierarchyExtractor] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞.
        
        Args:
            validator: –í–∞–ª–∏–¥–∞—Ç–æ—Ä (—Å–æ–∑–¥–∞—ë—Ç—Å—è –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω)
            pattern_extractor: –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            causal_chain_extractor: –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Ü–µ–ø–æ—á–µ–∫
            hierarchy_extractor: –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –∏–µ—Ä–∞—Ä—Ö–∏–∏
        """
        # –°–æ–∑–¥–∞—Ç—å —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã
        self.validator = validator or TerminologyValidator()
        
        self.pattern_extractor = pattern_extractor or \
            NeurostalkingPatternExtractor(terminology_validator=self.validator)
        
        self.causal_chain_extractor = causal_chain_extractor or \
            CausalChainExtractor(terminology_validator=self.validator)
        
        self.hierarchy_extractor = hierarchy_extractor or \
            ConceptHierarchyExtractor(terminology_validator=self.validator)
        
        # Knowledge Graph
        self.knowledge_graph = KnowledgeGraph()
    
    def process_text(
        self,
        text: str,
        text_id: Optional[str] = None,
        metadata: Optional[Dict] = None
    ) -> ProcessingResult:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç –≤—Å–µ–º–∏ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞–º–∏.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            text_id: ID —Ç–µ–∫—Å—Ç–∞ (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω)
            metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            
        Returns:
            ProcessingResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤—Å–µ—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤
        """
        text_id = text_id or str(uuid.uuid4())
        metadata = metadata or {}
        
        # –®–ê–ì 1: –í–ê–õ–ò–î–ê–¶–ò–Ø
        validation = self.validator.validate_text(text)
        
        if not validation.is_valid:
            return ProcessingResult(
                text_id=text_id,
                is_valid=False,
                validation_reason=validation.reason,
                validation_metrics=validation.metrics,
                patterns_extracted=[],
                chains_extracted=[],
                hierarchy_extracted=None,
                total_concepts=0,
                total_patterns=0,
                total_chains=0,
                sarsekenov_density=validation.metrics.get('density', 0.0),
                metadata=metadata
            )
        
        # –®–ê–ì 2: –ò–ó–í–õ–ï–ß–ï–ù–ò–ï (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
        patterns_result = self.pattern_extractor.extract(text)
        chains_result = self.causal_chain_extractor.extract(text)
        hierarchy_result = self.hierarchy_extractor.extract(text)
        
        # –®–ê–ì 3: –ü–û–°–¢–†–û–ï–ù–ò–ï KNOWLEDGE GRAPH
        self._build_graph_from_results(
            text_id=text_id,
            validation=validation,
            patterns_result=patterns_result,
            chains_result=chains_result,
            hierarchy_result=hierarchy_result
        )
        
        # –®–ê–ì 4: –°–û–ó–î–ê–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–ê
        result = ProcessingResult(
            text_id=text_id,
            is_valid=True,
            validation_reason=validation.reason,
            validation_metrics=validation.metrics,
            patterns_extracted=patterns_result.get('patterns', []),
            chains_extracted=chains_result.get('chains', []),
            hierarchy_extracted=hierarchy_result.get('hierarchy') if hierarchy_result['valid'] else None,
            total_concepts=self._count_concepts(hierarchy_result),
            total_patterns=len(patterns_result.get('patterns', [])),
            total_chains=len(chains_result.get('chains', [])),
            sarsekenov_density=validation.metrics['density'],
            metadata=metadata
        )
        
        return result
    
    def _build_graph_from_results(
        self,
        text_id: str,
        validation: Any,
        patterns_result: Dict,
        chains_result: Dict,
        hierarchy_result: Dict
    ) -> None:
        """
        –ü–æ—Å—Ç—Ä–æ–∏—Ç—å Knowledge Graph –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤.
        
        Args:
            text_id: ID —Ç–µ–∫—Å—Ç–∞
            validation: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            patterns_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            chains_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ü–µ–ø–æ—á–µ–∫
            hierarchy_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–µ—Ä–∞—Ä—Ö–∏–∏
        """
        
        # 1. –î–û–ë–ê–í–ò–¢–¨ –£–ó–õ–´ –ò–ó –ò–ï–†–ê–†–•–ò–ò
        if hierarchy_result['valid']:
            self._add_hierarchy_to_graph(hierarchy_result['hierarchy'], text_id)
        
        # 2. –î–û–ë–ê–í–ò–¢–¨ –ü–ê–¢–¢–ï–†–ù–´
        self._add_patterns_to_graph(patterns_result.get('patterns', []), text_id)
        
        # 3. –î–û–ë–ê–í–ò–¢–¨ –¶–ï–ü–û–ß–ö–ò
        self._add_chains_to_graph(chains_result.get('chains', []), text_id)
    
    def _add_hierarchy_to_graph(self, hierarchy: Dict, text_id: str) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—é –≤ –≥—Ä–∞—Ñ"""
        
        # Root
        root = hierarchy['root']
        root_node = GraphNode(
            id=f"{text_id}_root_{root['name']}",
            name=root['name'],
            node_type=NodeType.CONCEPT,
            description=root.get('description', ''),
            sarsekenov_terms=root.get('sarsekenov_terms', []),
            tier=1,
            metadata={"source": text_id, "level": "root"}
        )
        self.knowledge_graph.add_node(root_node)
        
        # Domains
        for domain in hierarchy.get('domains', []):
            domain_node = GraphNode(
                id=f"{text_id}_domain_{domain['name']}",
                name=domain['name'],
                node_type=NodeType.CONCEPT,
                description=domain.get('description', ''),
                sarsekenov_terms=domain.get('sarsekenov_terms', []),
                tier=2,
                metadata={"source": text_id, "level": "domain"}
            )
            domain_id = self.knowledge_graph.add_node(domain_node)
            
            # –°–≤—è–∑—å domain -> root
            edge = GraphEdge(
                from_id=domain_id,
                to_id=root_node.id,
                edge_type=EdgeType.IS_CORE_COMPONENT_OF,
                explanation=f"{domain['name']} is core component of {root['name']}"
            )
            self.knowledge_graph.add_edge(edge)
        
        # Practices
        for practice in hierarchy.get('practices', []):
            practice_node = GraphNode(
                id=f"{text_id}_practice_{practice['name']}",
                name=practice['name'],
                node_type=NodeType.PRACTICE,
                description=practice.get('description', ''),
                sarsekenov_terms=practice.get('sarsekenov_terms', []),
                tier=3,
                metadata={"source": text_id, "level": "practice"}
            )
            practice_id = self.knowledge_graph.add_node(practice_node)
            
            # –°–≤—è–∑—å practice -> domain (parent)
            parent_id = f"{text_id}_domain_{practice['parent']}"
            if parent_id in self.knowledge_graph.nodes:
                edge = GraphEdge(
                    from_id=practice_id,
                    to_id=parent_id,
                    edge_type=EdgeType.IS_PRACTICE_FOR,
                    explanation=f"{practice['name']} is practice for {practice['parent']}"
                )
                self.knowledge_graph.add_edge(edge)
        
        # Techniques
        for technique in hierarchy.get('techniques', []):
            technique_node = GraphNode(
                id=f"{text_id}_technique_{technique['name']}",
                name=technique['name'],
                node_type=NodeType.TECHNIQUE,
                description=technique.get('description', ''),
                sarsekenov_terms=technique.get('sarsekenov_terms', []),
                tier=4,
                metadata={"source": text_id, "level": "technique"}
            )
            technique_id = self.knowledge_graph.add_node(technique_node)
            
            # –°–≤—è–∑—å technique -> practice (parent)
            parent_id = f"{text_id}_practice_{technique['parent']}"
            if parent_id in self.knowledge_graph.nodes:
                edge = GraphEdge(
                    from_id=technique_id,
                    to_id=parent_id,
                    edge_type=EdgeType.IS_TECHNIQUE_FOR,
                    explanation=f"{technique['name']} is technique for {technique['parent']}"
                )
                self.knowledge_graph.add_edge(edge)
        
        # Exercises
        for exercise in hierarchy.get('exercises', []):
            exercise_node = GraphNode(
                id=f"{text_id}_exercise_{exercise['name']}",
                name=exercise['name'],
                node_type=NodeType.EXERCISE,
                description=exercise.get('description', ''),
                sarsekenov_terms=[],
                metadata={
                    "source": text_id,
                    "level": "exercise",
                    "duration": exercise.get('duration'),
                    "frequency": exercise.get('frequency'),
                    "instructions": exercise.get('instructions')
                }
            )
            exercise_id = self.knowledge_graph.add_node(exercise_node)
            
            # –°–≤—è–∑—å exercise -> technique (parent)
            parent_id = f"{text_id}_technique_{exercise['parent']}"
            if parent_id in self.knowledge_graph.nodes:
                edge = GraphEdge(
                    from_id=exercise_id,
                    to_id=parent_id,
                    edge_type=EdgeType.IS_EXERCISE_FOR,
                    explanation=f"{exercise['name']} is exercise for {exercise['parent']}"
                )
                self.knowledge_graph.add_edge(edge)
        
        # Cross-connections
        for conn in hierarchy.get('cross_connections', []):
            from_concept = self.knowledge_graph.get_node_by_name(conn['from_concept'])
            to_concept = self.knowledge_graph.get_node_by_name(conn['to_concept'])
            
            if from_concept and to_concept:
                edge_type_map = {
                    "enables": EdgeType.ENABLES,
                    "requires": EdgeType.REQUIRES,
                    "leads_to": EdgeType.LEADS_TO,
                    "transforms_into": EdgeType.TRANSFORMS_INTO
                }
                
                edge = GraphEdge(
                    from_id=from_concept.id,
                    to_id=to_concept.id,
                    edge_type=edge_type_map.get(conn['relation'], EdgeType.RELATED_TO),
                    explanation=conn.get('explanation', '')
                )
                self.knowledge_graph.add_edge(edge)
    
    def _add_patterns_to_graph(self, patterns: List[Dict], text_id: str) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –≥—Ä–∞—Ñ"""
        
        for pattern in patterns:
            pattern_node = GraphNode(
                id=f"{text_id}_pattern_{pattern['pattern_name']}",
                name=pattern['pattern_name'],
                node_type=NodeType.PATTERN,
                description=pattern.get('description', ''),
                sarsekenov_terms=pattern.get('key_terms', []),
                confidence=pattern.get('confidence', 1.0),
                metadata={
                    "source": text_id,
                    "category": pattern['pattern_category'],
                    "typical_context": pattern.get('typical_context', ''),
                    "related_practices": pattern.get('related_practices', [])
                }
            )
            pattern_id = self.knowledge_graph.add_node(pattern_node)
            
            # –°–≤—è–∑–∞—Ç—å —Å –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏
            for practice_name in pattern.get('related_practices', []):
                practice_node = self.knowledge_graph.get_node_by_name(practice_name)
                if practice_node:
                    edge = GraphEdge(
                        from_id=pattern_id,
                        to_id=practice_node.id,
                        edge_type=EdgeType.RELATED_TO,
                        explanation=f"Pattern {pattern['pattern_name']} relates to {practice_name}"
                    )
                    self.knowledge_graph.add_edge(edge)
    
    def _add_chains_to_graph(self, chains: List[Dict], text_id: str) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å —Ü–µ–ø–æ—á–∫–∏ –≤ –≥—Ä–∞—Ñ"""
        
        for chain_idx, chain in enumerate(chains):
            # –°–æ–∑–¥–∞—Ç—å —É–∑–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞
            stage_ids = []
            
            for stage in chain['stages']:
                stage_node = GraphNode(
                    id=f"{text_id}_chain{chain_idx}_stage{stage['stage']}",
                    name=stage['stage_name'],
                    node_type=NodeType.PROCESS_STAGE,
                    description=stage.get('description', ''),
                    sarsekenov_terms=stage.get('sarsekenov_terms', []),
                    metadata={
                        "source": text_id,
                        "chain_category": chain['process_category'],
                        "stage_number": stage['stage']
                    }
                )
                stage_id = self.knowledge_graph.add_node(stage_node)
                stage_ids.append((stage['stage'], stage_id))
            
            # –°–æ–∑–¥–∞—Ç—å —Å–≤—è–∑–∏ –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏
            for i in range(len(stage_ids) - 1):
                current_stage_num, current_id = stage_ids[i]
                next_stage_num, next_id = stage_ids[i + 1]
                
                edge = GraphEdge(
                    from_id=current_id,
                    to_id=next_id,
                    edge_type=EdgeType.EMERGES_FROM,
                    explanation=f"Stage {next_stage_num} emerges from stage {current_stage_num}",
                    confidence=chain.get('confidence', 1.0)
                )
                self.knowledge_graph.add_edge(edge)
    
    def _count_concepts(self, hierarchy_result: Dict) -> int:
        """–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –≤ –∏–µ—Ä–∞—Ä—Ö–∏–∏"""
        if not hierarchy_result.get('valid'):
            return 0
        
        hierarchy = hierarchy_result['hierarchy']
        return (
            1 +  # root
            len(hierarchy.get('domains', [])) +
            len(hierarchy.get('practices', [])) +
            len(hierarchy.get('techniques', [])) +
            len(hierarchy.get('exercises', []))
        )
    
    def get_knowledge_graph(self) -> KnowledgeGraph:
        """–ü–æ–ª—É—á–∏—Ç—å Knowledge Graph"""
        return self.knowledge_graph
    
    def find_practices_for_symptom(self, symptom: str) -> List[Dict]:
        """
        –ù–∞–π—Ç–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–∏–º–ø—Ç–æ–º–æ–º.
        
        Args:
            symptom: –û–ø–∏—Å–∞–Ω–∏–µ —Å–∏–º–ø—Ç–æ–º–∞ (–Ω–∞–ø—Ä. "–∑–∞—Ö–≤–∞—Ç –≤–Ω–∏–º–∞–Ω–∏—è")
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–∞–∫—Ç–∏–∫ —Å reasoning chains
        """
        # –ù–∞–π—Ç–∏ —É–∑–µ–ª —Å–∏–º–ø—Ç–æ–º–∞
        symptom_node = self.knowledge_graph.get_node_by_name(symptom)
        
        if not symptom_node:
            return []
        
        # –ù–∞–π—Ç–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏
        practices = []
        for edge in self.knowledge_graph.get_outgoing_edges(symptom_node.id):
            if edge.edge_type in [EdgeType.REQUIRES, EdgeType.ENABLES]:
                target_node = self.knowledge_graph.get_node(edge.to_id)
                if target_node and target_node.node_type == NodeType.PRACTICE:
                    practices.append({
                        "practice": target_node.name,
                        "relation": edge.edge_type.value,
                        "explanation": edge.explanation,
                        "confidence": edge.confidence
                    })
        
        return practices
    
    def recommend_exercise(
        self,
        practice: str,
        duration: Optional[str] = None
    ) -> Optional[Dict]:
        """
        –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ –¥–ª—è –ø—Ä–∞–∫—Ç–∏–∫–∏.
        
        Args:
            practice: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏
            duration: –ñ–µ–ª–∞–µ–º–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–Ω–∞–ø—Ä. "5-10 –º–∏–Ω—É—Ç")
            
        Returns:
            Dict —Å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ–º –∏–ª–∏ None
        """
        practice_node = self.knowledge_graph.get_node_by_name(practice)
        
        if not practice_node:
            return None
        
        # –ù–∞–π—Ç–∏ technique –¥–ª—è —ç—Ç–æ–π –ø—Ä–∞–∫—Ç–∏–∫–∏
        techniques = []
        for edge in self.knowledge_graph.get_incoming_edges(practice_node.id):
            if edge.edge_type == EdgeType.IS_TECHNIQUE_FOR:
                source_node = self.knowledge_graph.get_node(edge.from_id)
                if source_node:
                    techniques.append(source_node)
        
        if not techniques:
            return None
        
        # –ù–∞–π—Ç–∏ exercises –¥–ª—è –ø–µ—Ä–≤–æ–π —Ç–µ—Ö–Ω–∏–∫–∏
        technique = techniques[0]
        for edge in self.knowledge_graph.get_incoming_edges(technique.id):
            if edge.edge_type == EdgeType.IS_EXERCISE_FOR:
                exercise_node = self.knowledge_graph.get_node(edge.from_id)
                if exercise_node:
                    exercise_duration = exercise_node.metadata.get('duration')
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞
                    if duration and exercise_duration and duration not in exercise_duration:
                        continue
                    
                    return {
                        "exercise": exercise_node.name,
                        "technique": technique.name,
                        "practice": practice,
                        "duration": exercise_duration,
                        "frequency": exercise_node.metadata.get('frequency'),
                        "instructions": exercise_node.metadata.get('instructions')
                    }
        
        return None
```


***



–ü—Ä–æ–¥–æ–ª–∂–∞—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è –≠—Ç–∞–ø–∞ ‚Ññ5!

***

## üìù –®–ê–ì 4: RAG Formatter (–≠–∫—Å–ø–æ—Ä—Ç –¥–ª—è RAG)

### –§–∞–π–ª: `text_processor/export/rag_formatter.py`

```python
"""
RAG Formatter - –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ RAG —Å–∏—Å—Ç–µ–º—É.

–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç Knowledge Graph –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î:
- –î–æ–∫—É–º–µ–Ω—Ç—ã —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
- Embeddings-ready —Ñ–æ—Ä–º–∞—Ç
"""

from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import json

from text_processor.orchestrator.knowledge_graph import (
    KnowledgeGraph,
    GraphNode,
    NodeType
)


@dataclass
class RAGDocument:
    """–î–æ–∫—É–º–µ–Ω—Ç –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã"""
    id: str                          # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
    content: str                     # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è embedding
    metadata: Dict[str, Any]         # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
    node_type: str                   # –¢–∏–ø —É–∑–ª–∞
    sarsekenov_terms: List[str]      # –¢–µ—Ä–º–∏–Ω—ã –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞
    tier: Optional[int] = None       # Tier (1-6)
    confidence: float = 1.0          # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    
    def to_dict(self) -> Dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ dict"""
        return asdict(self)


class RAGFormatter:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Knowledge Graph –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã.
    
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≥—Ä–∞—Ñ –≤ –Ω–∞–±–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î:
    1. –ö–∞–∂–¥—ã–π —É–∑–µ–ª ‚Üí –¥–æ–∫—É–º–µ–Ω—Ç
    2. –°–≤—è–∑–∏ ‚Üí –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    3. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è embedding –º–æ–¥–µ–ª–µ–π
    
    –§–ò–õ–û–°–û–§–ò–Ø:
    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
    - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ content
    - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–æ—á–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    - –°–≤—è–∑–∏ –¥–ª—è reasoning chains
    - –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –¥–ª—è embedding –º–æ–¥–µ–ª–µ–π
    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
    """
    
    def __init__(self, knowledge_graph: KnowledgeGraph):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä–∞.
        
        Args:
            knowledge_graph: –ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        self.graph = knowledge_graph
    
    def format_for_rag(self) -> List[RAGDocument]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã.
        
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
        """
        documents = []
        
        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —É–∑–ª—ã
        for node_id, node in self.graph.nodes.items():
            doc = self._node_to_document(node)
            documents.append(doc)
        
        return documents
    
    def _node_to_document(self, node: GraphNode) -> RAGDocument:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —É–∑–µ–ª –≥—Ä–∞—Ñ–∞ –≤ RAG –¥–æ–∫—É–º–µ–Ω—Ç.
        
        Args:
            node: –£–∑–µ–ª –≥—Ä–∞—Ñ–∞
            
        Returns:
            RAG –¥–æ–∫—É–º–µ–Ω—Ç
        """
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ content (—Ç–µ–∫—Å—Ç –¥–ª—è embedding)
        content_parts = [
            f"–ö–æ–Ω—Ü–µ–ø—Ç: {node.name}",
            f"–û–ø–∏—Å–∞–Ω–∏–µ: {node.description}"
        ]
        
        # –î–æ–±–∞–≤–∏—Ç—å —Ç–µ—Ä–º–∏–Ω—ã –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤–∞
        if node.sarsekenov_terms:
            terms_str = ", ".join(node.sarsekenov_terms)
            content_parts.append(f"–ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã: {terms_str}")
        
        # –î–æ–±–∞–≤–∏—Ç—å —Ç–∏–ø —É–∑–ª–∞
        content_parts.append(f"–¢–∏–ø: {node.node_type.value}")
        
        # –î–æ–±–∞–≤–∏—Ç—å —Å–≤—è–∑–∏
        outgoing_edges = self.graph.get_outgoing_edges(node.id)
        if outgoing_edges:
            relations = []
            for edge in outgoing_edges:
                target_node = self.graph.get_node(edge.to_id)
                if target_node:
                    relations.append(
                        f"{edge.edge_type.value} ‚Üí {target_node.name}"
                    )
            if relations:
                content_parts.append(f"–°–≤—è–∑–∏: {'; '.join(relations)}")
        
        content = "\n".join(content_parts)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata = {
            "node_id": node.id,
            "node_name": node.name,
            "node_type": node.node_type.value,
            "tier": node.tier,
            "confidence": node.confidence,
            "sarsekenov_terms": node.sarsekenov_terms,
            "source": node.metadata.get("source", "unknown")
        }
        
        # –î–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if node.node_type == NodeType.EXERCISE:
            metadata.update({
                "duration": node.metadata.get("duration"),
                "frequency": node.metadata.get("frequency"),
                "has_instructions": bool(node.metadata.get("instructions"))
            })
        
        if node.node_type == NodeType.PATTERN:
            metadata.update({
                "pattern_category": node.metadata.get("category"),
                "related_practices": node.metadata.get("related_practices", [])
            })
        
        # –°–æ–∑–¥–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç
        return RAGDocument(
            id=node.id,
            content=content,
            metadata=metadata,
            node_type=node.node_type.value,
            sarsekenov_terms=node.sarsekenov_terms,
            tier=node.tier,
            confidence=node.confidence
        )
    
    def export_to_json(self, filepath: str) -> None:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ JSON —Ñ–∞–π–ª.
        
        Args:
            filepath: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        documents = self.format_for_rag()
        
        data = {
            "documents": [doc.to_dict() for doc in documents],
            "total_documents": len(documents),
            "graph_statistics": self.graph.get_statistics()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def get_documents_by_type(
        self,
        node_type: NodeType
    ) -> List[RAGDocument]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞.
        
        Args:
            node_type: –¢–∏–ø —É–∑–ª–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞
        """
        documents = self.format_for_rag()
        return [
            doc for doc in documents
            if doc.node_type == node_type.value
        ]
    
    def get_documents_by_tier(self, tier: int) -> List[RAGDocument]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ tier.
        
        Args:
            tier: Tier (1-6)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ tier
        """
        documents = self.format_for_rag()
        return [
            doc for doc in documents
            if doc.tier == tier
        ]
    
    def format_for_embedding_model(
        self,
        model_name: str = "multilingual-e5-large"
    ) -> List[Dict[str, Any]]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π embedding –º–æ–¥–µ–ª–∏.
        
        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –º–æ–¥–µ–ª–∏
        """
        documents = self.format_for_rag()
        
        if "e5" in model_name.lower():
            # –§–æ—Ä–º–∞—Ç –¥–ª—è E5 –º–æ–¥–µ–ª–µ–π: "query: " –∏–ª–∏ "passage: "
            return [
                {
                    "id": doc.id,
                    "text": f"passage: {doc.content}",
                    "metadata": doc.metadata
                }
                for doc in documents
            ]
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        return [
            {
                "id": doc.id,
                "text": doc.content,
                "metadata": doc.metadata
            }
            for doc in documents
        ]


# ============================================================================
# HELPER: Utility —Ñ—É–Ω–∫—Ü–∏–∏
# ============================================================================

def format_knowledge_graph(
    knowledge_graph: KnowledgeGraph,
    output_format: str = "rag"
) -> Any:
    """
    –ë—ã—Å—Ç—Ä–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Knowledge Graph.
    
    Args:
        knowledge_graph: –ì—Ä–∞—Ñ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        output_format: –§–æ—Ä–º–∞—Ç ("rag", "json", "embedding")
        
    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    formatter = RAGFormatter(knowledge_graph)
    
    if output_format == "rag":
        return formatter.format_for_rag()
    elif output_format == "json":
        return [doc.to_dict() for doc in formatter.format_for_rag()]
    elif output_format == "embedding":
        return formatter.format_for_embedding_model()
    else:
        raise ValueError(f"Unknown format: {output_format}")
```


***

## üìù –®–ê–ì 5: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ __init__.py

### –§–∞–π–ª: `text_processor/orchestrator/__init__.py`

```python
"""
Orchestrator module - –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≤—Å–µ—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤.

–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç:
- SarsekenovProcessor: –≥–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
- KnowledgeGraph: –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π
- NodeType, EdgeType: —Ç–∏–ø—ã –¥–ª—è –≥—Ä–∞—Ñ–∞
"""

from text_processor.orchestrator.sarsekenov_processor import (
    SarsekenovProcessor,
    ProcessingResult
)
from text_processor.orchestrator.knowledge_graph import (
    KnowledgeGraph,
    GraphNode,
    GraphEdge,
    NodeType,
    EdgeType
)

__all__ = [
    'SarsekenovProcessor',
    'ProcessingResult',
    'KnowledgeGraph',
    'GraphNode',
    'GraphEdge',
    'NodeType',
    'EdgeType'
]
```


### –§–∞–π–ª: `text_processor/export/__init__.py`

```python
"""
Export module - —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è RAG —Å–∏—Å—Ç–µ–º.

–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç:
- RAGFormatter: —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è RAG
- RAGDocument: –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
- format_knowledge_graph: utility —Ñ—É–Ω–∫—Ü–∏—è
"""

from text_processor.export.rag_formatter import (
    RAGFormatter,
    RAGDocument,
    format_knowledge_graph
)

__all__ = [
    'RAGFormatter',
    'RAGDocument',
    'format_knowledge_graph'
]
```


***

## üìù –®–ê–ì 6: –¢–µ—Å—Ç—ã –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞

### –§–∞–π–ª: `tests/orchestrator/test_sarsekenov_processor.py`

```python
"""
–¢–µ—Å—Ç—ã –¥–ª—è SarsekenovProcessor.

–ü—Ä–æ–≤–µ—Ä—è—é—Ç:
- –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—é —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Knowledge Graph
- API –¥–ª—è AI-–±–æ—Ç–∞
"""

import pytest
from text_processor.orchestrator import (
    SarsekenovProcessor,
    KnowledgeGraph,
    NodeType,
    EdgeType
)
from tests.fixtures.real_sarsekenov_texts import (
    TRIADA_TRANSFORMATION_TEXT,
    HIERARCHY_PRACTICES_TEXT
)


@pytest.fixture
def processor():
    """–§–∏–∫—Å—Ç—É—Ä–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
    return SarsekenovProcessor()


class TestSarsekenovProcessor:
    """–¢–µ—Å—Ç—ã –≥–ª–∞–≤–Ω–æ–≥–æ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
    
    def test_process_text_full_workflow(self, processor):
        """
        –¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ workflow –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞.
        
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
        1. –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—Ö–æ–¥–∏—Ç
        2. –í—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –æ—Ç—Ä–∞–±–æ—Ç–∞–ª–∏
        3. Knowledge Graph –ø–æ—Å—Ç—Ä–æ–µ–Ω
        4. –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª–Ω—ã–π
        """
        text = TRIADA_TRANSFORMATION_TEXT
        
        result = processor.process_text(text, text_id="test_001")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        assert result.is_valid, f"Validation failed: {result.validation_reason}"
        assert result.sarsekenov_density >= 0.15
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        assert len(result.patterns_extracted) > 0, "No patterns extracted"
        assert len(result.chains_extracted) > 0, "No chains extracted"
        assert result.hierarchy_extracted is not None, "No hierarchy extracted"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        assert result.total_concepts > 0
        assert result.total_patterns > 0
        assert result.total_chains > 0
        
        print(f"\n‚úÖ FULL WORKFLOW TEST PASSED")
        print(f"   Concepts: {result.total_concepts}")
        print(f"   Patterns: {result.total_patterns}")
        print(f"   Chains: {result.total_chains}")
        print(f"   Density: {result.sarsekenov_density:.1%}")
    
    def test_knowledge_graph_built(self, processor):
        """–¢–µ—Å—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è Knowledge Graph"""
        text = TRIADA_TRANSFORMATION_TEXT
        
        result = processor.process_text(text, text_id="test_002")
        
        # –ü–æ–ª—É—á–∏—Ç—å –≥—Ä–∞—Ñ
        graph = processor.get_knowledge_graph()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –≥—Ä–∞—Ñ –Ω–µ –ø—É—Å—Ç
        assert len(graph.nodes) > 0, "Graph is empty"
        assert len(graph.edges) > 0, "No edges in graph"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        stats = graph.get_statistics()
        print(f"\n‚úÖ KNOWLEDGE GRAPH BUILT")
        print(f"   Total nodes: {stats['total_nodes']}")
        print(f"   Total edges: {stats['total_edges']}")
        print(f"   Nodes by type: {stats['nodes_by_type']}")
    
    def test_hierarchy_nodes_in_graph(self, processor):
        """–¢–µ—Å—Ç —á—Ç–æ —É–∑–ª—ã –∏–µ—Ä–∞—Ä—Ö–∏–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –≥—Ä–∞—Ñ"""
        text = HIERARCHY_PRACTICES_TEXT
        
        result = processor.process_text(text, text_id="test_003")
        graph = processor.get_knowledge_graph()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —É–∑–ª–æ–≤ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
        concepts = graph.get_nodes_by_type(NodeType.CONCEPT)
        practices = graph.get_nodes_by_type(NodeType.PRACTICE)
        techniques = graph.get_nodes_by_type(NodeType.TECHNIQUE)
        
        assert len(concepts) > 0, "No concept nodes"
        assert len(practices) > 0, "No practice nodes"
        
        print(f"\n‚úÖ HIERARCHY NODES IN GRAPH")
        print(f"   Concepts: {len(concepts)}")
        print(f"   Practices: {len(practices)}")
        print(f"   Techniques: {len(techniques)}")
    
    def test_find_practices_for_symptom(self, processor):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –ø—Ä–∞–∫—Ç–∏–∫ –ø–æ —Å–∏–º–ø—Ç–æ–º—É"""
        text = TRIADA_TRANSFORMATION_TEXT
        
        result = processor.process_text(text, text_id="test_004")
        
        # –ü–æ–∏—Å–∫ –ø—Ä–∞–∫—Ç–∏–∫ –¥–ª—è "–∑–∞—Ö–≤–∞—Ç –≤–Ω–∏–º–∞–Ω–∏—è"
        practices = processor.find_practices_for_symptom("–∑–∞—Ö–≤–∞—Ç –≤–Ω–∏–º–∞–Ω–∏—è")
        
        # –ú–æ–∂–µ—Ç –Ω–µ –Ω–∞–π—Ç–∏ –µ—Å–ª–∏ –∫–æ–Ω—Ü–µ–ø—Ç –Ω–µ –≤ —Ç–µ–∫—Å—Ç–µ
        print(f"\n   Practices found for '–∑–∞—Ö–≤–∞—Ç –≤–Ω–∏–º–∞–Ω–∏—è': {len(practices)}")
    
    def test_recommend_exercise(self, processor):
        """–¢–µ—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è"""
        text = HIERARCHY_PRACTICES_TEXT
        
        result = processor.process_text(text, text_id="test_005")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –¥–ª—è –º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏—è
        exercise = processor.recommend_exercise("–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ")
        
        if exercise:
            print(f"\n‚úÖ EXERCISE RECOMMENDED")
            print(f"   Exercise: {exercise['exercise']}")
            print(f"   Duration: {exercise.get('duration')}")
            print(f"   Frequency: {exercise.get('frequency')}")
        else:
            print(f"\n   No exercise found for '–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ'")
    
    def test_invalid_text_rejected(self, processor):
        """–¢–µ—Å—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        text = "–û–±—â–∞—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è –∏ —Ç–µ—Ä–∞–ø–∏—è —Å—Ç—Ä–µ—Å—Å–∞."
        
        result = processor.process_text(text, text_id="test_006")
        
        # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç–∫–ª–æ–Ω—ë–Ω
        assert not result.is_valid
        assert result.total_concepts == 0
        assert result.total_patterns == 0
        
        print(f"\n‚úÖ INVALID TEXT REJECTED")
        print(f"   Reason: {result.validation_reason}")
    
    def test_metadata_preserved(self, processor):
        """–¢–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        text = TRIADA_TRANSFORMATION_TEXT
        metadata = {
            "source": "lecture_001",
            "author": "–°–∞–ª–∞–º–∞—Ç –°–∞—Ä—Å–µ–∫–µ–Ω–æ–≤",
            "date": "2024-12-08"
        }
        
        result = processor.process_text(
            text,
            text_id="test_007",
            metadata=metadata
        )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        assert result.metadata == metadata
        
        print(f"\n‚úÖ METADATA PRESERVED")
        print(f"   Source: {result.metadata['source']}")
    
    def test_multiple_texts_processing(self, processor):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
        texts = [
            TRIADA_TRANSFORMATION_TEXT,
            HIERARCHY_PRACTICES_TEXT
        ]
        
        results = []
        for i, text in enumerate(texts):
            result = processor.process_text(text, text_id=f"test_multi_{i}")
            results.append(result)
        
        # –í—Å–µ —Ç–µ–∫—Å—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
        assert all(r.is_valid for r in results)
        
        # –ì—Ä–∞—Ñ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —É–∑–ª—ã –∏–∑ –æ–±–æ–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
        graph = processor.get_knowledge_graph()
        stats = graph.get_statistics()
        
        print(f"\n‚úÖ MULTIPLE TEXTS PROCESSED")
        print(f"   Total nodes: {stats['total_nodes']}")
        print(f"   Total edges: {stats['total_edges']}")


class TestKnowledgeGraphAPI:
    """–¢–µ—Å—Ç—ã API –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π"""
    
    def test_find_path_between_concepts(self, processor):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –ø—É—Ç–∏ –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏"""
        text = TRIADA_TRANSFORMATION_TEXT
        
        processor.process_text(text, text_id="test_path")
        graph = processor.get_knowledge_graph()
        
        # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –ø—É—Ç—å
        # (–º–æ–∂–µ—Ç –Ω–µ –Ω–∞–π—Ç–∏ –µ—Å–ª–∏ –∫–æ–Ω—Ü–µ–ø—Ç—ã –Ω–µ —Å–≤—è–∑–∞–Ω—ã)
        nodes = list(graph.nodes.keys())
        if len(nodes) >= 2:
            path = graph.find_path(nodes[0], nodes[1])
            print(f"\n   Path found: {path is not None}")
    
    def test_build_reasoning_chain(self, processor):
        """–¢–µ—Å—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è reasoning chain"""
        text = TRIADA_TRANSFORMATION_TEXT
        
        processor.process_text(text, text_id="test_reasoning")
        graph = processor.get_knowledge_graph()
        
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ü–µ–ø–æ—á–∫—É
        chain = graph.build_reasoning_chain(
            "–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ",
            "—á–∏—Å—Ç–æ–µ –æ—Å–æ–∑–Ω–∞–≤–∞–Ω–∏–µ"
        )
        
        if chain:
            print(f"\n‚úÖ REASONING CHAIN BUILT")
            print(f"   From: {chain['from_concept']}")
            print(f"   To: {chain['to_concept']}")
            print(f"   Steps: {chain['length']}")
        else:
            print(f"\n   No reasoning chain found")
```


***

## üìù –®–ê–ì 7: –¢–µ—Å—Ç—ã Knowledge Graph

### –§–∞–π–ª: `tests/orchestrator/test_knowledge_graph.py`

```python
"""
–¢–µ—Å—Ç—ã –¥–ª—è KnowledgeGraph.

–ü—Ä–æ–≤–µ—Ä—è—é—Ç:
- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤ –∏ —Å–≤—è–∑–µ–π
- –ü–æ–∏—Å–∫ –ø–æ –≥—Ä–∞—Ñ—É
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—É—Ç–µ–π
- –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é
"""

import pytest
import tempfile
import os

from text_processor.orchestrator import (
    KnowledgeGraph,
    GraphNode,
    GraphEdge,
    NodeType,
    EdgeType
)


@pytest.fixture
def empty_graph():
    """–ü—É—Å—Ç–æ–π –≥—Ä–∞—Ñ"""
    return KnowledgeGraph()


@pytest.fixture
def sample_graph():
    """–ì—Ä–∞—Ñ —Å –ø—Ä–∏–º–µ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö"""
    graph = KnowledgeGraph()
    
    # –°–æ–∑–¥–∞—Ç—å —É–∑–ª—ã
    root = GraphNode(
        id="root_1",
        name="–Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥",
        node_type=NodeType.CONCEPT,
        description="–ö–æ—Ä–µ–Ω—å —É—á–µ–Ω–∏—è",
        sarsekenov_terms=["–Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥"],
        tier=1
    )
    
    domain = GraphNode(
        id="domain_1",
        name="–ø–æ–ª–µ –≤–Ω–∏–º–∞–Ω–∏—è",
        node_type=NodeType.CONCEPT,
        description="–î–æ–º–µ–Ω–Ω–∞—è –æ–±–ª–∞—Å—Ç—å",
        sarsekenov_terms=["–ø–æ–ª–µ –≤–Ω–∏–º–∞–Ω–∏—è"],
        tier=2
    )
    
    practice = GraphNode(
        id="practice_1",
        name="–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ",
        node_type=NodeType.PRACTICE,
        description="–ü—Ä–∞–∫—Ç–∏–∫–∞ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è",
        sarsekenov_terms=["–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ"],
        tier=3
    )
    
    # –î–æ–±–∞–≤–∏—Ç—å —É–∑–ª—ã
    graph.add_node(root)
    graph.add_node(domain)
    graph.add_node(practice)
    
    # –°–æ–∑–¥–∞—Ç—å —Å–≤—è–∑–∏
    edge1 = GraphEdge(
        from_id="domain_1",
        to_id="root_1",
        edge_type=EdgeType.IS_CORE_COMPONENT_OF,
        explanation="Domain is core component of root"
    )
    
    edge2 = GraphEdge(
        from_id="practice_1",
        to_id="domain_1",
        edge_type=EdgeType.IS_PRACTICE_FOR,
        explanation="Practice is for domain"
    )
    
    graph.add_edge(edge1)
    graph.add_edge(edge2)
    
    return graph


class TestGraphConstruction:
    """–¢–µ—Å—Ç—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞"""
    
    def test_add_node(self, empty_graph):
        """–¢–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —É–∑–ª–∞"""
        node = GraphNode(
            id="test_1",
            name="—Ç–µ—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ü–µ–ø—Ç",
            node_type=NodeType.CONCEPT,
            description="–û–ø–∏—Å–∞–Ω–∏–µ",
            sarsekenov_terms=["—Ç–µ—Ä–º–∏–Ω1"]
        )
        
        node_id = empty_graph.add_node(node)
        
        assert node_id == "test_1"
        assert len(empty_graph.nodes) == 1
        assert empty_graph.get_node("test_1") is not None
    
    def test_add_duplicate_node_merges(self, empty_graph):
        """–¢–µ—Å—Ç —á—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç—ã –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è"""
        node1 = GraphNode(
            id="dup_1",
            name="–∫–æ–Ω—Ü–µ–ø—Ç",
            node_type=NodeType.CONCEPT,
            description="–ü–µ—Ä–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ",
            sarsekenov_terms=["—Ç–µ—Ä–º–∏–Ω1"]
        )
        
        node2 = GraphNode(
            id="dup_2",
            name="–∫–æ–Ω—Ü–µ–ø—Ç",  # –¢–æ –∂–µ –∏–º—è!
            node_type=NodeType.CONCEPT,
            description="–í—Ç–æ—Ä–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ",
            sarsekenov_terms=["—Ç–µ—Ä–º–∏–Ω2"],
            confidence=0.9
        )
        
        id1 = empty_graph.add_node(node1)
        id2 = empty_graph.add_node(node2)
        
        # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–æ—Ç –∂–µ ID (merge)
        assert id1 == id2
        assert len(empty_graph.nodes) == 1
        
        # Confidence –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π
        merged_node = empty_graph.get_node(id1)
        assert merged_node.confidence == max(1.0, 0.9)
    
    def test_add_edge(self, sample_graph):
        """–¢–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–≤—è–∑–∏"""
        assert len(sample_graph.edges) == 2
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤
        outgoing = sample_graph.get_outgoing_edges("domain_1")
        assert len(outgoing) == 1
        assert outgoing[0].to_id == "root_1"
        
        incoming = sample_graph.get_incoming_edges("root_1")
        assert len(incoming) == 1
        assert incoming[0].from_id == "domain_1"
    
    def test_add_edge_invalid_nodes_raises(self, empty_graph):
        """–¢–µ—Å—Ç —á—Ç–æ —Å–≤—è–∑—å —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —É–∑–ª–∞–º–∏ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–∫—É"""
        edge = GraphEdge(
            from_id="nonexistent_1",
            to_id="nonexistent_2",
            edge_type=EdgeType.ENABLES,
            explanation="Test"
        )
        
        with pytest.raises(ValueError):
            empty_graph.add_edge(edge)


class TestGraphQueries:
    """–¢–µ—Å—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –≥—Ä–∞—Ñ—É"""
    
    def test_get_node_by_name(self, sample_graph):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –ø–æ –∏–º–µ–Ω–∏"""
        node = sample_graph.get_node_by_name("–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ")
        
        assert node is not None
        assert node.id == "practice_1"
        assert node.node_type == NodeType.PRACTICE
    
    def test_get_nodes_by_type(self, sample_graph):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –ø–æ —Ç–∏–ø—É"""
        concepts = sample_graph.get_nodes_by_type(NodeType.CONCEPT)
        practices = sample_graph.get_nodes_by_type(NodeType.PRACTICE)
        
        assert len(concepts) == 2  # root + domain
        assert len(practices) == 1
    
    def test_find_path(self, sample_graph):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –ø—É—Ç–∏"""
        path = sample_graph.find_path("practice_1", "root_1")
        
        assert path is not None
        assert len(path) == 3  # practice -> domain -> root
        assert path == ["practice_1", "domain_1", "root_1"]
    
    def test_find_path_no_connection(self, sample_graph):
        """–¢–µ—Å—Ç —á—Ç–æ –ø—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω –µ—Å–ª–∏ –Ω–µ—Ç —Å–≤—è–∑–∏"""
        # –î–æ–±–∞–≤–∏—Ç—å –Ω–µ—Å–≤—è–∑–∞–Ω–Ω—ã–π —É–∑–µ–ª
        isolated = GraphNode(
            id="isolated_1",
            name="–∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π",
            node_type=NodeType.CONCEPT,
            description="–ë–µ–∑ —Å–≤—è–∑–µ–π",
            sarsekenov_terms=[]
        )
        sample_graph.add_node(isolated)
        
        path = sample_graph.find_path("practice_1", "isolated_1")
        
        assert path is None
    
    def test_build_reasoning_chain(self, sample_graph):
        """–¢–µ—Å—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è reasoning chain"""
        chain = sample_graph.build_reasoning_chain(
            "–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ",
            "–Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥"
        )
        
        assert chain is not None
        assert chain['from_concept'] == "–º–µ—Ç–∞–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ"
        assert chain['to_concept'] == "–Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥"
        assert chain['length'] == 2  # practice -> domain -> root
        assert len(chain['steps']) == 2


class TestGraphSerialization:
    """–¢–µ—Å—Ç—ã —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∞"""
    
    def test_to_dict(self, sample_graph):
        """–¢–µ—Å—Ç —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ dict"""
        data = sample_graph.to_dict()
        
        assert 'nodes' in data
        assert 'edges' in data
        assert 'statistics' in data
        
        assert len(data['nodes']) == 3
        assert len(data['edges']) == 2
    
    def test_to_json_and_back(self, sample_graph):
        """–¢–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ JSON –∏ –∑–∞–≥—Ä—É–∑–∫–∏"""
        # –°–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(
            mode='w',
            suffix='.json',
            delete=False
        ) as f:
            filepath = f.name
        
        try:
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
            sample_graph.to_json(filepath)
            
            # –ó–∞–≥—Ä—É–∑–∏—Ç—å
            loaded_graph = KnowledgeGraph.from_json(filepath)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç
            assert len(loaded_graph.nodes) == len(sample_graph.nodes)
            assert len(loaded_graph.edges) == len(sample_graph.edges)
            
        finally:
            # –£–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if os.path.exists(filepath):
                os.remove(filepath)
    
    def test_get_statistics(self, sample_graph):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        stats = sample_graph.get_statistics()
        
        assert stats['total_nodes'] == 3
        assert stats['total_edges'] == 2
        assert 'nodes_by_type' in stats
        assert stats['nodes_by_type']['concept'] == 2
        assert stats['nodes_by_type']['practice'] == 1
```


***

## üìù –®–ê–ì 8: –¢–µ—Å—Ç—ã RAG Formatter

### –§–∞–π–ª: `tests/orchestrator/test_rag_formatter.py`

```python
"""
–¢–µ—Å—Ç—ã –¥–ª—è RAGFormatter.

–ü—Ä–æ–≤–µ—Ä—è—é—Ç:
- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –¥–ª—è RAG
- –≠–∫—Å–ø–æ—Ä—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- –§–æ—Ä–º–∞—Ç—ã –¥–ª—è embedding –º–æ–¥–µ–ª–µ–π
"""

import pytest
import tempfile
import os
import json

from text_processor.orchestrator import (
    SarsekenovProcessor,
    KnowledgeGraph
)
from text_processor.export import (
    RAGFormatter,
    RAGDocument,
    format_knowledge_graph
)
from tests.fixtures.real_sarsekenov_texts import TRIADA_TRANSFORMATION_TEXT


@pytest.fixture
def processor_with_data():
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º"""
    processor = SarsekenovProcessor()
    processor.process_text(
        TRIADA_TRANSFORMATION_TEXT,
        text_id="test_rag"
    )
    return processor


@pytest.fixture
def formatter(processor_with_data):
    """RAG —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä"""
    graph = processor_with_data.get_knowledge_graph()
    return RAGFormatter(graph)


class TestRAGFormatting:
    """–¢–µ—Å—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è RAG"""
    
    def test_format_for_rag(self, formatter):
        """–¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≥—Ä–∞—Ñ–∞"""
        documents = formatter.format_for_rag()
        
        assert len(documents) > 0, "No documents generated"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        for doc in documents:
            assert isinstance(doc, RAGDocument)
            assert doc.id
            assert doc.content
            assert doc.metadata
            assert doc.node_type
        
        print(f"\n‚úÖ RAG FORMATTING")
        print(f"   Total documents: {len(documents)}")
    
    def test_document_content_structure(self, formatter):
        """–¢–µ—Å—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã content –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö"""
        documents = formatter.format_for_rag()
        
        doc = documents[0]
        
        # Content –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —á–∞—Å—Ç–∏
        assert "–ö–æ–Ω—Ü–µ–ø—Ç:" in doc.content
        assert "–û–ø–∏—Å–∞–Ω–∏–µ:" in doc.content
        assert "–¢–∏–ø:" in doc.content
        
        print(f"\n   Sample content:\n{doc.content[:200]}...")
    
    def test_metadata_complete(self, formatter):
        """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ—Ç—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        documents = formatter.format_for_rag()
        
        for doc in documents:
            metadata = doc.metadata
            
            # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
            assert 'node_id' in metadata
            assert 'node_name' in metadata
            assert 'node_type' in metadata
            assert 'source' in metadata
    
    def test_get_documents_by_type(self, formatter):
        """–¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Ç–∏–ø—É"""
        from text_processor.orchestrator import NodeType
        
        practice_docs = formatter.get_documents_by_type(NodeType.PRACTICE)
        
        # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∞–∫—Ç–∏–∫–∏
        for doc in practice_docs:
            assert doc.node_type == "practice"
        
        print(f"\n   Practice documents: {len(practice_docs)}")
    
    def test_get_documents_by_tier(self, formatter):
        """–¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ tier"""
        tier3_docs = formatter.get_documents_by_tier(3)
        
        # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ç–æ–ª—å–∫–æ tier 3
        for doc in tier3_docs:
            assert doc.tier == 3
        
        print(f"\n   Tier 3 documents: {len(tier3_docs)}")


class TestExport:
    """–¢–µ—Å—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∞"""
    
    def test_export_to_json(self, formatter):
        """–¢–µ—Å—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ JSON"""
        # –°–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(
            mode='w',
            suffix='.json',
            delete=False
        ) as f:
            filepath = f.name
        
        try:
            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å
            formatter.export_to_json(filepath)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω
            assert os.path.exists(filepath)
            
            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            assert 'documents' in data
            assert 'total_documents' in data
            assert 'graph_statistics' in data
            
            print(f"\n‚úÖ EXPORT TO JSON")
            print(f"   Documents: {data['total_documents']}")
            
        finally:
            # –£–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª
            if os.path.exists(filepath):
                os.remove(filepath)
    
    def test_format_for_embedding_model(self, formatter):
        """–¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è embedding –º–æ–¥–µ–ª–∏"""
        # –§–æ—Ä–º–∞—Ç –¥–ª—è E5 –º–æ–¥–µ–ª–∏
        e5_docs = formatter.format_for_embedding_model("multilingual-e5-large")
        
        assert len(e5_docs) > 0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        for doc in e5_docs:
            assert 'id' in doc
            assert 'text' in doc
            assert 'metadata' in doc
            assert doc['text'].startswith("passage: ")
        
        print(f"\n‚úÖ E5 FORMAT")
        print(f"   Documents: {len(e5_docs)}")
        print(f"   Sample: {e5_docs[0]['text'][:100]}...")


class TestUtilityFunctions:
    """–¢–µ—Å—Ç—ã utility —Ñ—É–Ω–∫—Ü–∏–π"""
    
    def test_format_knowledge_graph_rag(self, processor_with_data):
        """–¢–µ—Å—Ç utility —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è RAG —Ñ–æ—Ä–º–∞—Ç–∞"""
        graph = processor_with_data.get_knowledge_graph()
        
        documents = format_knowledge_graph(graph, output_format="rag")
        
        assert len(documents) > 0
        assert all(isinstance(doc, RAGDocument) for doc in documents)
    
    def test_format_knowledge_graph_json(self, processor_with_data):
        """–¢–µ—Å—Ç utility —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è JSON —Ñ–æ—Ä–º–∞—Ç–∞"""
        graph = processor_with_data.get_knowledge_graph()
        
        documents = format_knowledge_graph(graph, output_format="json")
        
        assert len(documents) > 0
        assert all(isinstance(doc, dict) for doc in documents)
    
    def test_format_knowledge_graph_embedding(self, processor_with_data):
        """–¢–µ—Å—Ç utility —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è embedding —Ñ–æ—Ä–º–∞—Ç–∞"""
        graph = processor_with_data.get_knowledge_graph()
        
        documents = format_knowledge_graph(graph, output_format="embedding")
        
        assert len(documents) > 0
        assert all(doc['text'].startswith("passage: ") for doc in documents)
```


***

## üìù –®–ê–ì 9: –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤

### –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

```bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞
pytest tests/orchestrator/ -v

# –ó–∞–ø—É—Å–∫ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –≤—ã–≤–æ–¥–æ–º
pytest tests/orchestrator/ -v -s

# –ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
pytest tests/orchestrator/test_sarsekenov_processor.py::TestSarsekenovProcessor::test_process_text_full_workflow -v -s

# –ó–∞–ø—É—Å–∫ –í–°–ï–• —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ (–≤–∫–ª—é—á–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ)
pytest tests/ -v

# –° –ø–æ–∫—Ä—ã—Ç–∏–µ–º –∫–æ–¥–∞
pytest tests/orchestrator/ --cov=text_processor.orchestrator --cov-report=html
```


***

## ‚úÖ –ß–µ–∫–ª–∏—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≠—Ç–∞–ø–∞ ‚Ññ5

- [ ] –°–æ–∑–¥–∞–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π (`orchestrator/`, `export/`)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω `knowledge_graph.py`:
    - [ ] –ö–ª–∞—Å—Å—ã: `GraphNode`, `GraphEdge`, `KnowledgeGraph`
    - [ ] Enum: `NodeType`, `EdgeType`
    - [ ] –ú–µ—Ç–æ–¥—ã: `add_node`, `add_edge`, `find_path`, `build_reasoning_chain`
    - [ ] –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è: `to_json`, `from_json`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω `sarsekenov_processor.py`:
    - [ ] –ö–ª–∞—Å—Å `SarsekenovProcessor`
    - [ ] –ú–µ—Ç–æ–¥ `process_text()` (–∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≤—Å–µ—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤)
    - [ ] –ú–µ—Ç–æ–¥—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    - [ ] API –¥–ª—è –±–æ—Ç–∞: `find_practices_for_symptom`, `recommend_exercise`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω `rag_formatter.py`:
    - [ ] –ö–ª–∞—Å—Å `RAGFormatter`
    - [ ] –ú–µ—Ç–æ–¥ `format_for_rag()`
    - [ ] –ú–µ—Ç–æ–¥—ã —ç–∫—Å–ø–æ—Ä—Ç–∞: `export_to_json`, `format_for_embedding_model`
    - [ ] Utility —Ñ—É–Ω–∫—Ü–∏—è `format_knowledge_graph`
- [ ] –û–±–Ω–æ–≤–ª–µ–Ω—ã `__init__.py` —Ñ–∞–π–ª—ã
- [ ] –°–æ–∑–¥–∞–Ω—ã —Ç–µ—Å—Ç—ã:
    - [ ] `test_sarsekenov_processor.py` (8+ —Ç–µ—Å—Ç–æ–≤)
    - [ ] `test_knowledge_graph.py` (10+ —Ç–µ—Å—Ç–æ–≤)
    - [ ] `test_rag_formatter.py` (8+ —Ç–µ—Å—Ç–æ–≤)
- [ ] **–í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´** ‚úÖ

***

## üéØ –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞

–≠—Ç–∞–ø ‚Ññ5 —Å—á–∏—Ç–∞–µ—Ç—Å—è —É—Å–ø–µ—à–Ω—ã–º –µ—Å–ª–∏:

1. ‚úÖ –í—Å–µ 26+ —Ç–µ—Å—Ç–æ–≤ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –ø—Ä–æ—Ö–æ–¥—è—Ç
2. ‚úÖ `SarsekenovProcessor` –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã
3. ‚úÖ `KnowledgeGraph` —Å—Ç—Ä–æ–∏—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
4. ‚úÖ RAG –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É—é—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ
5. ‚úÖ API –¥–ª—è –±–æ—Ç–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç (`find_practices`, `recommend_exercise`)
6. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–æ –≤—Å–µ–º–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —ç—Ç–∞–ø–∞–º–∏

***

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ—Å–ª–µ –≠—Ç–∞–ø–∞ ‚Ññ5

```bash
pytest tests/ -v

========================= test session starts ==========================
tests/extractors/test_terminology_validator.py ......          [ 15%]
tests/extractors/test_neurostalking_pattern_extractor.py ..... [ 28%]
tests/extractors/test_causal_chain_extractor.py ......         [ 41%]
tests/extractors/test_concept_hierarchy_extractor.py ....      [ 52%]
tests/integration/test_all_extractors.py .......               [ 70%]
tests/orchestrator/test_sarsekenov_processor.py ........       [ 85%]
tests/orchestrator/test_knowledge_graph.py ..........          [ 95%]
tests/orchestrator/test_rag_formatter.py ........             [100%]

======================== 50+ passed in 5.00s ===========================
```


***

**–ì–æ—Ç–æ–≤–æ! –ü–æ–ª–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è Cursor AI –ø–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –≠—Ç–∞–ø–∞ ‚Ññ5 ‚Äî –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞!** üéØ‚ú®



